
@inproceedings{gong_reinforcement_2023,
	title = {Reinforcement {Learning} {Enabled} {Real}-{Time} {Energy} {Dispatch} of {Energy} {Systems} with {Flexible} {Operational} {Resources}},
	doi = {10.1109/AIKIIE60097.2023.10390385},
	abstract = {This paper developed a reinforcement learning- enabled real-time energy dispatch solution for energy systems with flexible operational resources. The detailed process of the proposed solution is formulated and implemented. The deep reinforcement learning method is introduced to solve the action strategy of the energy storage system and the controllable generator. Specifially, this work developed a reinforcement learning-enabled real-time energy dispatch solution for energy systems considering the presence of flexible operational resources. For the real-time scheduling phase, the timing decision problem of real-time scheduling is designed to maintain the stability of the trading curve. The deep reinforcement learning algorithm is designed and adopted to identify the action strategy of the energy storage system and the controllable generator. The proposed solution is evaluated through a case study via simulations and the numerical results confirmed the effectiveness of the proposed real-time energy dispatch solution for multi-energy systems.},
	booktitle = {2023 {International} {Conference} on {Ambient} {Intelligence}, {Knowledge} {Informatics} and {Industrial} {Electronics} ({AIKIIE})},
	author = {Gong, Liwu and Huang, Yuehua and Zhang, Wei and Gu, Yixing and Chen, Chao},
	month = nov,
	year = {2023},
	keywords = {Optimization, Real-time systems, Reinforcement learning, Reinforcement Learning, Deep learning, Generators, Control systems, Day-Ahead Energy Planning, Job shop scheduling, Multi-Energy Systems, Stability analysis},
	pages = {1--6},
	file = {Gong et al. - 2023 - Reinforcement Learning Enabled Real-Time Energy Di.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\DEL4RFMN\\Gong et al. - 2023 - Reinforcement Learning Enabled Real-Time Energy Di.pdf:application/pdf},
}

@inproceedings{selim_optimal_2022,
	title = {Optimal {Scheduled} {Control} {Operation} of {Battery} {Energy} {Storage} {System} using {Model}-{Free} {Reinforcement} {Learning}},
	doi = {10.1109/iSPEC54162.2022.10033035},
	abstract = {Driven by the tremendous increase in rooftop solar panels and battery installations in Australian states, several studies have been conducted to efficiently manage battery operations with the imported grid power through battery energy storage systems (BESS). Therefore, it is crucial for the BESS to carefully decide the power set-points of the installed batteries to maintain user comfort while operating household appliances. Additionally, BESS should be capable of reducing the electricity bills by optimally managing the battery operation to sustain times of higher tariff prices for the imported grid power. This paper formulates the scheduled operation of the BESS as a Markov decision Process (MDP) that enables the BESS to Figure out numerous scenarios and decides the optimal power set-points for both batteries and grid power. A model-free reinforcement learning approach is proposed to manage the batteries’ power-sharing and grid operation set-points to solve this MDP problem. This approach utilizes the advantages of the Deep Deterministic Policy Gradient (DDPG) algorithm to decide the shared power set-points every 5 minutes interval for the day ahead operation of the BESS. Finally, the proposed model is trained and validated using historical data of the Australian National Electricity market to offer an optimal scheduled control pattern for the daily BESS operations.},
	booktitle = {2022 {IEEE} {Sustainable} {Power} and {Energy} {Conference} ({iSPEC})},
	author = {Selim, Alaa},
	month = dec,
	year = {2022},
	keywords = {Pricing, Reinforcement learning, Optimal scheduling, Tariffs, Training, Battery energy storage system, Control optimization, Model-free, Optimal control, Power sharing, State of charge, Supercomputers},
	pages = {1--5},
	file = {Selim - 2022 - Optimal Scheduled Control Operation of Battery Ene.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\X6TBK9SI\\Selim - 2022 - Optimal Scheduled Control Operation of Battery Ene.pdf:application/pdf},
}

@inproceedings{basso_battery_2023,
	title = {Battery {Energy} {Storage} {Control} {Using} {Reinforcement} {Learning}},
	doi = {10.1109/IFEEC58486.2023.10458579},
	abstract = {With the increasing adoption of solar PV installations in Australian households, the availability of cheap renewable power during the day has surged. However, the challenge lies in rising electricity prices during morning and evening peak-consumption times. This project assessed the feasibility and profitability of using a Reinforcement Learning (RL) controller in a Battery Energy Storage System (BESS) to make cost-effective decisions by purchasing power when it's inexpensive and selling when it's costly. MATLAB/Simulink is used to create a BESS simulation model integrated into the electricity market, with the RL agent trained using normalized observation data and a reward function. Benchmarking demonstrated the RL controller's consistent outperformance of the timer-based controller in various market scenarios, emphasizing its adaptability and profitability advantages, particularly in volatile markets.},
	booktitle = {2023 {IEEE} {International} {Future} {Energy} {Electronics} {Conference} ({IFEEC})},
	author = {Basso, Elliott and Du, Yang},
	month = nov,
	year = {2023},
	keywords = {Reinforcement learning, Mathematical models, Electricity supply industry, Reinforcement Learning, Renewable energy sources, Profitability, Battery Energy Storage System, Energy consumption, Fluctuations, Matlab/Simulink},
	pages = {1--5},
	file = {Basso and Du - 2023 - Battery Energy Storage Control Using Reinforcement.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\DFIK6QT2\\Basso and Du - 2023 - Battery Energy Storage Control Using Reinforcement.pdf:application/pdf},
}

@inproceedings{el-telbany_prediction_2020,
	address = {Cham},
	title = {Prediction of the {Electrical} {Load} for {Egyptian} {Energy} {Management} {Systems}: {Deep} {Learning} {Approach}},
	isbn = {978-3-030-44289-7},
	shorttitle = {Prediction of the {Electrical} {Load} for {Egyptian} {Energy} {Management} {Systems}},
	doi = {10.1007/978-3-030-44289-7_23},
	abstract = {In the era of the Internet of Things (IoT) and machine learning, energy utilities have now the possibility of providing many benefits to the customers. Using advanced metering infrastructure is an important step to optimize and manage energy consumption. Smart meters are deployed in millions of households worldwide, representing an opportunity for monitoring systems and data analytics. Egypt has started its path into smart metering and needs to use big data analytics to endow the Egyptian grid with intelligence. In this paper, we investigate the role of big data analytics and available machine learning technologies that mine the data to generate insights into smart grid management process. We investigate a deep learning-based methodology such as long short-term memory (LSTM) network model to perform prediction of the electrical load for energy management systems. The LSTM model presents a decrease of 14\% in forecasting error compared to deep forward neural networks.},
	language = {en},
	booktitle = {Proceedings of the {International} {Conference} on {Artificial} {Intelligence} and {Computer} {Vision} ({AICV2020})},
	publisher = {Springer International Publishing},
	author = {El-Telbany, Mohammed E.},
	editor = {Hassanien, Aboul-Ella and Azar, Ahmad Taher and Gaber, Tarek and Oliva, Diego and Tolba, Fahmy M.},
	year = {2020},
	keywords = {Machine learning, Deep learning, Smart meters, Big data analytics, Electrical load, LSTM, Predictive analytics},
	pages = {237--246},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\XKKN2U2L\\El-Telbany - 2020 - Prediction of the Electrical Load for Egyptian Ene.pdf:application/pdf},
}

@article{poongulali_improved_2024,
	title = {Improved load demand prediction for cluster microgrids using modified temporal convolutional feed forward network},
	issn = {1572-9451},
	url = {https://doi.org/10.1007/s11235-024-01187-6},
	doi = {10.1007/s11235-024-01187-6},
	abstract = {This research addresses the challenge of accurate load forecasting in cluster microgrids, where distributed energy systems interlink to operate seamlessly. As renewable energy sources become more widespread, ensuring a consistent and reliable power supply in the face of variable weather conditions is a significant challenge for power providers. The variability in energy consumption patterns, influenced by human behavior and environmental conditions, further complicates load prediction. The inherent instability of solar and wind energies adds complexity to forecasting load demand accurately. This paper suggests a solution in addressing some challenges by proposing a Modified Temporal Convolutional Feed Forward Network (MTCFN) for load forecasting in cluster microgrids. The Fire Hawk Optimization algorithm is employed to determine optimal configurations, addressing the intricacies of this complex optimization problem. Data collected from the Microgrid Market Share and Forecast 2024–2032 report, the efficiency of the proposed approach is evaluated through metrics such as Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Mean Absolute Percentage Error (MAPE), Mean Square Error (MSE), and R-squared. The RMSE, MSE, MAE, MAPE, and R-squared values of the MTCFN are 0.4\%, 1.5\%, 0.6\%, 6.8\%, and 0.8\%, respectively. The optimization algorithm's effectiveness is cross-validated through rigorous testing, training, and validation processes, revealing that the FFNN model based on the Fire Hawk Optimization algorithm yields superior load forecasting results. This research contributes to the advancement of signal, image, and video processing in the context of resilient and accurate energy management in cluster microgrids.},
	language = {en},
	urldate = {2024-07-19},
	journal = {Telecommunication Systems},
	author = {Poongulali, E. and Selvaraj, K.},
	month = jul,
	year = {2024},
	keywords = {Microgrids, Energy management system, Feed forward neural network, Fire hawk optimization, Sparse attention mechanism, Temporal convolutional layer},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\IXX8J5B2\\Poongulali and Selvaraj - 2024 - Improved load demand prediction for cluster microg.pdf:application/pdf},
}

@inproceedings{syu_triples_2024,
	address = {Singapore},
	title = {{TripleS}: {A} {Subsidy}-{Supported} {Storage} for {Electricity} with {Self}-financing {Management} {System}},
	isbn = {978-981-9722-62-4},
	shorttitle = {{TripleS}},
	doi = {10.1007/978-981-97-2262-4_20},
	abstract = {In this paper, we propose a Subsidy-Supported Storage (also called TripleS) to assist grid management. Q-learning algorithms first determine the origin subsidies, and the proposed self-financing mechanism then balances the expected costs and gains, and generates the final subsidies. During market equilibrium, energy storage is fully charged when there is excess electricity and discharged when there is insufficient electricity. The electricity market then calculates the cash flow of the subsidies, and the remaining cash is used to make up for the self-discharge loss of the storage units. Experimental results demonstrate the effectiveness of the proposed TripleS in maintaining grid stability.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer Nature},
	author = {Syu, Jia-Hao and Cupek, Rafal and Chen, Chao-Chun and Lin, Jerry Chun-Wei},
	editor = {Yang, De-Nian and Xie, Xing and Tseng, Vincent S. and Pei, Jian and Huang, Jen-Wei and Lin, Jerry Chun-Wei},
	year = {2024},
	keywords = {Electricity grid, Management, Self-Financing, Storage},
	pages = {244--255},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\HGVGFYCZ\\Syu et al. - 2024 - TripleS A Subsidy-Supported Storage for Electrici.pdf:application/pdf},
}

@article{xu_federated_2023,
	title = {Federated learning for interpretable short-term residential load forecasting in edge computing network},
	volume = {35},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-022-08130-3},
	doi = {10.1007/s00521-022-08130-3},
	abstract = {Short-term residential load forecasting is of great significance to smart grid applications. Deep learning techniques, especially recurrent neural networks, can greatly improve the performance of prediction models. However, deep neural networks usually have low interpretability, which creates obstacles for customers to deeply understand the prediction results and make quick responses. In addition, the existing deep learning prediction methods rely heavily on the centralized training of massive data. However, the transmission of data from the client to the server poses a threat to the data security of customers. In this work, we propose an interpretable deep learning framework with federated learning for short-term residential load forecasting. Specifically, we propose a new automatic relevance determination network for feature interpretation, combined with the encoder–decoder architecture to achieve interpretable multi-step load prediction. In the edge computing network, the training scheme based on federated learning does not share the original data, which can effectively protect data privacy. The introduction of iterative federated clustering algorithm can alleviate the problem of non-independent and identical distribution of data in different households. We use two real-world datasets to verify the feasibility and performance of the proposed method. Finally, we discuss in detail the feature interpretation of these two datasets.},
	language = {en},
	number = {11},
	urldate = {2024-07-19},
	journal = {Neural Computing and Applications},
	author = {Xu, Chongchong and Chen, Guo and Li, Chaojie},
	month = apr,
	year = {2023},
	keywords = {Federated learning, Interpretable deep learning, Short-term residential load forecasting},
	pages = {8561--8574},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\6PRWLDRS\\Xu et al. - 2023 - Federated learning for interpretable short-term re.pdf:application/pdf},
}

@inproceedings{florez_ai-optimized_2023,
	address = {Cham},
	title = {{AI}-{Optimized} {Energy} {Management} for {More} {Efficient} and {Sustainable} {Microgrids}},
	isbn = {978-3-031-38318-2},
	doi = {10.1007/978-3-031-38318-2_43},
	abstract = {The implementation of renewable energy sources reduces dependence on fossil fuels and greenhouse gas emissions, but it comes at a significant cost to the grid due to the need for coupling multiple energy sources. This necessitates the optimization of energy production using artificial intelligence techniques that can reflect the characteristics of distributed energy management from the storage capacity of the microgrid while considering the consumer load. As such, this study develops an energy management algorithm based on the Deep-Q-Network (DQN) with prioritized experience replay (PER) utility function to model the operator’s risk-aversion or risk-seeking behavior, generating optimal exchange strategies in a dynamic environment. The reinforcement learning-based agent provides an understanding of energy storage capacity constraints in aggregate load/discharge energy decision making in the microgrid, using a discrete action space that depends on a reward related to the value of the optimal online objective function of the microgrid. By analyzing microgrid management under different system state definitions, the results show that substantially improved performance can be achieved compared to a traditional model that assumes deterministic information. The findings provide solid experimental validation of the potential of deep reward-based learning techniques to enable more efficient, flexible, and cost-effective energy management, particularly with the integration of more intermittent renewable energy sources.},
	language = {en},
	booktitle = {Distributed {Computing} and {Artificial} {Intelligence}, {Special} {Sessions} {I}, 20th {International} {Conference}},
	publisher = {Springer Nature Switzerland},
	author = {Flórez, Sebastián López and Herniández, Guillermo and Gonziález-Briones, Alfonso and de la Prieta, Fernando},
	editor = {Mehmood, Rashid and Alves, Victor and Praça, Isabel and Wikarek, Jarosław and Parra-Domínguez, Javier and Loukanova, Roussanka and de Miguel, Ignacio and Pinto, Tiago and Nunes, Ricardo and Ricca, Michela},
	year = {2023},
	keywords = {Reinforcement learning, contingency reserve, Energy efficiency optimization, Smart grid technologies},
	pages = {438--447},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\5ZRJMEMB\\Flórez et al. - 2023 - AI-Optimized Energy Management for More Efficient .pdf:application/pdf},
}

@inproceedings{pon_ragothama_priya_optimal_2022,
	address = {Singapore},
	title = {Optimal {Storage} {Planning} in {Active} {Distribution} {Network} {Considering} {Uncertainty} of {Wind} {Energy} {System}},
	isbn = {9789811651205},
	doi = {10.1007/978-981-16-5120-5_22},
	abstract = {This paper proposes an optimal location for Battery Energy storage system (BESS) and Wind Energy System (WES) targeting to minimize the power loss of the distribution system. In active distribution networks (ADNs), the use of Distributed Generation (DG) has grown significantly. In distributed generation, Renewable and Non-Renewable Energy resources are used for Power Generations. Renewable DGs such as wind, solar and tidal are environment-friendly sources. Among all Renewable Energy sources, wind energy has more attention because it provides larger power in the distribution system. The intermittent nature of wind speed increases the risk of secure and economical operation of Distribution network. Storage units or conventional DGs may be used to solve this problem. The IEEE 34-node three-phase unbalanced radial distribution system is taken as a test system. The distribution power flow analysis for unbalanced radial system is simulated with DIgSILENT power factory. The optimal location for WES and BESS is determined for the three-phase unbalanced radial distribution system.},
	language = {en},
	booktitle = {Proceedings of {International} {Conference} on {Data} {Science} and {Applications}},
	publisher = {Springer},
	author = {Pon Ragothama Priya, P. and Baskar, S. and Mala, K. and Tamilselvi, S. and Mohamed Umar Raja, M.},
	editor = {Saraswat, Mukesh and Roy, Sarbani and Chowdhury, Chandreyee and Gandomi, Amir H.},
	year = {2022},
	keywords = {Battery energy storage system (BESS), DIgSILENT power factory, Unbalanced radial distribution system, Wind energy system (WES)},
	pages = {285--296},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\SLIMWFUN\\Pon Ragothama Priya et al. - 2022 - Optimal Storage Planning in Active Distribution Ne.pdf:application/pdf},
}

@inproceedings{silvestri_hybrid_2022,
	address = {Cham},
	title = {Hybrid {Offline}/{Online} {Optimization} for {Energy} {Management} via {Reinforcement} {Learning}},
	isbn = {978-3-031-08011-1},
	doi = {10.1007/978-3-031-08011-1_24},
	abstract = {Constrained decision problems in the real world are subject to uncertainty. If predictive information about the stochastic elements is available offline, recent works have shown that it is possible to rely on an (expensive) parameter tuning phase to improve the behavior of a simple online solver so that it roughly matches the solution quality of an anticipative approach but maintains its original efficiency. Here, we start from a state-of-the-art offline/online optimization method that relies on optimality conditions to inject knowledge of a (convex) online approach into an offline solver used for parameter tuning. We then propose to replace the offline step with (Deep) Reinforcement Learning (RL) approaches, which results in a simpler integration scheme with a higher potential for generalization. We introduce two hybrid methods that combine both learning and optimization: the first optimizes all the parameters at once, whereas the second exploits the sequential nature of the online problem via the Markov Decision Process framework. In a case study in energy management, we show the effectiveness of our hybrid approaches, w.r.t. the state-of-the-art and pure RL methods. The combination proves capable of faster convergence and naturally handles constraint satisfaction.},
	language = {en},
	booktitle = {Integration of {Constraint} {Programming}, {Artificial} {Intelligence}, and {Operations} {Research}},
	publisher = {Springer International Publishing},
	author = {Silvestri, Mattia and De Filippo, Allegra and Ruggeri, Federico and Lombardi, Michele},
	editor = {Schaus, Pierre},
	year = {2022},
	keywords = {Deep reinforcement learning, Uncertainty, Constrained optimization, Offline/online optimization},
	pages = {358--373},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\X7E5Q6NZ\\Silvestri et al. - 2022 - Hybrid OfflineOnline Optimization for Energy Mana.pdf:application/pdf},
}

@article{el_bourakadi_robust_2023,
	title = {A robust energy management approach in two-steps ahead using deep learning {BiLSTM} prediction model and type-2 fuzzy decision-making controller},
	volume = {22},
	issn = {1573-2908},
	url = {https://doi.org/10.1007/s10700-022-09406-y},
	doi = {10.1007/s10700-022-09406-y},
	abstract = {The price prediction is valuable in energy management system (EMS) because it allows making informed decisions and solving the problem of the uncertainty related to the future ignorance based only on the past knowledge. To this goal, we present in this paper a two-steps EMS in order to control the different operations of a micro-grid (MG). In the first step, we exploit the advantages of the Bidirectional Long-Short Term Memory (BiLSTM) deep learning model to predict the next daily electricity price based on time series. In the second step, we use a type-2 fuzzy logic controller to decide which energy source will exploit the excess energy produced or meet the MG need. Real data is used in this paper to test the effectiveness of the proposed EMS whose superiority is proved through the test period. The BiLSTM forecasting model better performs compared to other related algorithms designed to the electricity price prediction. In addition, the proposed decision-making process can reduce the total MG cost and protect the batteries against the deep discharge and maximum charge in order to prolong their lifespan. We expect that this work can contribute to meet the real-world needs in the management of the electrical system.},
	language = {en},
	number = {4},
	urldate = {2024-07-19},
	journal = {Fuzzy Optimization and Decision Making},
	author = {El Bourakadi, Dounia and Ramadan, Hiba and Yahyaouy, Ali and Boumhidi, Jaouad},
	month = dec,
	year = {2023},
	keywords = {Energy management system, Bidirectional long-short term memory, Decision-making, Electricity price prediction, Type-2 fuzzy logic control},
	pages = {645--667},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\EBVRFY8K\\El Bourakadi et al. - 2023 - A robust energy management approach in two-steps a.pdf:application/pdf},
}

@inproceedings{sinha_methodological_2023,
	address = {Singapore},
	title = {A {Methodological} {Review} of {Time} {Series} {Forecasting} with {Deep} {Learning} {Model}: {A} {Case} {Study} on {Electricity} {Load} and {Price} {Prediction}},
	isbn = {978-981-19586-8-7},
	shorttitle = {A {Methodological} {Review} of {Time} {Series} {Forecasting} with {Deep} {Learning} {Model}},
	doi = {10.1007/978-981-19-5868-7_34},
	abstract = {Today, the world experiences a surge in adoption of renewable electricity generation methods. As a consequence to this, the dependence of electricity supply and demand has parallelly seen a dramatic increase on covariates like solar irradiance, wind speed, and temperature. Addressing the demand response scenario with efficient forecasting strategies is critical for the smart grid stability. With increment of renewable energy factor in total share of electricity generation, it becomes imperative to consider the external factors covariates while predicting the electricity price and load forecasting. Forecasting strategies, based on statistical and machine learning models, facilitates efficient and informed responses for electricity market. However, due to presence of large pool of forecasting models each having its own suitability, it becomes cumbersome to choose an appropriate sophisticated model selection from them. This work presents a methodological review of existing forecasting statistical and machine learning models and algorithms, with the prime purpose of choosing a best suited model for a specific environment or scenario. Data used for this purpose are a time series data, and information is very scattered in nature; thus, the process to make a full dataset and combining it with external covariates is a complex phenomenon. The work also discusses the process of making the multivariate time series dataset based on U.S. Energy Information Administration and combined it with typical meteorological year (TMY3) datasets. To validate the outcome of literature survey, detail experiment has been performed using the prepared dataset, and comparative analysis is presented.},
	language = {en},
	booktitle = {Machine {Learning}, {Image} {Processing}, {Network} {Security} and {Data} {Sciences}},
	publisher = {Springer Nature},
	author = {Sinha, Ayush and Singh, Tinku and Vyas, Ranjana and Kumar, Manish and Vyas, O. P.},
	editor = {Doriya, Rajesh and Soni, Badal and Shukla, Anupam and Gao, Xiao-Zhi},
	year = {2023},
	keywords = {Convolution Neural Network, Electrical load Forecasting, Long short-term memory networks, Time Series},
	pages = {457--479},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\JYABD3ZD\\Sinha et al. - 2023 - A Methodological Review of Time Series Forecasting.pdf:application/pdf},
}

@inproceedings{bousnina_deep_2022,
	address = {Cham},
	title = {Deep {Reinforcement} {Learning} for {Optimal} {Energy} {Management} of {Multi}-energy {Smart} {Grids}},
	isbn = {978-3-030-95470-3},
	doi = {10.1007/978-3-030-95470-3_2},
	abstract = {This paper proposes a Deep Reinforcement Learning approach for optimally managing multi-energy systems in smart grids. The optimal control problem of the production and storage units within the smart grid is formulated as a Partially Observable Markov Decision Process (POMDP), and is solved using an actor-critic Deep Reinforcement Learning algorithm. The framework is tested on a novel multi-energy residential microgrid model that encompasses electrical, heating and cooling storage as well as thermal production systems and renewable energy generation. One of the main challenges faced when dealing with real-time optimal control of such multi-energy systems is the need to take multiple continuous actions simultaneously. The proposed Deep Deterministic Policy Gradient (DDPG) agent has shown to handle well the continuous state and action spaces and learned to simultaneously take multiple actions on the production and storage systems that allow to jointly optimize the electrical, heating and cooling usages within the smart grid. This allows the approach to be applied for the real-time optimal energy management of larger scale multi-energy Smart Grids like eco-distrits and smart cities where multiple continuous actions need to be taken simultaneously.},
	language = {en},
	booktitle = {Machine {Learning}, {Optimization}, and {Data} {Science}},
	publisher = {Springer International Publishing},
	author = {Bousnina, Dhekra and Guerassimoff, Gilles},
	editor = {Nicosia, Giuseppe and Ojha, Varun and La Malfa, Emanuele and La Malfa, Gabriele and Jansen, Giorgio and Pardalos, Panos M. and Giuffrida, Giovanni and Umeton, Renato},
	year = {2022},
	keywords = {Smart grids, Energy management, Deep Reinforcement Learning, Actor-critic, Multi-energy},
	pages = {15--30},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\DJ464Q2N\\Bousnina and Guerassimoff - 2022 - Deep Reinforcement Learning for Optimal Energy Man.pdf:application/pdf},
}

@article{si_deep_2021,
	title = {Deep reinforcement learning based home energy management system with devices operational dependencies},
	volume = {12},
	issn = {1868-808X},
	url = {https://doi.org/10.1007/s13042-020-01266-5},
	doi = {10.1007/s13042-020-01266-5},
	abstract = {Advanced metering infrastructure and bilateral communication technologies facilitate the development of the home energy management system in the smart home. In this paper, we propose an energy management strategy for controllable loads based on reinforcement learning (RL). First, based on the mathematical model, the Markov decision process of different types of home energy resources (HERs) is formulated. Then, two RL algorithms, i.e. deep Q-learning and deep deterministic policy gradient are utilized. Based on the living habits of the residents, the dependency modes for HERs are proposed and are integrated into the reinforcement learning algorithms. Through the case studies, it is verified that the proposed method can schedule HERs properly to satisfy the established dependency modes. The difference between the achieved result and the optimal solution is relatively small.},
	language = {en},
	number = {6},
	urldate = {2024-07-19},
	journal = {International Journal of Machine Learning and Cybernetics},
	author = {Si, Caomingzhe and Tao, Yuechuan and Qiu, Jing and Lai, Shuying and Zhao, Junhua},
	month = jun,
	year = {2021},
	keywords = {Reinforcement learning, Smart home, Dependency modes, Home energy management system},
	pages = {1687--1703},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\SIFIQSGW\\Si et al. - 2021 - Deep reinforcement learning based home energy mana.pdf:application/pdf},
}

@inproceedings{da_silva_lima_multi_2006,
	address = {Berlin, Heidelberg},
	title = {A {Multi} {Agent} {Based} {Simulator} for {Brazilian} {Wholesale} {Electricity} {Energy} {Market}},
	isbn = {978-3-540-45464-9},
	doi = {10.1007/11874850_11},
	abstract = {During the last two decades power systems industry has undergone many changes world-wide, seeking to create competitive wholesale electricity markets. In these markets, power suppliers and consumers are free to negotiate the terms of their contracts, e.g., energy prices, power quantities and contract durations in several auctions structures. Multi-agent systems are a widely used computer paradigm in the simulation of these new power market business models. A usual approach is to develop a specific application within a standard agent management framework, such as JADE. Several approaches are commonly used for market simulations: those that evaluate the behavior of supplier and demand agents under several auction models, and others that focus on each market’s particular operations and problems, i.e., they simulate realtime market operating conditions. This work presents a multi-agent-based simulator for Brazilian electrical power market, incorporating operational and commercial models.},
	language = {en},
	booktitle = {Advances in {Artificial} {Intelligence} - {IBERAMIA}-{SBIA} 2006},
	publisher = {Springer},
	author = {da Silva Lima, Wagner and de Andrade Freitas, Eduardo Noronha},
	editor = {Sichman, Jaime Simão and Coelho, Helder and Rezende, Solange Oliveira},
	year = {2006},
	keywords = {Bilateral Contract, Independent System Operator, Multi Agent, Multiagent System, Spot Price},
	pages = {68--77},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\QA8NB4XJ\\da Silva Lima and de Andrade Freitas - 2006 - A Multi Agent Based Simulator for Brazilian Wholes.pdf:application/pdf},
}

@article{berlink_intelligent_2015,
	title = {Intelligent {Decision}-{Making} for {Smart} {Home} {Energy} {Management}},
	volume = {80},
	issn = {1573-0409},
	url = {https://doi.org/10.1007/s10846-014-0169-8},
	doi = {10.1007/s10846-014-0169-8},
	abstract = {One of the goals of Smart Grids is to encourage distributed generation of energy in houses, hence allowing the user to profit by injecting energy into the power grid. The implementation of a differentiated tariff of energy per time of use, coupled with energy storage in batteries, enables profit maximization by the user, who can choose to sell or store the energy generated whenever it is convenient. This paper proposes a solution to the sequential decision-making problem of energy sale by applying reinforcement learning. Results show a significant increase in the total long-term profit by using the policy obtained with the proposed approach, when compared with a price-unaware selling policy.},
	language = {en},
	number = {1},
	urldate = {2024-07-19},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Berlink, Heider and Kagan, Nelson and Reali Costa, Anna Helena},
	month = dec,
	year = {2015},
	keywords = {Reinforcement learning, Energy management system, SmartGrid, SmartHome},
	pages = {331--354},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\W2RBC8NG\\Berlink et al. - 2015 - Intelligent Decision-Making for Smart Home Energy .pdf:application/pdf},
}

@article{monacchi_assisted_2016,
	title = {Assisted energy management in smart microgrids},
	volume = {7},
	issn = {1868-5145},
	url = {https://doi.org/10.1007/s12652-016-0392-1},
	doi = {10.1007/s12652-016-0392-1},
	abstract = {Demand response provides utilities with a mechanism to share with end users the stochasticity resulting from the use of renewable sources. Pricing is accordingly used to reflect energy availability, to allocate such a limited resource to those loads that value it most. However, the strictly competitive mechanism can result in service interruption in presence of competing demand. To solve this issue we investigate on the use of forward contracts, i.e., service-level agreements priced to reflect the expectation of future supply and demand curves. Given the limited resources of microgrids, service availability is an opposite objective to the one of system reactivity. We firstly design policy-based brokers and identify then a learning broker based on artificial neural networks. We show the latter being progressively minimizing the reimbursement costs and maximizing the overall profit.},
	language = {en},
	number = {6},
	urldate = {2024-07-19},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Monacchi, Andrea and Elmenreich, Wilfried},
	month = dec,
	year = {2016},
	keywords = {Energy management, Artificial neural network, Energy trading, Behavior modeling, Smart metering},
	pages = {901--913},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\RZWS3WYX\\Monacchi and Elmenreich - 2016 - Assisted energy management in smart microgrids.pdf:application/pdf},
}

@article{tomazzoli_internet_2023,
	title = {Internet of {Things} and artificial intelligence enable energy efficiency},
	volume = {14},
	issn = {1868-5145},
	url = {https://doi.org/10.1007/s12652-020-02151-3},
	doi = {10.1007/s12652-020-02151-3},
	abstract = {In smart environments, there is an increasing demand for scalable and autonomous management systems. In this regard, energy efficiency hands out challenging aspects, for both home and business usages. Scalability in energy management systems is particularly difficult in those industry sector where power consumption of branches located in remote areas need to be monitored. Being autonomous requires that behavioural rules are automatically extracted from consumption data and applied to the system. Best practices for the specific energy configuration should be devised to achieve optimal energy efficiency. Best practices should also be revised and applied without human intervention against topology changes. In this paper, the Internet of Things paradigm and machine learning techniques are exploited to (1) define a novel system architecture for centralised energy efficiency in distributed sub-networks of electric appliances, (2) extract behavioural rules, identify best practices and detect device types. A system architecture tailored for autonomous energy efficiency has interesting applications in smart industry—where energy managers may effortlessly monitor and optimally setup a large number of sparse divisions—and smart home—where impaired people may avoid energy waste through an autonomous system that can be employed by the users as a delegate for decision making.},
	language = {en},
	number = {5},
	urldate = {2024-07-19},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Tomazzoli, Claudio and Scannapieco, Simone and Cristani, Matteo},
	month = may,
	year = {2023},
	keywords = {Energy management, Machine learning, Intelligent systems},
	pages = {4933--4954},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\NDWGIRLH\\Tomazzoli et al. - 2023 - Internet of Things and artificial intelligence ena.pdf:application/pdf},
}

@article{ghasvarian_jahromi_novel_2020,
	title = {A novel method for day-ahead solar power prediction based on hidden {Markov} model and cosine similarity},
	volume = {24},
	issn = {1433-7479},
	url = {https://doi.org/10.1007/s00500-019-04249-z},
	doi = {10.1007/s00500-019-04249-z},
	abstract = {Nowadays, with the emergence of new technologies such as smart grid and increasing the use of renewable energy in the grid, energy prediction has become more important in the electricity industry. Furthermore, with growing the integration of power generated from renewable energy sources into grids, an accurate forecasting tool for the reduction in undesirable effects of this scenario is essential. This study has developed a novel approach based on the hidden Markov model (HMM) for forecasting day-ahead solar power. The aim is to find a pattern of solar power changes at a given time in consecutive days. The proposed approach consists of two steps. In the first step, the cosine similarity is used to determine the similarity of solar power variations on consecutive days to a particular vector. In the second step, the obtained information from the first step is fed to HMM as a feature vector. These data are used for training and forecasting day-ahead solar power. After obtaining the preliminary results of the prediction, two known filters are utilized as post-processing to remove spikes and smooth the results. Finally, the performance of the proposed method is tested on real NREL data. No meteorological data (even solar radiation) are used; moreover, the model is fed only from the solar power of the past 23 days. To evaluate the proposed method, a feed-forward neural network and a simple HMM are examined with the same data and conditions. All three methods are tested with and without the post-processing. The results show that the proposed model is superior to other examined methods in terms of accuracy and computational time.},
	language = {en},
	number = {7},
	urldate = {2024-07-19},
	journal = {Soft Computing},
	author = {Ghasvarian Jahromi, Khatereh and Gharavian, Davood and Mahdiani, Hamidreza},
	month = apr,
	year = {2020},
	keywords = {Cosine similarity, Day-ahead forecasting, Hidden Markov Model, Solar power prediction},
	pages = {4991--5004},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\AIQUJ7T2\\Ghasvarian Jahromi et al. - 2020 - A novel method for day-ahead solar power predictio.pdf:application/pdf},
}

@inproceedings{abbasi_minimizing_2020,
	address = {Cham},
	title = {Minimizing {Daily} {Electricity} {Cost} {Using} {Bird} {Chase} {Scheme} with {Electricity} {Management} {Controller} in a {Smart} {Home}},
	isbn = {978-3-030-15032-7},
	doi = {10.1007/978-3-030-15032-7_7},
	abstract = {Integration of Demand Side Management (DSM) strategies within Smart Grid (SG) helps the utilities to mange and control the power consumer load to meet the power demand. Schemes adapted by DSM are used for reducing the load on utilities at peak time, which is achieved by managing the user appliances according to the changes in load on utility and individual smart home. This work is focused on hourly scheduling of the appliances being used in a smart home targeting the daily electricity cost minimization. A new heuristic scheme is introduced for hourly appliances scheduling on user side in this paper. The proposed scheme works at the electricity management controller level, installed in a smart home, within a SG infrastructure. The proposed scheme results are compared with other heuristic schemes as well. From extensive simulations it is depicted that proposed scheme performs best and outperforms other schemes in term of electricity cost minimization.},
	language = {en},
	booktitle = {Advanced {Information} {Networking} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Abbasi, Raza Abid and Javaid, Nadeem and ur Rehman, Shujat and {Amanulla} and Khan, Sajjad and Faisal, Hafiz Muhammad and Ur Rehman Khan, Sajawal},
	editor = {Barolli, Leonard and Takizawa, Makoto and Xhafa, Fatos and Enokido, Tomoya},
	year = {2020},
	keywords = {Machine learning, Smart grid, STLF, Xgboost},
	pages = {82--94},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\X4YPLDJP\\Abbasi et al. - 2020 - Minimizing Daily Electricity Cost Using Bird Chase.pdf:application/pdf},
}

@inproceedings{andrade_two_2020,
	address = {Cham},
	title = {A {Two} {Tier} {Architecture} for {Local} {Energy} {Market} {Simulation} and {Control}},
	isbn = {978-3-030-51999-5},
	doi = {10.1007/978-3-030-51999-5_25},
	abstract = {This paper addresses energy management and security having as basis sensing and monitoring of cyber-physical infrastructure of consumers and prosumers, and their participation in the Local Energy Market (LEM). The vision is to create a layered multi-agent framework that brings a complete view of the cyber-physical system of LEM participants, and provides optimization and control of energy for said participants. The proposed system is separated into a Market layer and a Cyber-Physical layer, each of them providing different services. The cyber-physical layer, represented by SMARTERCtrol system, provides Data Monitoring and Optimized Energy Control of individual building resources. The Market layer, represented by LEM Multi-Agent System, provides Negotiation, Forecasting, and Trust Evaluation. Both systems work together to provide and integrate a tool for simulation and control of LEM.},
	language = {en},
	booktitle = {Highlights in {Practical} {Applications} of {Agents}, {Multi}-{Agent} {Systems}, and {Trust}-worthiness. {The} {PAAMS} {Collection}},
	publisher = {Springer International Publishing},
	author = {Andrade, Rui and Garcia-Rodriguez, Sandra and Praca, Isabel and Vale, Zita},
	editor = {De La Prieta, Fernando and Mathieu, Philippe and Rincón Arango, Jaime Andrés and El Bolock, Alia and Del Val, Elena and Jordán Prunera, Jaume and Carneiro, João and Fuentes, Rubén and Lopes, Fernando and Julian, Vicente},
	year = {2020},
	keywords = {Optimization, Forecasting, Multi-agent systems, Energy},
	pages = {302--313},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\F483RWGL\\Andrade et al. - 2020 - A Two Tier Architecture for Local Energy Market Si.pdf:application/pdf},
}

@inproceedings{khan_hourly_2020,
	address = {Cham},
	title = {Hourly {Electricity} {Load} {Forecasting} in {Smart} {Grid} {Using} {Deep} {Learning} {Techniques}},
	isbn = {978-3-030-22263-5},
	doi = {10.1007/978-3-030-22263-5_18},
	abstract = {In this paper, a Deep Learning (DL) technique is introduced to forecast the electricity load accurately. We are facing energy shortage in today’s world. So, it is the need of the hour that proper scenario should be introduced to overcome this issue. For this purpose, moving towards Smart Grids (SG) from Traditional Grids (TG) is required. Electricity load is a factor which plays a major role in forecasting. For this purpose, we proposed a model which is based on selection, extraction and classification of historical data. Grey Correlation based Random Forest (RF) and Mutual Information (MI) is performed for feature selection, Kernel Principle Component Analysis (KPCA) is used for feature extraction and enhanced Convolutional Neural Network (CNN) is used for classification. Our proposed scheme is then compared with other benchmark schemes. Simulation results proved the efficiency and accuracy of the proposed model for hourly load forecasting of one day, one week and one month.},
	language = {en},
	booktitle = {Innovative {Mobile} and {Internet} {Services} in {Ubiquitous} {Computing}},
	publisher = {Springer International Publishing},
	author = {Khan, Abdul Basit Majeed and Javaid, Nadeem and Nazeer, Orooj and Zahid, Maheen and Akbar, Mariam and Hameed Khan, Majid},
	editor = {Barolli, Leonard and Xhafa, Fatos and Hussain, Omar K.},
	year = {2020},
	keywords = {Deep learning, Smart grid, Mutual Information, Random forest},
	pages = {185--196},
	file = {Full Text PDF:C\:\\Users\\Jacob\\Zotero\\storage\\47QZVT22\\Khan et al. - 2020 - Hourly Electricity Load Forecasting in Smart Grid .pdf:application/pdf},
}

@article{dong_strategic_2021,
	title = {A {Strategic} {Day}-ahead bidding strategy and operation for battery energy storage system by reinforcement learning},
	volume = {196},
	issn = {0378-7796},
	doi = {10.1016/j.epsr.2021.107229},
	abstract = {The Battery Energy Storage System (BESS) plays an essential role in the smart grid, and the ancillary market offers a high revenue. It is important for BESS owners to maximise their profit by deciding how to balance between the different offers and bidding with the rivals. Therefore, this paper formulates the BESS bidding problem as a Markov Decision Process(MDP) to maximise the total profit from the e Automation Generation Control (AGC) market and the energy market, considering the factors such as charging/discharging losses and the lifetime of the BESS. In the proposed algorithm, function approximation technology is introduced to handle the continuous massive bidding scales and avoid the dimension curse. As a model-free approach, the proposed algorithm can learn from the stochastic and dynamic environment of a power market, so as to help the BESS owners to decide their bidding and operational schedules profitably. Several case studies illustrate the effectiveness and validity of the proposed algorithm.},
	journal = {ELECTRIC POWER SYSTEMS RESEARCH},
	author = {Dong, Yi and Dong, Zhen and Zhao, Tianqiao and Ding, Zhengtao},
	month = jul,
	year = {2021},
	keywords = {Reinforcement learning, Battery energy storage system (BESS), Power market bidding},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\9PPDG3AS\\Dong et al. - 2021 - A Strategic Day-ahead bidding strategy and operati.pdf:application/pdf},
}

@article{giglio_efficient_2023,
	title = {An {Efficient} {Artificial} {Intelligence} {Energy} {Management} {System} for {Urban} {Building} {Integrating} {Photovoltaic} and {Storage}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3247636},
	abstract = {The emerging leading role of green energy in our society pushes the investigation of new economic and technological solutions. Green energies and smart communities increase efficiency with the use of digital solutions for the benefits of inhabitants and companies. The paper focuses on the development of a methodology for the energy management, combining photovoltaics and storage systems, considering as the main case study a multi-story building characterized by a high density of households, used to generate data which allow feasibility foresights. The physical model of the algorithm is composed by two main elements: the photovoltaics modules and the battery energy storage system. In addition, to gain information about the real-time consumption a machine learning module is included in our approach to generate predictions about the near future demand. The benefits provided by the method are evaluated with an economic analysis, which computes the return of the investment using the real consumptions of a Boarding School, located in Turin (Italy). The case study analyzed in this article showed an increase in purchased energy at the minimum price from 25\% to 91\% and a 55\% reduction in the electricity bill compared to most solutions on the market, with no additional costs and a stabilizing effect on the grid. Finally, the economic analysis shows that the proposed method is a profitable investment, with a breakeven point of thirteen years, due to the very simple implementation and the zero additional cost requested.},
	journal = {IEEE Access},
	author = {Giglio, Enrico and Luzzani, Gabriele and Terranova, Vito and Trivigno, Gabriele and Niccolai, Alessandro and Grimaccia, Francesco},
	year = {2023},
	keywords = {Smart grids, Forecasting, Renewable energy sources, Deep learning, Buildings, Energy storage, energy storage, energy management systems, Computer architecture, environmental economics, Photovoltaic systems, renewable energy sources},
	pages = {18673--18688},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\GEZVWBGK\\Giglio et al. - 2023 - An Efficient Artificial Intelligence Energy Manage.pdf:application/pdf},
}

@article{binyamin_artificial_2024,
	title = {Artificial intelligence-powered energy community management for developing renewable energy systems in smart homes},
	volume = {51},
	issn = {2211-467X},
	doi = {10.1016/j.esr.2023.101288},
	abstract = {The increase in demand due to scientific innovation and economic expansion raises challenges linked to environmental impact and sustainable market development. This study analyzes the role played by Peer -to -Peer (P2P) energy trading in system operation. Several case studies with four distinct prosumer models, each fitted with diverse Energy Storage Systems (ESS), photovoltaic (PV) systems, and responsive demand technologies such as Electric Vehicles (EV), are examined. An economic analysis is conducted using the developed interface. An energy management system establishes a dynamic market framework, enabling energy trading via P2P market operators and distribution system operators. The implemented trading platform is chosen depending on pricing variations across different time intervals for home models. The P2P energy trading system employs mathematical modeling via deep learning to achieve an optimal solution that minimizes costs. The study uses other domestic models and optimization techniques to explore the amount of energy traded across households and timeframes. Additionally, it investigates the accomplishment of two-way energy transfer in electric cars, the importance of energy storage and photovoltaic systems, and various housing scenarios concerning peer -to -peer energy trading. Additionally, the system's advantages are demonstrated to participants beforehand by validating and presenting data through an input and output system that accepts these instances.},
	journal = {ENERGY STRATEGY REVIEWS},
	author = {Binyamin, Sami Saeed and Ben Slama, Sami Abdullah and Zafar, Bassam},
	month = jan,
	year = {2024},
	keywords = {Deep reinforcement learning, Artificial intelligence, Electrical vehicle, Energy charing community, Peer to peer energy trading, Photovoltaic system},
}

@article{yi_integrated_2022,
	title = {An integrated energy management system using double deep {Q}-learning and energy storage equipment to reduce energy cost in manufacturing under real-time pricing condition: {A} case study of scale-model factory},
	volume = {38},
	issn = {1755-5817},
	doi = {10.1016/j.cirpj.2022.07.009},
	abstract = {Reducing energy costs is an emerging aspect in the research on the economic and environmental dimen-sions of manufacturing systems. The share of electricity cost accounts for approximately 60 \% of the total energy cost of a manufacturing system, whereas the share of oil, coal, and gas accounts for the remaining 40 \%. The electricity cost is dependent on the electricity price and usage. In terms of the electricity price, one of the pricing strategies widely used in the USA and Europe is called real-time pricing (RTP), which is characterised by hourly price changes. Compared to other pricing strategies, RTP yields the highest reward and the highest risk. In the RTP strategy, the electricity price is influenced by the supply and demand of the energy market. Hence, the energy cost of manufacturing cannot be determined by the manufacturing companies, implying a high level of risk. However, if manufacturing companies seize the opportunity to perform more manufacturing tasks when the energy price is low, the cost-savings will be significant, im-plying a high level of reward. In this study, we propose an integrated energy management system (IEMS) to reduce the energy cost of manufacturing systems. The IEMS consists of an energy storage equipment and an intelligent switch mechanism. When the electricity price is high, the manufacturing system is powered by the energy storage equipment. When the electricity price is low, the manufacturing system is powered by the public electricity grid, and the energy storage equipment is charged. The decision-making of these operations is performed by the intelligent switch mechanism based on double deep Q-learning. To validate this framework, a case study is conducted, in which an IEMS is developed to reduce the electricity cost of a scale-model factory. Based on an online test of the IEMS in different manufacturing cycles, it is concluded that the proposed IEMS approach achieves a cost reduction of approximately 57.21 \%.(c) 2022 The Authors. CC\_BY\_NC\_ND\_4.0},
	journal = {CIRP JOURNAL OF MANUFACTURING SCIENCE AND TECHNOLOGY},
	author = {Yi, Li and Langlotz, Pascal and Hussong, Marco and Glatt, Moritz and Sousa, Fabio J. P. and Aurich, Jan C.},
	month = aug,
	year = {2022},
	keywords = {Reinforcement learning, Energy management system, Double deep Q-learning, Energy cost, Manufacturing system, Real-time pricing},
	pages = {844--860},
	file = {Yi et al. - 2022 - An integrated energy management system using doubl.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\6F4UGQV9\\Yi et al. - 2022 - An integrated energy management system using doubl.pdf:application/pdf},
}

@article{li_attentive_2024,
	title = {Attentive {Convolutional} {Deep} {Reinforcement} {Learning} for {Optimizing} {Solar}-{Storage} {Systems} in {Real}-{Time} {Electricity} {Markets}},
	volume = {20},
	issn = {1941-0050},
	doi = {10.1109/TII.2024.3352229},
	abstract = {This article studies the synergy of solar-battery energy storage system (BESS) and develops a viable strategy for the BESS to unlock its economic potential by serving as a backup to reduce solar curtailments while also participating in the electricity market. We model the real-time bidding of the solar-battery system as two Markov decision processes for the solar farm and the BESS, respectively. We develop a novel deep reinforcement learning (DRL) algorithm to solve the problem by leveraging attention mechanism (AC) and multigrained feature convolution to process DRL input for better bidding decisions. Simulation results demonstrate that our AC-DRL outperforms two optimization-based and one DRL-based benchmarks by generating 23\%, 20\%, and 11\% higher revenue, as well as improving curtailment responses. The excess solar generation can effectively charge the BESS to bid in the market, significantly reducing solar curtailments by 76\% and creating synergy for the solar-battery system to be more viable.},
	number = {5},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Li, Jinhao and Wang, Changlong and Wang, Hao},
	month = may,
	year = {2024},
	keywords = {Optimization, Real-time systems, Batteries, Electricity supply industry, Battery energy storage system (BESS), deep reinforcement learning (DRL), Degradation, electricity market, Nanoelectromechanical systems, solar curtailment, solar photovoltaic (PV), Solar power generation},
	pages = {7205--7215},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\BKIHFRJZ\\Li et al. - 2024 - Attentive Convolutional Deep Reinforcement Learnin.pdf:application/pdf},
}

@article{samadi_decentralized_2020,
	title = {Decentralized multi-agent based energy management of microgrid using reinforcement learning},
	volume = {122},
	issn = {0142-0615},
	doi = {10.1016/j.ijepes.2020.106211},
	abstract = {This paper proposes a multi-agent based decentralized energy management approach in a grid-connected microgrid (MG). The MG comprises of wind and photovoltaic resources, diesel generator, electrical energy storage, and combined heat and power generations to serve electrical and thermal loads at the lower-level of energy management system (EMS). All distributed energy resources (DERs) and customers are modelled as self-interested agents who adopt reinforcement learning to optimize their behaviours and operation costs. Based on this algorithm, agents have the capability to interact with each other in a distributed manner and find the best strategy in competitive environment. At the upper-level of EMS, there is an energy management agent that gathers the information of agents of lower-level and clears the MG electrical and thermal energy market in line with predetermined goals. Utilizing energy availability from different DERs and variety of customers' consumption patterns, considering uncertainty of renewable generation and load consumption and taking into account technical constraint of DERs are the strengths of the presented framework. Performance of the proposed algorithm is investigated under different conditions of agents learning and using epsilon-greedy, soft-max and upper confidence bound methods. The simulation results verify efficacy of the proposed approach.},
	journal = {INTERNATIONAL JOURNAL OF ELECTRICAL POWER \& ENERGY SYSTEMS},
	author = {Samadi, Esmat and Badri, Ali and Ebrahimpour, Reza},
	month = nov,
	year = {2020},
	keywords = {Reinforcement learning, Distributed energy resources, Microgrid energy management system, Multi-agent systems},
	file = {Samadi et al. - 2020 - Decentralized multi-agent based energy management .pdf:C\:\\Users\\Jacob\\Zotero\\storage\\H328U336\\Samadi et al. - 2020 - Decentralized multi-agent based energy management .pdf:application/pdf},
}

@article{li_deep_2023,
	title = {Deep reinforcement learning for wind and energy storage coordination in wholesale energy and ancillary service markets},
	volume = {14},
	issn = {2666-5468},
	url = {https://www.sciencedirect.com/science/article/pii/S2666546823000526},
	doi = {https://doi.org/10.1016/j.egyai.2023.100280},
	abstract = {Wind energy has been increasingly adopted to mitigate climate change. However, the variability of wind energy causes wind curtailment, resulting in considerable economic losses for wind farm owners. Wind curtailment can be reduced using battery energy storage systems (BESS) as onsite backup sources. Yet, this auxiliary role may significantly weaken the economic potential of BESS in energy trading. Ideal BESS scheduling should balance onsite wind curtailment reduction and market bidding, but practical implementation is challenging due to coordination complexity and the stochastic nature of energy prices and wind generation. We investigate the joint-market bidding strategy of a co-located wind-battery system in the spot and Regulation Frequency Control Ancillary Service markets. We propose a novel deep reinforcement learning-based approach that decouples the system’s market participation into two related Markov decision processes for each facility, enabling the BESS to absorb onsite wind curtailment while performing joint-market bidding to maximize overall operational revenues. Using realistic wind farm data, we validated the coordinated bidding strategy, with outcomes surpassing the optimization-based benchmark in terms of higher revenue by approximately 25\% and more wind curtailment reduction by 2.3 times. Our results show that joint-market bidding can significantly improve the financial performance of wind-battery systems compared to participating in each market separately. Simulations also show that using curtailed wind generation as a power source for charging the BESS can lead to additional financial gains. The successful implementation of our algorithm would encourage co-location of generation and storage assets to unlock wider system benefits.},
	journal = {Energy and AI},
	author = {Li, Jinhao and Wang, Changlong and Wang, Hao},
	year = {2023},
	keywords = {Deep reinforcement learning, Electricity market, Wind curtailment, Wind-battery system},
	pages = {100280},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\5QHMN5IB\\Li et al. - 2023 - Deep reinforcement learning for wind and energy st.pdf:application/pdf},
}

@article{hussain_deep_2022,
	title = {Deep reinforcement learning-based operation of fast charging stations coupled with energy storage system},
	volume = {210},
	issn = {0378-7796},
	doi = {10.1016/j.epsr.2022.108087},
	abstract = {Fast charging stations (FCSs) can reduce the charging time of electric vehicles (EVs) and thus can help in the widespread adoption of EVs. However, FCSs may result in the power system overload. Therefore, the deployment of the battery energy storage system (BESS) in FCSs is considered as a potential solution to avoid system overload. However, the optimal operation of FCSs equipped with BESS is challenging due to the involvement of several uncertainties, such as EV arrival/departure times and electricity prices. Therefore, in this study, a deep reinforcement learning-based method is proposed to operate FCSs with BESS under these uncertainties. The stateof-the-art soft actor-critic method (SAC) is adopted and the model is trained with one-year data to cover seasonality and different types of days (working days and holidays). The performance of SAC is compared with two other deep reinforcement learning methods, i.e., deep deterministic policy gradient and twin delayed deep deterministic policy gradient. A comprehensive reward function is devised to train the model offline, which can then be used for the real-time operation of FCS with BESS under different uncertainties. The trained model has successfully reduced the peak load of the FCS during both weekdays and holidays by optimizing the operation of the BESS. In addition, the robustness of the proposed model against different EV arrival scenarios and extreme market price scenarios is also evaluated. Simulation results have shown that the proposed model can reduce the peak load of the FCS under diverse conditions in the desired fashion.},
	journal = {ELECTRIC POWER SYSTEMS RESEARCH},
	author = {Hussain, Akhtar and Bui, Van-Hai and Kim, Hak-Man},
	month = sep,
	year = {2022},
	keywords = {Reinforcement learning, Deep reinforcement learning, Smart grid, Electric vehicles, Charging station, Energy storage system},
	file = {Hussain et al. - 2022 - Deep reinforcement learning-based operation of fas.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\BDBFJCQC\\Hussain et al. - 2022 - Deep reinforcement learning-based operation of fas.pdf:application/pdf},
}

@article{pla_leveraging_2024,
	title = {Leveraging battery electric vehicle energy storage potential for home energy saving by model predictive control with backward induction},
	volume = {372},
	issn = {0306-2619},
	doi = {10.1016/j.apenergy.2024.123800},
	abstract = {Battery electric vehicles (BEVs) are gaining market shares due to their ability to employ clean energy, their smooth operation and reduced noise, pollutant emissions and maintenance. Batteries are one of the key technologies in BEV since they strongly affect the vehicle cost and driving range, two of the major concerns of BEV costumers. While the energy storing capabilities of BEVs usually exceed commuting requirements, batteries can be also utilized for home energy management system using bi-directional charging technology. This paper introduces an efficient energy management system for a smart home with BEVs and a bidirectional charger by addressing the corresponding optimal control problem of deciding the battery charging and discharging strategy to minimize energy expenditure and cost. To this aim, the electricity price and expenditure of upcoming weeks is forecasted using data from the present week, and a model of the complete system is used to find the optimal solutions by means of backward induction in a receding horizon approach. The proposed strategy relies on currently available information about the home and vehicle energy expenditure and energy prices in the recent past. The results of the study show a reduction of the electricity cost above 20\% in the considered use-case.},
	journal = {APPLIED ENERGY},
	author = {Pla, Benjamin and Bares, Pau and Aronis, Andre Nakaema and Anuratha, Sanjith},
	month = oct,
	year = {2024},
	keywords = {Reinforcement learning, Smart home energy management system, Smart grid, Battery electric vehicles, Bidirectional charging},
	file = {Pla et al. - 2024 - Leveraging battery electric vehicle energy storage.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\AFVUK8M6\\Pla et al. - 2024 - Leveraging battery electric vehicle energy storage.pdf:application/pdf},
}

@article{yang_mitigating_2024,
	title = {Mitigating long-term financial risk for large customers via a hybrid procurement strategy considering power purchase agreements},
	volume = {295},
	issn = {0360-5442},
	doi = {10.1016/j.energy.2024.131038},
	abstract = {In facing urgent climate issues, large electricity customers committed to the RE100 initiative, aiming to transition entirely to renewable energy sources (RES). However, they encounter significant challenges in managing the unpredictability of RES generation and the volatility of market prices. This study unveils a groundbreaking hybrid procurement model that integrates Power Purchase Agreements (PPAs) with Battery Energy Storage Systems (BESS) to mitigate these financial risks through a novel method. Employing a sophisticated Mixed Integer Linear Programming (MILP) model alongside an innovative deep learning forecast for long-term PPAs planning, we present a unique solution that significantly boosts financial returns and enhances risk mitigation for large electricity customers. Validated with real-world data across three distinct customer profiles, our model demonstrates a notable increase in expected Net Present Value (NPV) by up to 13.58\% compared to traditional strategies and improved earnings stability under adverse market conditions. Our proposed study not only charts a path toward more effective long-term RES procurement strategies but also provides large electricity customers with a strategic framework to skillfully navigate the complexities of the electricity market in alignment with their sustainability commitments.},
	journal = {ENERGY},
	author = {Yang, Haolin and Xu, Siqi and Gao, Weijun and Wang, Yafei and Li, You and Wei, Xindong},
	month = may,
	year = {2024},
	keywords = {Renewable energy sources, Deep learning networks, Power purchase agreements, Risk-averse optimal operational strategy, Stochastic programming},
	file = {Yang et al. - 2024 - Mitigating long-term financial risk for large cust.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\FUAU7VI3\\Yang et al. - 2024 - Mitigating long-term financial risk for large cust.pdf:application/pdf},
}

@article{ochoa_multi-agent_2022,
	title = {Multi-agent deep reinforcement learning for efficient multi-timescale bidding of a hybrid power plant in day-ahead and real-time markets},
	volume = {317},
	issn = {0306-2619},
	doi = {10.1016/j.apenergy.2022.119067},
	abstract = {Effective bidding on multiple electricity products under uncertainty would allow a more profitable market participation for hybrid power plants with variable energy resources and storage systems, therefore aiding the decarbonization process. This study deals with the effective bidding of a photovoltaic plant with an energy storage system (PV-ESS) participating in multi-timescale electricity markets by providing energy and ancillary services (AS) products. The energy management system (EMS) aims to maximize the plant's profits by efficiently bidding in the day-ahead and real-time markets while considering the awarded products' adequate delivery. EMS's bidding decisions are usually obtained from traditional mathematical optimization frameworks. However, since the addressed problem is a multi-stage stochastic program, it is often intractable and suffers the curse of dimensionality. This paper presents a novel multi-agent deep reinforcement learning (MADRL) framework for efficient multi-timescale bidding. Two agents based on multi-view artificial neural networks with recurrent layers (MVANNs) are adjusted to map environment observations to actions. Such mappings use as inputs available information related to electricity market products, bidding decisions, solar generation, stored energy, and time representations to bid in both electricity markets. Sustained by a price-taker assumption, the physically and financially constrained EMS's environment is simulated by employing historical data. A shared cumulative reward function with a finite time horizon is used to adjust both MVANNs' weights simultaneously during the learning phase. We compare the proposed MADRL framework against scenario-based two-stage robust and stochastic optimization methods. Results are provided for one-year-round market participation of the hybrid plant at a 1-minute resolution. The proposed method achieved statistically significant higher profits, less variable incomes from both electricity markets, and better provision of awarded products by achieving smaller and less variable energy imbalances through time.},
	journal = {APPLIED ENERGY},
	author = {Ochoa, Tomas and Gil, Esteban and Angulo, Alejandro and Valle, Carlos},
	month = jul,
	year = {2022},
	keywords = {Energy storage, Energy management system, Electricity market bidding, Multi-agent deep reinforcement learning, Multi-timescale electricity markets, Multi-view artificial neural networks, Solar generation},
	file = {Ochoa et al. - 2022 - Multi-agent deep reinforcement learning for effici.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\YSA8F8LA\\Ochoa et al. - 2022 - Multi-agent deep reinforcement learning for effici.pdf:application/pdf},
}

@article{afrasiabi_multi-agent_2019,
	title = {Multi-agent microgrid energy management based on deep learning forecaster},
	volume = {186},
	issn = {0360-5442},
	doi = {10.1016/j.energy.2019.115873},
	abstract = {This paper presents a multi-agent day-ahead microgrid energy management framework. The objective is to minimize energy loss and operation cost of agents, including conventional distributed generators, wind turbines, photovoltaics, demands, battery storage systems, and microgrids aggregator agent. To forecast market prices, wind generation, solar generation, and load demand, a deep learning-based approach is designed based on a combination of convolutional neural networks and gated recurrent unit. Each agent utilizes the designed learning approach and its own historical data to forecast its required parameters/data for scheduling purposes. To preserve the information privacy of agents, the alternating direction method of multipliers (ADMM) is utilized to find the optimal operating point of microgrid distributedly. To enhance the convergence performance of the distributed algorithm, an accelerated ADMM is presented based on the concept of over-relaxation. In the proposed framework, the agents do not need to share with other parties either their historical data for forecasting purposes or commercially sensitive information for scheduling purposes. The proposed framework is tested on a realistic test system. The forecast values obtained by the proposed forecasting method are compared with several other methods and the accelerated distributed algorithm is compared with the standard ADMM and analytical target cascading. (C) 2019 Published by Elsevier Ltd.},
	journal = {ENERGY},
	author = {Afrasiabi, Mousa and Mohammadi, Mohammad and Rastegar, Mohammad and Kargarian, Amin},
	month = nov,
	year = {2019},
	keywords = {Convolutional neural networks, Deep learning, Microgrid energy management system, Alternating direction method of multipliers, Gated recurrent unit, Short-term forecasting},
	file = {Afrasiabi et al. - 2019 - Multi-agent microgrid energy management based on d.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\DCGTYB3N\\Afrasiabi et al. - 2019 - Multi-agent microgrid energy management based on d.pdf:application/pdf},
}

@article{kim_multi-period_2024,
	title = {Multi-period, multi-timescale stochastic optimization model for simultaneous capacity investment and energy management decisions for hybrid {Micro}-{Grids} with green hydrogen production under uncertainty},
	volume = {190},
	issn = {1364-0321},
	doi = {10.1016/j.rser.2023.114049},
	abstract = {Given the steep rises in renewable energy's proportion in the global energy mix expected over several decades, a systematic way to plan the long-term deployment is needed. The main challenges are how to handle the sig-nificant uncertainties in technologies and market dynamics over a large time horizon. The problem is further complicated by the fast-timescale volatility of renewable energy sources, potentially causing grid instability and unfulfilled demands. As a remedy, energy storage and power-to-hydrogen systems are considered in conjunction with energy management system but doing so raises the complexity of the planning problem further. In this work, the long-term capacity planning for a hybrid microgrid (HM) system is formulated as a multi-period stochastic decision problem that considers uncertainties occurring at multiple timescales. Long-term capacity decisions are inherently linked with energy dispatch and storage decisions occurring at fast-timescale and it is best to solve for them simultaneously. However, the computational demand for solving it becomes quickly intractable with problem size. To this end, we propose to develop a Markov decision process (MDP) formulation of the problem and use simulation-based reinforcement learning for multi-period capacity investments of the planning horizon. The MDP includes the policies used for dispatch and storage operation, which are represented by linear programming as a part of the simulation model. The effectiveness of our proposed method is demonstrated with a case study, where decisions over multiple decades are considered along with various un-certainties of multi-timescales. Economic and environmental assessments are performed, providing valuable guidelines for government's energy policy.},
	number = {A},
	journal = {RENEWABLE \& SUSTAINABLE ENERGY REVIEWS},
	author = {Kim, Sunwoo and Choi, Yechan and Park, Joungho and Adams, Derrick and Heo, Seongmin and Lee, Jay H.},
	month = feb,
	year = {2024},
	keywords = {Energy management system, Capacity investment planning, Dynamic multi-period and multi-timescale decision-making, Green hydrogen, Hybrid microgrid, Multi-timescale uncertainty},
}

@article{taherian_optimal_2021,
	title = {Optimal dynamic pricing for an electricity retailer in the price-responsive environment of smart grid},
	volume = {130},
	issn = {0142-0615},
	doi = {10.1016/j.ijepes.2021.107004},
	abstract = {The main purpose of this study is to support a retail electric provider (REP) to make the best day-ahead dynamic pricing decisions in a realistic scenario. These decisions are made with the aim of maximizing the profit achieved by the REP under the assumption that mixed types of customers with different behaviors in the electricity market are considered. While some of the customers have installed smart meters with an embedded home energy management system (HEMS) in their home, others do not participate in the demand response (DR) programs. For this purpose, a bi-level hybrid demand modeling framework is proposed. It firstly uses an optimal energy management algorithm with bill minimization in order to model the behavior of customers with smart meters. Then, using a customers? behavior learning machine (CBLM), the behavior of other groups without smart meters is modeled. Therefore, the proposed hybrid model cannot only schedule usage of home appliances to the interests of customers with smart meters but can also be used to understand electricity usage behavior of customers without smart meters. The proposed model includes a stacked auto-encoder (SAE), one of the deep learning (DL) methods suitable for real-valued inputs, and adaptive neuro-fuzzy inference system (ANFIS). Based on the established hybrid demand model for all customers, a profit maximization algorithm is developed in order to achieve optimal prices for the REP under relevant market constraints. The results of the case studies confirm the applicability and effectiveness of the proposed model.},
	journal = {INTERNATIONAL JOURNAL OF ELECTRICAL POWER \& ENERGY SYSTEMS},
	author = {Taherian, Hossein and Aghaebrahimi, Mohammad Reza and Baringo, Luis and Goldani, Saeid Reza},
	month = sep,
	year = {2021},
	keywords = {Deep learning, Smart grid, Bidding strategy, Customer behavior learning, Day-ahead dynamic pricing, Retail electric provider},
	file = {Taherian et al. - 2021 - Optimal dynamic pricing for an electricity retaile.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\GZV7UYVL\\Taherian et al. - 2021 - Optimal dynamic pricing for an electricity retaile.pdf:application/pdf},
}

@article{kelly_optimal_2020,
	title = {Optimal investment timing and sizing for battery energy storage systems},
	volume = {28},
	doi = {10.1016/j.est.2020.101272},
	abstract = {Due to electricity market deregulation over the past two decades, the responsibility for new generation is with private investors who seek profit maximisation. Battery Energy Storage Systems (BESS), which are one solution to combat the intermittent nature of renewable energy sources, also require private investment for widespread deployment. This paper develops a methodology for applying Real Options Analysis to a BESS project from the perspective of private investors to determine the optimal investment time and BESS capacity size (MWh). Two models with different timescales are utilized: the operational model which is hourly, and the planning model which is yearly. The operational model is solved using a reinforcement learning algorithm called Deterministic Policy Gradient, while the planning model is solved using a MATLAB inbuilt nonlinear global optimiser called patternsearch. The methodology is demonstrated for a 100 MW BESS connected to the Irish grid and trading exclusively in the day-ahead market. Three different BESS CAPEX future realisations are analysed along with three different BESS manufacturers' degradation warranties for C-Rates under 0.37C. The results show that BESS CAPEX has minimal influence on investment timing but has a significant effect on BESS size. Furthermore, extrapolating degradation warranty for C-Rates greater than 0.37C does not influence optimal investment timing or sizing, while a change in BESS energy retention limit at year 10 can have a significant influence on the viability of a BESS project.},
	journal = {JOURNAL OF ENERGY STORAGE},
	author = {Kelly, Joseph J. and Leahy, Paul G.},
	month = apr,
	year = {2020},
	keywords = {Reinforcement learning, Battery degradation, Battery energy storage systems, Deterministic Policy Gradient Algorithm, Net Present Value, Real Option Analysis, Stochastic optimization},
	file = {Kelly and Leahy - 2020 - Optimal investment timing and sizing for battery e.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\XVTDH4UD\\Kelly and Leahy - 2020 - Optimal investment timing and sizing for battery e.pdf:application/pdf},
}

@article{mashlakov_probabilistic_2020,
	title = {Probabilistic {Forecasting} of {Battery} {Energy} {Storage} {State}-of-{Charge} under {Primary} {Frequency} {Control}},
	volume = {38},
	issn = {1558-0008},
	doi = {10.1109/JSAC.2019.2952195},
	abstract = {Multi-service market optimization of battery energy storage system (BESS) requires assessing the forecasting uncertainty arising from coupled resources and processes. For the primary frequency control (PFC), which is one of the highest-value applications of BESS, this uncertainty is linked to the changes of BESS state-of-charge (SOC) under stochastic frequency variations. In order to quantify this uncertainty, this paper aims to exploit one of the recent achievements in the field of deep learning, i.e. multi-attention recurrent neural network (MARNN), for BESS SOC forecasting under PFC. Furthermore, we extend the MARNN model for probabilistic forecasting with a hybrid approach combining Mixture Density Networks and Monte Carlo dropout that incorporate the uncertainties of the data noise and the model parameters in the form of prediction interval (PI). The performance of the model is studied on BESS SOC datasets that are simulated based on real frequency measurements from three European synchronous areas in Great Britain, Continental Europe, and Northern Europe and validated by three PI evaluation indexes. Compared with the state-of-the-art quantile regression algorithms, the proposed hybrid model performed well with respect to the coverage probability of PIs for the different regulatory environments of the PFC.},
	number = {1},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Mashlakov, Aleksei and Lensu, Lasse and Kaarna, Arto and Tikka, Ville and Honkapuro, Samuli},
	month = jan,
	year = {2020},
	keywords = {Batteries, Forecasting, Predictive models, Uncertainty, Frequency control, Attention-based neural network, battery energy storage system (BESS), Data models, frequency control, mixture density networks, Monte Carlo dropout, prediction intervals, probabilistic forecasting, Probabilistic logic, state-of-charge (SOC)},
	pages = {96--109},
	file = {Accepted Version:C\:\\Users\\Jacob\\Zotero\\storage\\K9GGJV7Z\\Mashlakov et al. - 2020 - Probabilistic Forecasting of Battery Energy Storag.pdf:application/pdf},
}

@article{norouzi_risk-averse_2023,
	title = {Risk-averse and flexi-intelligent scheduling of microgrids based on hybrid {Boltzmann} machines and cascade neural network forecasting},
	volume = {348},
	issn = {0306-2619},
	doi = {10.1016/j.apenergy.2023.121573},
	abstract = {The future of energy flexibility in microgrids (MGs) is steering towards a highly granular control of the end-user customers. This calls for more highly accurate uncertainty forecasting and optimal management of risk and flexibility options. This paper presents a novel data-driven model to optimize the operation of MGs based on a risk-averse flexi-intelligent energy management system (RFEMS), considering the rising challenge of global climate change. It considers the presence of renewables, a diesel generator, and flexibility resources (FRs) containing a demand response program (DRP), distributed electric vehicles (EVs), and electric springs (ESs). In the first phase, the proposed model, by means of a novel hybrid deep-learning (DL) model, forecasts uncertain parameters associated with wind and solar generations, load demand, and day-ahead energy market price. The architecture of the proposed hybrid forecasting model is composed of several stacked restricted Boltzmann machines and a cascade neural network. In the second phase, the MG operator (MGO), based on the obtained uncertainty forecasting results, in the context of a hybrid risk-controlling model, optimizes the MG operation using the provided demand-side flexibility. The proposed optimization problem is linearized stochastic pro-gramming with robust concepts, subject to AC optimal power flow constraints, MG flexibility restrictions, and operating limits of local resources. Finally, the efficiency of the proposed RFEMS by using real German datasets on a 33-bus test MG is analyzed. Numerical results demonstrate the superior performance of the proposed forecasting model over several hybrid DL models. In particular, the root mean square error (RMSE) index for wind, solar, load, and price forecasting is improved by 53.35\%, 73.24\%, 80.24\%, and 58.1\%, respectively. Further analysis of the proposed RFEMS reveals that operating indices in two 33-bus and 69-bus test networks are significantly improved. It paves pathways to risk-averse, flexible, and economic operation of smart active dis-tribution networks.},
	journal = {APPLIED ENERGY},
	author = {Norouzi, Mohammadali and Aghaei, Jamshid and Niknam, Taher and Alipour, Mohammadali and Pirouzi, Sasan and Lehtonen, Matti},
	month = oct,
	year = {2023},
	keywords = {spring},
}

@article{dong_optimal_2020,
	title = {An {Optimal} {Day}-ahead {Bidding} {Strategy} and {Operation} for {Battery} {Energy} {Storage} {System} by {Reinforcement} {Learning}},
	volume = {53},
	issn = {2405-8963},
	url = {https://www.sciencedirect.com/science/article/pii/S240589632030402X},
	doi = {https://doi.org/10.1016/j.ifacol.2020.12.144},
	abstract = {The Battery Energy Storage System (BESS) plays an important role in the smart grid and the ancillary market offers high revenues. It is reasonable for the owner of the BESS to maximise their profits by deciding how to bid with their rivals and balance between the different market offers. Therefore, this paper proposes an optimal bidding model of the BESS to maximise the total profit from the Automation Generation Control (AGC) market and the energy market, while taking the charging/discharging losses and the life of the BESS into consideration. Taking advantages of function approximation approaches, a reinforcement learning algorithm is introduced to the designed model, which can cope with the continuous and massive states of the proposed model and avoid the dimension curse. The resultant novel bidding model would help the BESS owners to decide their biddings and operational schedules profitably. Several case studies illustrate the effectiveness and validity of the proposed model.},
	number = {2},
	journal = {IFAC-PapersOnLine},
	author = {Dong, Yi and Zhao, Tianqiao and Ding, Zhengtao},
	year = {2020},
	keywords = {reinforcement learning, Battery Energy Storage System (BESS), optimal bidding},
	pages = {13190--13195},
}

@article{hedayatnia_two-stage_2024,
	title = {Two-{Stage} {Data}-{Driven} optimal energy management and dynamic {Real}-{Time} operation in networked microgrid based deep reinforcement learning approach},
	volume = {160},
	issn = {0142-0615},
	url = {https://www.sciencedirect.com/science/article/pii/S0142061524003636},
	doi = {https://doi.org/10.1016/j.ijepes.2024.110142},
	abstract = {Given the significant challenges posed by the vast and diverse data in energy management, this study introduces a two-stage approach: optimal energy management system (OEMS) and dynamic real-time operation (DRTOP). These stages employ a multi-agent policy-oriented deep reinforcement learning (DRL) approach, aiming to minimize operating and energy exchange costs through interactions in the networked microgrid (NMG) energy market. The primary objectives include minimizing the distribution system operator (DSO) cost and optimizing the exchanged power between DSO and NMG, and the power transmission losses and the secondary include minimizing MG’s operating cost, optimal use of renewable energy resources (RER) and energy storage systems (ESS), minimizing the exchanged power cost with the main grid and, risk analysis. The OEMS\&DRTOP model is developed based on the Stackelberg game theory and the DRL structure. The DRL model is developed in two offline learning and online distributed operation phases to minimize the computational burden, time, and DRL operation process. This study’s results show the high efficiency of the presented approach to minimizing the operating cost, the exchanged power based on the price uncertainty, power transmission losses, and, RER and ESSs optimal participation. In addition, regarding computational load, the proposed concept demonstrates a 12.9\% reduction compared to the dueling deep Q-network method and a 17\% reduction compared to the deep Q-network method. Also regarding computational time, the proposed concept demonstrates a 17.13\% reduction compared to the dueling deep Q-network method and a 25.6\% reduction compared to the deep Q-network method.},
	journal = {International Journal of Electrical Power \& Energy Systems},
	author = {Hedayatnia, Atefeh and Ghafourian, Javid and Sepehrzad, Reza and Al-Durrad, Ahmed and Anvari-Moghaddam, Amjad},
	year = {2024},
	keywords = {Deep reinforcement learning, Networked microgrid, Optimal energy management and real-time operation, Stackelberg game theory},
	pages = {110142},
}

@article{xie_multi-agent_2023,
	title = {Multi-{Agent} attention-based deep reinforcement learning for demand response in grid-responsive buildings},
	volume = {342},
	issn = {0306-2619},
	url = {https://www.sciencedirect.com/science/article/pii/S0306261923005263},
	doi = {https://doi.org/10.1016/j.apenergy.2023.121162},
	abstract = {Integrating renewable energy resources and deploying energy management devices offer great opportunities to develop autonomous energy management systems in grid-responsive buildings. Demand response can promote enhancing demand flexibility and energy efficiency while reducing consumer costs. In this work, we propose a novel multi-agent deep reinforcement learning (MADRL) based approach with an agent assigned to individual buildings to facilitate demand response programs with diverse loads, including space heating/cooling and electrical equipment. Achieving real-time autonomous demand response in networks of buildings is challenging due to uncertain system parameters, the dynamic market price, and complex coupled operational constraints. To develop a scalable approach for automated demand response in networks of interconnected buildings, coordination between buildings is necessary to ensure demand flexibility and the grid's stability. We propose a MADRL technique that utilizes an actor-critic algorithm incorporating shared attention mechanism to enable effective and scalable real-time coordinated demand response in grid-responsive buildings. The presented case studies demonstrate the ability of the proposed approach to obtain decentralized cooperative policies for electricity costs minimization and efficient load shaping without knowledge of building energy systems. The viability of the proposed control approach is also demonstrated by a reduction of over 6\% net load demand compared to standard reinforcement learning approaches, deep deterministic policy gradient, and soft actor-critic algorithm, as well as a tailored MADRL approach for demand response.},
	journal = {Applied Energy},
	author = {Xie, Jiahan and Ajagekar, Akshay and You, Fengqi},
	year = {2023},
	keywords = {Deep reinforcement learning, Demand response, Buildings, Multi-agent},
	pages = {121162},
	file = {Xie et al. - 2023 - Multi-Agent attention-based deep reinforcement lea.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\BL5A3TXR\\Xie et al. - 2023 - Multi-Agent attention-based deep reinforcement lea.pdf:application/pdf},
}

@article{saberikamarposhti_comprehensive_2024,
	title = {A comprehensive review of {AI}-enhanced smart grid integration for hydrogen energy: {Advances}, challenges, and future prospects},
	volume = {67},
	issn = {0360-3199},
	url = {https://www.sciencedirect.com/science/article/pii/S0360319924001320},
	doi = {https://doi.org/10.1016/j.ijhydene.2024.01.129},
	abstract = {The convergence of hydrogen energy with artificial intelligence (AI) in smart infrastructure has significant potential to revolutionise the worldwide energy sector. This article thoroughly examines the progress, difficulties, and potential breakthroughs in the integration of AI technology with smart grids to enhance the use of hydrogen energy . The study focuses on utilising AI technologies such as deep learning and machine learning to optimise the processes of generating, distributing, and utilising energy. The discoveries stemming from this investigation facilitate prognostic maintenance, instantaneous decision-making, and effective demand-side management, augmenting the durability and eco-friendliness of energy systems. Nevertheless, this auspicious panorama is surrounded by significant obstacles. Significant issues develop regarding data privacy and security when sensitive information is sent over AI-powered grid systems. Interoperability difficulties necessitate standardising the communication protocols to enable smooth data flow. Additionally, further research is essential to tackle the technological limitations of AI in grid management. This article presents a forward-thinking viewpoint on the incorporation of AI-enhanced smart grid technologies, with a focus on future expectations. Autonomous energy management systems offer improved flexibility, proactive maintenance, and flexible energy distribution. Simultaneously, the combination of Edge AI and decentralisation facilitates the establishment of energy generating and storage facilities at local levels. This helps to make immediate decisions, minimises delays, and improves the durability of the power grid. The report emphasises the pivotal importance of governmental and regulatory factors in directing these advancements. The foundation for a safe and flexible power system is established by data privacy legislation, grid modernisation initiatives, and incentives for hydrogen energy. The essay promotes energy market reforms, technological neutrality, and measures that improve grid resilience as a means of achieving environmental sustainability. The integration of hydrogen energy into smart infrastructure is facilitated by AI, and strategic planning and collaborative design are crucial for achieving a resilient, sustainable, and efficient energy future. This article provides a strategic plan for efficiently handling complexities, leveraging advantageous situations, and collaboratively building an energy industry that is adaptable, productive, and environmentally aware.},
	journal = {International Journal of Hydrogen Energy},
	author = {SaberiKamarposhti, Morteza and Kamyab, Hesam and Krishnan, Santhana and Yusuf, Mohammad and Rezania, Shahabaldin and Chelliapan, Shreeshivadasan and Khorami, Masoud},
	year = {2024},
	keywords = {Artificial intelligence (AI), Energy optimisation, Grid resilience, Hydrogen energy, Policy and regulation, Smart grid integration},
	pages = {1009--1025},
}

@article{dreher_ai_2022,
	title = {{AI} agents envisioning the future: {Forecast}-based operation of renewable energy storage systems using hydrogen with {Deep} {Reinforcement} {Learning}},
	volume = {258},
	issn = {0196-8904},
	url = {https://www.sciencedirect.com/science/article/pii/S0196890422001972},
	doi = {https://doi.org/10.1016/j.enconman.2022.115401},
	abstract = {Hydrogen-based energy storage has the potential to compensate for the volatility of renewable power generation in energy systems with a high renewable penetration. The operation of these storage facilities can be optimized using automated energy management systems. This work presents a Reinforcement Learning-based energy management approach in the context of CO2-neutral hydrogen production and storage for an industrial combined heat and power application. The economic performance of the presented approach is compared to a rule-based energy management strategy as a lower benchmark and a Dynamic Programming-based unit commitment as an upper benchmark. The comparative analysis highlights both the potential benefits and drawbacks of the implemented Reinforcement Learning approach. The simulation results indicate a promising potential of Reinforcement Learning-based algorithms for hydrogen production planning, outperforming the lower benchmark. Furthermore, a novel approach in the scientific literature demonstrates that including energy and price forecasts in the Reinforcement Learning observation space significantly improves optimization results and allows the algorithm to take variable prices into account. An unresolved challenge, however, is balancing multiple conflicting objectives in a setting with few degrees of freedom. As a result, no parameterization of the reward function could be found that fully satisfied all predefined targets, highlighting one of the major challenges for Reinforcement Learning -based energy management algorithms to overcome.},
	journal = {Energy Conversion and Management},
	author = {Dreher, Alexander and Bexten, Thomas and Sieker, Tobias and Lehna, Malte and Schütt, Jonathan and Scholz, Christoph and Wirsum, Manfred},
	year = {2022},
	keywords = {Deep reinforcement learning, Energy management, Hydrogen, Dynamic programming, Renewable energy storage},
	pages = {115401},
	file = {Dreher et al. - 2022 - AI agents envisioning the future Forecast-based o.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\TZ6IXY95\\Dreher et al. - 2022 - AI agents envisioning the future Forecast-based o.pdf:application/pdf},
}

@article{salari_model-free_2024,
	title = {Model-free reinforcement learning-based energy management for plug-in electric vehicles in a cooperative multi-agent home microgrid with consideration of travel behavior},
	volume = {288},
	issn = {0360-5442},
	url = {https://www.sciencedirect.com/science/article/pii/S0360544223031195},
	doi = {https://doi.org/10.1016/j.energy.2023.129725},
	abstract = {The rise in popularity of plug-in electric vehicles (PEVs) and the increasing use of renewable energy sources (RESs) have paved the way for advanced energy management systems (EMSs) that optimize energy usage and distribution in home microgrids (H-MGs). This study focuses on the integration of PEVs in H-MGs using an EMS and analyzes its impact on electrical power grids (EPGs). We examine the effect of PEV charging and discharging patterns on H-MG energy flow, considering various scenarios such as high renewable energy generation, different levels of PEV penetration, and EPG connection status. Our findings indicate that an efficient EMS can significantly enhance H-MGs’ overall efficiency by intelligently scheduling PEV charging and discharging, maximizing the use of locally generated renewable energy, and reducing peak load on the EPG. We demonstrate that a cooperative multi-agent system EMS, driven by a robust continuous and real-time fuzzy Q-learning (FQL) method, can reduce electricity market prices by 15\% by increasing the use of renewable energy generation by 25\%. To fully realize the benefits of EMS, we address challenges such as reducing dependence on EPG by 30\%, improving battery state by 12\%, and ensuring EPG stability in the face of uncertainties.},
	journal = {Energy},
	author = {Salari, Azam and Zeinali, Mahdi and Marzband, Mousa},
	year = {2024},
	keywords = {Reinforcement learning, Battery health monitoring, Electricity market pricing, Intelligent PEV charging, Plug-in electric vehicle management},
	pages = {129725},
}

@incollection{kokossis_demand_2023,
	series = {Computer {Aided} {Chemical} {Engineering}},
	title = {Demand {Response} in {Microgrids} with {Attention}-{Based} {Deep} {Reinforcement} {Learning}},
	volume = {52},
	url = {https://www.sciencedirect.com/science/article/pii/B9780443152740502493},
	abstract = {In this work, we propose a novel multi-agent deep reinforcement learning (MA-DRL) based approach to facilitate efficient load shaping through automated demand response in a microgrid. Achieving real-time autonomous demand response with energy management systems in buildings can be challenging due to factors like uncertain system parameters, the dynamic market price, and the complex coupled operational constraints. To develop a scalable approach for automated demand response in a microgrid, it is necessary to allow for coordination between buildings in the grid to smoothen the overall demand curve. We present a MA-DRL agent that utilizes an actor-critic algorithm incorporating a shared attention mechanism to enable an effective and scalable real-time cooperation to prevent the non-coordinated peak shifting actions in the complicated building system. A computational case study conducted with nine residential buildings revealed the attention-based MA-DRL agent’s ability to execute decentralized cooperative policies without knowledge of building systems models or electricity price dynamics. Viability of the proposed control approach was also demonstrated by a reduction in net electricity consumption of over 6\% accompanied by reduction in carbon emissions as compared to both conventional and state-of-the-art reinforcement learning approaches for automated demand response.},
	booktitle = {33rd {European} {Symposium} on {Computer} {Aided} {Process} {Engineering}},
	publisher = {Elsevier},
	author = {Xie, Jiahan and Ajagekar, Akshay and You, Fengqi},
	editor = {Kokossis, Antonios C. and Georgiadis, Michael C. and Pistikopoulos, Efstratios},
	year = {2023},
	doi = {https://doi.org/10.1016/B978-0-443-15274-0.50249-3},
	note = {ISSN: 1570-7946},
	keywords = {Deep reinforcement learning, demand response, microgrids, multi-agent},
	pages = {1565--1571},
}

@article{miao_co-optimizing_2021,
	title = {Co-{Optimizing} {Battery} {Storage} for {Energy} {Arbitrage} and {Frequency} {Regulation} in {Real}-{Time} {Markets} {Using} {Deep} {Reinforcement} {Learning}},
	volume = {14},
	doi = {10.3390/en14248365},
	abstract = {Battery energy storage systems (BESSs) play a critical role in eliminating uncertainties associated with renewable energy generation, to maintain stability and improve flexibility of power networks. In this paper, a BESS is used to provide energy arbitrage (EA) and frequency regulation (FR) services simultaneously to maximize its total revenue within the physical constraints. The EA and FR actions are taken at different timescales. The multitimescale problem is formulated as two nested Markov decision process (MDP) submodels. The problem is a complex decision-making problem with enormous high-dimensional data and uncertainty (e.g., the price of the electricity). Therefore, a novel co-optimization scheme is proposed to handle the multitimescale problem, and also coordinate EA and FR services. A triplet deep deterministic policy gradient with exploration noise decay (TDD-ND) approach is used to obtain the optimal policy at each timescale. Simulations are conducted with real-time electricity prices and regulation signals data from the American PJM regulation market. The simulation results show that the proposed approach performs better than other studied policies in literature.},
	number = {24},
	journal = {ENERGIES},
	author = {Miao, Yushen and Chen, Tianyi and Bu, Shengrong and Liang, Hao and Han, Zhu},
	month = dec,
	year = {2021},
	file = {1-s2.0-S0925231220304367-main.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\X8D5Z3WX\\1-s2.0-S0925231220304367-main.pdf:application/pdf;Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\MBBP8FR9\\Miao et al. - 2021 - Co-Optimizing Battery Storage for Energy Arbitrage.pdf:application/pdf},
}

@article{gao_hybrid_2024,
	title = {A {Hybrid} {Approach} for {Home} {Energy} {Management} {With} {Imitation} {Learning} and {Online} {Optimization}},
	volume = {20},
	issn = {1551-3203},
	doi = {10.1109/TII.2023.3324939},
	abstract = {A home energy management system exploits the time-varying electricity tariff and renewable energy profiles to lower residents' electricity bills via wise scheduling of various domestic appliances. This study targets the rather typical case of a general household with solar panels. All four classes of loads are considered, while many existing studies only investigate a restricted subset. Considering the high stochasticity in real-time pricing and solar power generation, we propose an online approach in a hybrid semidecentralized framework, where each shiftable load is controlled by a deep neural network (DNN), and all adjustable loads are coordinated together by fast online optimization. We train each DNN via efficient and effective imitation learning (IL) instead of popular reinforcement learning (RL). This framework allows adjustable loads to react properly to possibly poor actions of shiftable loads via online one-step optimization to alleviate their adverse impact. Numerical experiments with real-world data show that, compared with RL, our approach can reduce the training time significantly, while its execution time is only slightly affected. Moreover, our approach outperforms the traditional day-ahead optimization method and the fully decentralized multiagent RL and multiagent IL methods by a wide margin, attaining an average cost fairly close to the theoretical minimum.},
	number = {3},
	journal = {IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS},
	author = {Gao, Shuhua and Lee, Raiyan bin Zulkifli and Huang, Zhenhao and Xiang, Cheng and Yu, Ming and Tan, Kuan Tak and Lee, Tong Heng Lee},
	month = mar,
	year = {2024},
	pages = {4527--4539},
	file = {Gao et al. - 2024 - A Hybrid Approach for Home Energy Management With .pdf:C\:\\Users\\Jacob\\Zotero\\storage\\DDF4FBPJ\\Gao et al. - 2024 - A Hybrid Approach for Home Energy Management With .pdf:application/pdf},
}

@article{mathew_improved_2021,
	title = {Improved residential energy management system using priority double deep {Q}-learning},
	volume = {69},
	issn = {2210-6707},
	doi = {10.1016/j.scs.2021.102812},
	abstract = {In the current era, electricity demand has skyrocketed. Power grids have to face a lot of uneven power demand daily. During a certain period in a day, the power demand peaks, making it difficult for the grid to meet the demand. To deal with this problem, an intelligent Home Energy Management (HEM) can be beneficial. Smart HEM systems can schedule loads from peak to low peak hours. Thereby reducing peak load on the grid as well as reducing decreasing the costs incurred by a user. In this paper, we proposed a Deep Reinforcement Learning model with prioritized experience sampling (PQDN-DR) for appropriate demand response, and the problem of load shifting is simulated as a game. We also propose a novel reward system for better convergence of the DRL model to near-optimal strategies and a DR adapted Epsilon Greedy Policy to guide the agent in exploration phase for faster convergence. The proposed system minimizes power demand peak and consumers? bills simultaneously. The proposed method has successfully reduced the peak load and peak costs in smaller DR environment. The agent reduced costs and overall variance of the load profile for all customers for 24 h in the standard DR environment.},
	journal = {SUSTAINABLE CITIES AND SOCIETY},
	author = {Mathew, Alwyn and Jolly, Milan Jeetendra and Mathew, Jimson},
	month = jun,
	year = {2021},
}

@article{gao_learning-based_2021,
	title = {A {Learning}-{Based} {Bidding} {Approach} for {PV}-{Attached} {BESS} {Power} {Plants}},
	volume = {9},
	issn = {2296-598X},
	doi = {10.3389/fenrg.2021.750796},
	abstract = {Large-scale renewable photovoltaic (PV) and battery energy storage system (BESS) units are promising to be significant electricity suppliers in the future electricity market. A bidding model is proposed for PV-integrated BESS power plants in a pool-based day-ahead (DA) electricity market, in which the uncertainty of PV generation output is considered. In the proposed model, we consider the market clearing process as the external environment, while each agent updates the bid price through the communication with the market environment for its revenue maximization. A multiagent reinforcement learning (MARL) called win-or-learn-fast policy-hill-climbing (WoLF-PHC) is used to explore optimal bid prices without any information of opponents. The case study validates the computational performance of WoLF-PHC in the proposed model, while the bidding strategy of each participated agent is thereafter analyzed.},
	journal = {FRONTIERS IN ENERGY RESEARCH},
	author = {Gao, Xiang and Ma, Haomin and Chan, Ka Wing and Xia, Shiwei and Zhu, Ziqing},
	month = oct,
	year = {2021},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\HV8SKA4N\\Gao et al. - 2021 - A Learning-Based Bidding Approach for PV-Attached .pdf:application/pdf},
}

@article{salazar_reinforcement_2023,
	title = {Reinforcement {Learning}-{Based} {Pricing} and {Incentive} {Strategy} for {Demand} {Response} in {Smart} {Grids}},
	volume = {16},
	doi = {10.3390/en16031466},
	abstract = {International agreements support the modernization of electricity networks and renewable energy resources (RES). However, these RES affect market prices due to resource variability (e.g., solar). Among the alternatives, Demand Response (DR) is presented as a tool to improve the balance between electricity supply and demand by adapting consumption to available production. In this sense, this work focuses on developing a DR model that combines price and incentive-based demand response models (P-B and I-B) to efficiently manage consumer demand with data from a real San Juan-Argentina distribution network. In addition, a price scheme is proposed in real time and by the time of use in relation to the consumers' influence in the peak demand of the system. The proposed schemes increase load factor and improve demand displacement compared to a demand response reference model. In addition, the proposed reinforcement learning model improves short-term and long-term price search. Finally, a description and formulation of the market where the work was implemented is presented.},
	number = {3},
	journal = {ENERGIES},
	author = {Salazar, Eduardo J. and Jurado, Mauro and Samper, Mauricio E.},
	month = feb,
	year = {2023},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\RUVF6V5Q\\Salazar et al. - 2023 - Reinforcement Learning-Based Pricing and Incentive.pdf:application/pdf},
}

@article{liang_robust_2024,
	title = {Robust {Vehicle}-to-{Grid} {Energy} {Trading} {Method} {Based} on {Smart} {Forecast} and {Multi}-{Blockchain} {Network}},
	volume = {12},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2024.3352631},
	abstract = {In the present era, energy issues are a significant concern, and the energy trading market is the crucial sector to facilitate supply-demand balance and sustainable development. For better demand response and grid balancing, vehicle-to-grid (V2G) technology is rapidly gaining importance in energy markets. To narrow the gap between ideal V2G goals and actual applications needs, energy trading system has to overcome the challenges of over-centralized structure, inflexible timeline adaptation, limited market scale and energy efficiency, excessive feedback time costs, and low rate of economic return. To address these issues and ensure a secure energy market, we propose a decentralized intelligent V2G system called V2G Forecasting and Trading Network (V2GFTN) to achieve efficient and robust energy trading in campus EV networks. A multiple blockchain structure is proposed in V2GFTN to ensure trading security and data privacy between energy requests and offers. V2GFTN also integrates energy forecasting functions for EVs with a smart energy trading and EV allocation mechanism called SRET so that the EVs with driving tasks can supply their extra power back to the grid and achieve higher energy efficiency and economic profit. Through rigorous experimentation and compared with equivalent studies, V2GFTN system has demonstrated higher economic profit and energy demand fill rate by up to 1.6 times and 1.9 times than the state-of-the-art V2G approaches.},
	journal = {IEEE Access},
	author = {Liang, Yuxiao and Wang, Zhishang and Abdallah, Abderazek Ben},
	year = {2024},
	keywords = {Vehicle dynamics, Forecasting, Energy management, Costs, Task analysis, Economics, Vehicle-to-grid, Blockchains, Emissions trading, energy forecast, Energy trading, multi-blockchain, vehicle-to-grid},
	pages = {8135--8153},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\LKCGUZY8\\Liang et al. - 2024 - Robust Vehicle-to-Grid Energy Trading Method Based.pdf:application/pdf},
}

@inproceedings{kasi_comprehensive_2023,
	title = {A {Comprehensive} {Investigation} of {Optimal} {Sizing} of {Hybrid} {Renewable} {Energy} {Resources} for {Micro} {Distributed} {Systems}},
	doi = {10.1109/NEleX59773.2023.10421117},
	abstract = {Renewable Energy Sources (RES) are rapidly increasing for the generation of electrical power due to the high demand for green electrical power and reduced dependency on conventional energy resources. Using the RES is considered to be crucial as they are scalable, eco-friendly, abundant in nature, and can be applied in different applications, such as residential, agriculture, commercial, and industrial areas. It can increase the system's reliability and thus reduce the cost of energy generation. However, the RES demonstrate inadequate load following and are not transportable. This issue can be overcome by implementing a microgrid system that is used to generate, transfer, and store electricity economically and efficiently. The Hybrid Renewable System (HRS) integrated with a microgrid system is considered to be a promising energy source and it is feasible. The primary objective of HRS is an enhancement of aspects to resolve the issues related to optimal sizing of HRS components by considering load supply incessantly. Considering the growing importance of such HRS and the increasing number of research activities, a Systematic Literature Review (SLR) is conducted to investigate the research based on optimal sizing of HRS integrated microgrid distributed generation with a focus on techno-economic reliability. This SLR reveals the articles published during 2019 to 2023. Through the SLR, the features of traditional methods, hybrid algorithms, and Artificial Intelligence (AI) based techniques are assessed and address the recent trends and development of optimal sizing of the HRS integrated microgrid distributed generation.},
	booktitle = {2023 {International} {Conference} on {Next} {Generation} {Electronics} ({NEleX})},
	author = {Kasi, Shanmuganatha Vadivel and Das, Narottam and Alahakoon, Sanath and Hassan, Nur},
	month = dec,
	year = {2023},
	keywords = {Energy management, Renewable energy sources, Artificial intelligence, Microgrids, Market research, Energy Management, Artificial Intelligence (AI), Distributed Generation, Energy resolution, Microgrids (MGs), Optimal Sizing, Power Generation, Reliability, Renewable Energy Sources (RES)},
	pages = {1--7},
}

@inproceedings{rezazadeh_federated_2022,
	title = {A {Federated} {DRL} {Approach} for {Smart} {Micro}-{Grid} {Energy} {Control} with {Distributed} {Energy} {Resources}},
	doi = {10.1109/CAMAD55695.2022.9966919},
	abstract = {The prevalence of the Internet of things (IoT) and smart meters devices in smart grids is providing key support for measuring and analyzing the power consumption patterns. This approach enables end-user to play the role of prosumers in the market and subsequently contributes to diminish the carbon footprint and the burden on utility grids. The coordination of trading surpluses of energy that is generated by house renewable energy resources (RERs) and the supply of shortages by external networks (main grid) is a necessity. This paper proposes a hierarchical architecture to manage energy in multiple smart buildings leveraging federated deep reinforcement learning (FDRL) with dynamic load in a distributed manner. Within the context of the developed FDRL-based framework, each agent that is hosted in local building energy management systems (BEMS) trains a local deep reinforcement learning (DRL) model and shares its experience in the form of model hyperparameters to the federation layer in the energy management system (EMS). Simulation studies are conducted using one EMS and up to twenty smart houses that are equipped with photovoltaic (PV) systems and batteries. This iterative training approach enables the proposed discretized soft actor-critic (SAC) agents to aggregate the collected knowledge to expedite the overall learning procedure and reduce costs and CO2 emissions, while the federation approach can mitigate privacy breaches. The numerical results confirm the performance of the proposed framework under different daytime periods, loads, and temperatures.},
	booktitle = {2022 {IEEE} 27th {International} {Workshop} on {Computer} {Aided} {Modeling} and {Design} of {Communication} {Links} and {Networks} ({CAMAD})},
	author = {Rezazadeh, Farhad and Bartzoudis, Nikolaos},
	month = nov,
	year = {2022},
	note = {ISSN: 2378-4873},
	keywords = {Reinforcement learning, Smart grids, federated learning, Training, deep reinforcement learning, Artificial intelligence, Deep learning, Computational modeling, Smart meters, energy control, smart micro-grid, soft actor-critic, Temperature control},
	pages = {108--114},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\2VHF9BX5\\Rezazadeh and Bartzoudis - 2022 - A Federated DRL Approach for Smart Micro-Grid Ener.pdf:application/pdf},
}

@inproceedings{samadi_q-learning-oriented_2021,
	title = {Q-{Learning}-{Oriented} {Distributed} {Energy} {Management} of {Grid}-{Connected} {Microgrid}},
	doi = {10.1109/ICEE52715.2021.9544152},
	abstract = {In this paper11This work is supported by Niroo Research Institute (NRI)., reinforcement learning (RL) is used for energy management of agent based microgrid (MG). The Grid connected MG that contains wind turbine, fuel cell (FC), diesel generator and electric vehicle (EV) to supply its demands, is modeled as a multi-agent system (MAS). The DER and customer are considered as self-interested agents that try to maximize their profits and optimize their behavior. These agents use RL to interact with each other in distributed manner without any direct communication. The market operator of MG is responsible to gather agents' data that have been submitted and clears the market to meet the desired goals. Modeling the stochastic nature of wind power generation and demand fluctuation of customer agents, implementing demand side management program for customer agents, besides taking into account the technical constraint of diesel generator, FC and EV agent are the main strengths of this paper. The simulation results confirm the efficiency of the proposed approach.},
	booktitle = {2021 29th {Iranian} {Conference} on {Electrical} {Engineering} ({ICEE})},
	author = {Samadi, Esmat and Badri, Ali and Ebrahimpour, Reza},
	month = may,
	year = {2021},
	note = {ISSN: 2642-9527},
	keywords = {Q-learning, Reinforcement learning, Fuel cells, Stochastic processes, Microgrids, Simulation, Fluctuations, distributed energy resources, energy management, multi-agent systems, Wind power generation, Microgrid},
	pages = {318--322},
}

@article{li_temporal-aware_2024,
	title = {Temporal-{Aware} {Deep} {Reinforcement} {Learning} for {Energy} {Storage} {Bidding} in {Energy} and {Contingency} {Reserve} {Markets}},
	issn = {2771-9626},
	doi = {10.1109/TEMPR.2024.3372656},
	abstract = {The battery energy storage system (BESS) has immense potential for enhancing grid reliability and security through its participation in the electricity market. BESS often seeks various revenue streams by taking part in multiple markets to unlock its full potential, but effective algorithms for joint-market participation under price uncertainties are insufficiently explored in the existing research. To bridge this gap, we develop a novel BESS joint bidding strategy that utilizes deep reinforcement learning (DRL) to bid in the spot and contingency frequency control ancillary services (FCAS) markets. Our approach leverages a transformer-based temporal feature extractor to effectively respond to price fluctuations in seven markets simultaneously and helps DRL learn the best BESS bidding strategy in joint-market participation. Additionally, unlike conventional “black-box” DRL model, our approach is more interpretable and provides valuable insights into the temporal bidding behavior of BESS in the dynamic electricity market. We validate our method using realistic market prices from the Australian National Electricity Market. The results show that our strategy outperforms benchmarks, including both optimization-based and other DRL-based strategies, by substantial margins. Our findings further suggest that effective temporal-aware bidding can significantly increase profits in the spot and contingency FCAS markets compared to individual market participation.},
	journal = {IEEE Transactions on Energy Markets, Policy and Regulation},
	author = {Li, Jinhao and Wang, Changlong and Zhang, Yanru and Wang, Hao},
	year = {2024},
	keywords = {Real-time systems, Uncertainty, Electricity supply industry, deep reinforcement learning, energy arbitrage, Regulation, Generators, Battery energy storage system, Australia, Contingency management, frequency control ancillary services, transformer},
	pages = {1--15},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\5TF22JC7\\Li et al. - 2024 - Temporal-Aware Deep Reinforcement Learning for Ene.pdf:application/pdf},
}

@article{ma_two-timescale_2024,
	title = {A {Two}-{Timescale} {Operation} {Strategy} for {Battery} {Storage} in {Joint} {Frequency} and {Energy} {Markets}},
	volume = {2},
	issn = {2771-9626},
	doi = {10.1109/TEMPR.2023.3324920},
	abstract = {The growing penetration of renewable energy in modern power systems requires energy storage to take on more responsibilities in multiple regulation services. Battery energy storage system (BESS) possesses fast response capability and is suitable to shave peak demand and provide frequency support. This article studies coordinated bidding strategies of BESS in frequency regulation and energy markets. Challenge arises from the fact that frequency control and energy arbitrage actions are taken in different timescales, and the capacity used in either market affects the available capacity and revenue in the other one. This article proposes a two-timescale decision framework, offering the hourly base-power bid in the energy market and capacity bid in the frequency regulation market, as well as real-time responses to the automatic generation control (AGC) signal every few seconds. In the fine timescale, we employ a threshold policy to generate AGC response accounting for battery lifespan. In the coarse timescale, we establish a stochastic dynamic programming model and optimize the bidding policy without exact forecasts of market prices. To solve the stochastic dynamic programming model online, a simulation-based policy improvement method is developed to approximate the state-action value function using a heuristic base policy. The performance improvement property brought by simulation is theoretically proven. We carry out comprehensive case studies to validate the effectiveness of the proposed method and analyze the economic impact of electricity prices and battery E/P ratio. Empirical tests show that with an E/P ratio of 3{\textbackslash}sim5, the BESS gains a higher net revenue across the lifespan.},
	number = {2},
	journal = {IEEE Transactions on Energy Markets, Policy and Regulation},
	author = {Ma, Qianli and Wei, Wei and Mei, Shengwei},
	month = jun,
	year = {2024},
	keywords = {Optimization, Batteries, Renewable energy sources, Automatic generation control, Battery storage, energy arbitrage, Frequency control, frequency regulation, online dynamic programming, Regulation, Stochastic processes, two-timescale control},
	pages = {200--213},
}

@inproceedings{anwar_proximal_2022,
	title = {Proximal {Policy} {Optimization} {Based} {Reinforcement} {Learning} for {Joint} {Bidding} in {Energy} and {Frequency} {Regulation} {Markets}},
	doi = {10.1109/PESGM48719.2022.9917082},
	abstract = {Driven by the global decarbonization effort, the rapid integration of renewable energy into the conventional electricity grid presents new challenges and opportunities for the battery energy storage system (BESS) participating in the energy market. Energy arbitrage can be a significant source of revenue for the BESS due to the increasing price volatility in the spot market caused by the mismatch between renewable generation and electricity demand. In addition, the Frequency Control Ancillary Services (FCAS) markets established to stabilize the grid can offer higher returns for the BESS due to their capability to respond within milliseconds. Therefore, it is crucial for the BESS to carefully decide how much capacity to assign to each market to maximize the total profit under uncertain market conditions. This paper formulates the bidding problem of the BESS as a Markov Decision Process, which enables the BESS to participate in both the spot market and the FCAS market to maximize profit. Then, Proximal Policy Optimization, a model-free deep reinforcement learning algorithm, is employed to learn the optimal bidding strategy from the dynamic environment of the energy market under a continuous bidding scale. The proposed model is trained and validated using real-world historical data of the Australian National Electricity Market. The results demonstrate that our developed joint bidding strategy in both markets is significantly profitable compared to individual markets.},
	booktitle = {2022 {IEEE} {Power} \& {Energy} {Society} {General} {Meeting} ({PESGM})},
	author = {Anwar, Muhammad and Wang, Changlong and de Nijs, Frits and Wang, Hao},
	month = jul,
	year = {2022},
	note = {ISSN: 1944-9933},
	keywords = {Heuristic algorithms, Reinforcement learning, Electricity supply industry, Renewable energy sources, Profitability, Regulation, Markov processes},
	pages = {1--5},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\5VHT5SPC\\Anwar et al. - 2022 - Proximal Policy Optimization Based Reinforcement L.pdf:application/pdf},
}

@inproceedings{mussakhanova_sd-lstm_2020,
	title = {{SD}-{LSTM} {Based} {Demand} {Response} {Framework} for {Prosumer} {Energy} {Management} {Systems}},
	doi = {10.1109/IECON43393.2020.9254615},
	abstract = {Prosumer Energy Management System (PEMS) is the system used for intelligent energy management for a house-hold with on-site photovoltaic (PV) system using the input data from various sources: smart meter, PV management system, a distribution transformer, dispatching unit of a home, real-time pricing from utility provider data center. An efficient PEMS should be able to provide demand response (DR) management in response to the prices, on-site energy generation, and electricity load to contribute to the improvement of overall electricity grid reliability and reduce the costs of a prosumer. This paper presents the Smart PEMS based on two components: seasonal decomposition long short-term memory (SD-LSTM) based forecasting system for predicting electricity prices and PV system energy generation combined with Q-Learning based home appliances scheduler.},
	booktitle = {{IECON} 2020 {The} 46th {Annual} {Conference} of the {IEEE} {Industrial} {Electronics} {Society}},
	author = {Mussakhanova, Meruyert and Kumar Nunna, H. S. V. S. and Srinivasan, Dipti},
	month = oct,
	year = {2020},
	note = {ISSN: 2577-1647},
	keywords = {Home appliances, Forecasting, Reinforcement Learning, Schedules, Smart meters, Market research, LSTM, ANN, Distributed Energy Resources, Logic gates, PEMS, PV forecasting, Scheduling},
	pages = {1998--2003},
}

@inproceedings{thirunavukkarasu_advancing_2023,
	title = {Advancing {Transactive} {Energy} {Market} {Management} using {Community} {Microgrid} {Emulator} that {Supports} {OpenADR} and {Q}-learning {Based} {Auction} {Model}},
	doi = {10.1109/ETFG55873.2023.10407269},
	abstract = {This paper delves into the practical application of transactive energy markets within community microgrids, making use of an innovative openADR-based microgrid emulator for thorough testing and validation. The emulator serves as a crucial conduit between theoretical concepts and real-world deployment, faithfully emulating the intricate behaviors of microgrids. Four distinct scenarios were meticulously examined: "Surplus Energy Selling," involving the return of excess energy to the grid; "Prioritized Community Sharing," which prioritizes local energy consumption within the community; a "Demand Response (DR)" scenario with a 10\% load reduction to explore demand-side management potential; and "Energy Auction model using Q-learning," introducing Q-learning models to optimize energy bidding strategies for efficient distribution within the community. Through rigorous testing in the community microgrid emulator, these scenarios were effectively verified, underscoring the emulator’s adaptability and versatility. This unique combination of advanced simulation and hardware-in-loop testing facilitates the exploration of a wide array of energy market strategies and demand-side management techniques, affirming the practical significance and robustness of community microgrid applications in real-world contexts.},
	booktitle = {2023 {IEEE} {International} {Conference} on {Energy} {Technologies} for {Future} {Grids} ({ETFG})},
	author = {Thirunavukkarasu, Gokul Sidarth and Seyedmahmoudian, Mehdi and Mekhilef, Saad and Stojcevski, Alex},
	month = dec,
	year = {2023},
	keywords = {Q-learning, Transactive energy, Load modeling, Microgrids, Demand response, Adaptation models, Testing, Community Microgrid, Demand side management, Hardware-in-the-Loop Testing, OpenADR, Peer-to-Peer Energy Trading, Q-Learning, Transactive Energy Market},
	pages = {1--6},
}

@inproceedings{matos_machine_2023,
	title = {A {Machine} {Learning} {Based} {Energy} {Management} {System} for {Renewable} {Energy} {Communities}},
	doi = {10.1109/IESES53571.2023.10253701},
	abstract = {Energy systems are under a profound transformation powered by the increasing penetration of renewable energy sources and the decentralization of electricity markets into local communities, in which the prosumer plays a fundamental role. As a result, the creation of Renewable Energy Communities (RECs) is becoming popular, especially in Europe, allowing their members to reduce electricity consumption from non-renewables, as well as to locally produce, store and exchange energy among themselves. This work introduces a REC management system using Artificial Intelligence/Machine Learning (AI/ML) techniques for the electricity consumption forecast. The obtained results of the simulated scheme show that, with the use of these techniques, the system is able to decrease the electricity bill of the REC as well as the energy consumption from the distribution grid.},
	booktitle = {2023 {IEEE} 3rd {International} {Conference} on {Industrial} {Electronics} for {Sustainable} {Energy} {Systems} ({IESES})},
	author = {Matos, Miguel and Almeida, João and Gonçalves, Pedro and Baldo, Fabiano and Braz, Fernando José and Bartolomeu, Paulo},
	month = jul,
	year = {2023},
	keywords = {Tariffs, Europe, Renewable Energy Communities, Renewable energy sources, Production, Machine learning, Energy consumption, Electricity Consumption Forecast, Industrial electronics, Machine Learning},
	pages = {1--6},
	file = {Matos et al. - 2023 - A Machine Learning Based Energy Management System .pdf:C\:\\Users\\Jacob\\Zotero\\storage\\KSEIBHWK\\Matos et al. - 2023 - A Machine Learning Based Energy Management System .pdf:application/pdf},
}

@article{tightiz_resilience_2021,
	title = {Resilience {Microgrid} as {Power} {System} {Integrity} {Protection} {Scheme} {Element} {With} {Reinforcement} {Learning} {Based} {Management}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3087491},
	abstract = {The microgrid is a solution for integrating renewable energy resources into the power system. However, overcoming the randomness of these nature-based resources requires a robust control system. Moreover, electricity market participation and ancillary service provision for the utility grid are other aspects, although intensify microgrid penetration makes its environment interactions more complex. Reinforcement learning is a technique vastly applied to such an intricate environment. Hence, in this paper, we deployed deep deterministic policy gradient and soft-actor critic methods to solve the high-dimensional, continuous, and stochastic problem of the microgrid's energy management system and compared the performance of two methods. Additionally, we developed the microgrid interactions with the utility grid as a participant of system integrity protection schema responding promptly to the utility grid protection requirements based on its reliable available resources. Moreover, we applied actual data of Gasa Island microgrid in Korea to prove the efficiency of proposed method.},
	journal = {IEEE Access},
	author = {Tightiz, Lilia and Yang, Hyosik},
	year = {2021},
	keywords = {Batteries, Uncertainty, Electricity supply industry, Energy management, Microgrids, Energy management system, Energy management systems, soft actor-critic, deep deterministic policy gradient, Power generation, system integrity protection schema},
	pages = {83963--83975},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\PRWWL3QS\\Tightiz and Yang - 2021 - Resilience Microgrid as Power System Integrity Pro.pdf:application/pdf},
}

@inproceedings{dreher_ai_2022-1,
	title = {{AI} agents assessing flexibility: the value of demand side management in times of high energy prices},
	doi = {10.1109/EEM54602.2022.9920982},
	abstract = {High energy and electricity prices, coupled with high price volatility, increase the value of demand response and demand side management. Energy management systems that are predictive and exchange-price oriented can help to leverage flexibility while lowering energy costs. In this paper, the value of flexibility is assessed in two scenarios of low and high energy prices. To that end, a self-learning home energy management system is introduced that takes into account the new volatility of high stock market electricity prices. The proposed approach is compared to a baseline system, which is a typical household self-consumption optimization. The findings indicate a significant economic potential of an exchange-price oriented usage of residential flexibility options in contrast to self-consumption optimization. Furthermore, the value of flexibility for the exemplary residential system increased more than fivefold between 2021 and 2022, while prices increased about fourfold.},
	booktitle = {2022 18th {International} {Conference} on the {European} {Energy} {Market} ({EEM})},
	author = {Dreher, Alexander and Martmann, Lisa Marie and Lehna, Malte and Roelofs, Cyriana and Bergsträßer, Jonathan and Scholz, Christoph and Slaby, Wolfgang and Wetzel, Heike},
	month = sep,
	year = {2022},
	note = {ISSN: 2165-4093},
	keywords = {Electric potential, Costs, Europe, Reinforcement Learning, Demand response, Energy management systems, Energy Management, Demand side management, Demand Side Management, Power System Economics, Stock markets},
	pages = {1--9},
	file = {Dreher et al. - 2022 - AI agents assessing flexibility the value of dema.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\S5QH9TWI\\Dreher et al. - 2022 - AI agents assessing flexibility the value of dema.pdf:application/pdf},
}

@article{rana_modelling_2022,
	title = {Modelling and {Simulation} {Approaches} for {Local} {Energy} {Community} {Integrated} {Distribution} {Networks}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3140237},
	abstract = {Due to the absence of studies of local energy communities (LECs) where the grid is represented, it is very difficult to infer implications of increased LEC integration for the distribution grid as well as for the wider society. Therefore, this paper aims to investigate holistic modelling and simulation approaches of LECs. To conduct a quantifiable assessment of different control architectures, LEC types and market frameworks, a flexible and comprehensive LEC modelling and simulation approach is needed. Modelling LECs and the environment they operate in involves a holistic approach consisting of different layers: market, controller, and grid. The controller layer is relevant both for the overall energy management system of the LEC and the controllers of single components in a LEC. In this paper, the different LEC modelling approaches in the reviewed literature are presented, several multilayered concepts for LECs are proposed, and a case study is presented to illustrate a holistic simulation where the different layers interact.},
	journal = {IEEE Access},
	author = {Rana, Rubi and Berg, Kjersti and Degefa, Merkebu Z. and Löschenbrand, Markus},
	year = {2022},
	keywords = {Optimization, Real-time systems, Biological system modeling, Energy management, Peer-to-peer computing, Microgrids, Distribution networks, Battery energy storage system, community manager, distribution system operator, energy management system, local energy community, photovoltaic, prosumers},
	pages = {3775--3789},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\E5IRIH44\\Rana et al. - 2022 - Modelling and Simulation Approaches for Local Ener.pdf:application/pdf},
}

@article{lu_demand_2019,
	title = {Demand {Response} for {Home} {Energy} {Management} {Using} {Reinforcement} {Learning} and {Artificial} {Neural} {Network}},
	volume = {10},
	issn = {1949-3061},
	doi = {10.1109/TSG.2019.2909266},
	abstract = {Ever-changing variables in the electricity market require energy management systems (EMSs) to make optimal real-time decisions adaptively. Demand response (DR) is the latest approach being used to accelerate the efficiency and stability of power systems. This paper proposes an hour-ahead DR algorithm for home EMSs. To deal with the uncertainty in future prices, a steady price prediction model based on artificial neural network is presented. In cooperation with forecasted future prices, multi-agent reinforcement learning is adopted to make optimal decisions for different home appliances in a decentralized manner. To verify the performance of the proposed energy management scheme, simulations are conducted with non-shiftable, shiftable, and controllable loads. Experimental results demonstrate that the proposed DR algorithm can handle energy management for multiple appliances, minimize user energy bills, and dissatisfaction costs, and help the user to significantly reduce its electricity cost compared with a benchmark without DR.},
	number = {6},
	journal = {IEEE Transactions on Smart Grid},
	author = {Lu, Renzhi and Hong, Seung Ho and Yu, Mengmeng},
	month = nov,
	year = {2019},
	keywords = {Home appliances, Reinforcement learning, Uncertainty, demand response, Load management, reinforcement learning, Artificial intelligence, Decision making, Energy consumption, home energy management, artificial neural network},
	pages = {6629--6639},
	file = {Lu et al. - 2019 - Demand Response for Home Energy Management Using R.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\PHDJHS7G\\Lu et al. - 2019 - Demand Response for Home Energy Management Using R.pdf:application/pdf},
}

@inproceedings{xie_attention_2023,
	title = {Attention {Based} {Multi}-{Agent} {Reinforcement} {Learning} for {Demand} {Response} in {Grid}-{Responsive} {Buildings}},
	doi = {10.1109/CCTA54093.2023.10253019},
	abstract = {Integrating renewable energy resources and deploying energy management devices offer great opportunities to develop autonomous energy management systems in grid-responsive buildings. Demand response can promote enhancing demand flexibility and energy efficiency while reducing consumer costs. In this work, we propose a novel multi-agent deep reinforcement learning (MADRL) based approach to utilize real-time system information to facilitate demand response programs for minimizing electricity costs and efficient load shaping. Achieving real-time autonomous demand response in networks of buildings is challenging due to uncertain system parameters, the dynamic market price, and complex coupled operational constraints. To develop a scalable approach for automated demand response in networks of interconnected buildings, coordination between buildings is necessary to ensure demand flexibility and the grid's stability. We propose a MADRL technique that utilizes an actor-critic algorithm incorporating shared attention mechanism to enable effective real-time coordinated demand response in grid-responsive buildings. The presented case studies demonstrate the ability of the proposed MADRL approach to obtain decentralized cooperative policies without knowledge of building energy systems. The viability of the proposed control approach is also demonstrated by a reduction of over 6\% net load demand compared to state-of-the-art reinforcement learning approaches.},
	booktitle = {2023 {IEEE} {Conference} on {Control} {Technology} and {Applications} ({CCTA})},
	author = {Xie, Jiahan and Ajagekar, Akshay and You, Fengqi},
	month = aug,
	year = {2023},
	note = {ISSN: 2768-0770},
	keywords = {Heuristic algorithms, Reinforcement learning, Costs, Renewable energy sources, demand response, Buildings, Power system stability, buildings, multi-agent reinforcement learning, Uncertain systems},
	pages = {118--123},
}

@inproceedings{li_optimal_2023,
	title = {Optimal {Energy} {Storage} {Scheduling} for {Wind} {Curtailment} {Reduction} and {Energy} {Arbitrage}: {A} {Deep} {Reinforcement} {Learning} {Approach}},
	doi = {10.1109/PESGM52003.2023.10253181},
	abstract = {Wind energy has been rapidly gaining popularity as a means for combating climate change. However, the variable nature of wind generation can undermine system reliability and lead to wind curtailment, causing substantial economic losses to wind power producers. Battery energy storage systems (BESS) that serve as onsite backup sources are among the solutions to mitigate wind curtailment. However, such an auxiliary role of the BESS might severely weaken its economic viability. This paper addresses the issue by proposing joint wind curtailment reduction and energy arbitrage for the BESS. We decouple the market participation of the co-located wind-battery system and develop a joint-bidding framework for the wind farm and BESS. It is challenging to optimize the joint-bidding because of the stochasticity of energy prices and wind generation. Therefore, we leverage deep reinforcement learning to maximize the overall revenue from the spot market while unlocking the BESS’s potential in concurrently reducing wind curtailment and conducting energy arbitrage. We validate the proposed strategy using realistic wind farm data and demonstrate that our joint-bidding strategy responds better to wind curtailment and generates higher revenues than the optimization-based benchmark. Our simulations also reveal that the extra wind generation used to be curtailed can be an effective power source to charge the BESS, resulting in additional financial returns.},
	booktitle = {2023 {IEEE} {Power} \& {Energy} {Society} {General} {Meeting} ({PESGM})},
	author = {Li, Jinhao and Wang, Changlong and Wang, Hao},
	month = jul,
	year = {2023},
	note = {ISSN: 1944-9933},
	keywords = {Reinforcement learning, Deep reinforcement learning, Renewable energy sources, energy arbitrage, Deep learning, Economics, Climate change, Simulation, spot market, wind curtailment., Wind energy, Wind energy generation, wind-battery system},
	pages = {1--5},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\7IQQQNI7\\Li et al. - 2023 - Optimal Energy Storage Scheduling for Wind Curtail.pdf:application/pdf},
}

@inproceedings{soofi_training_2023,
	title = {Training {A} {Deep} {Reinforcement} {Learning} {Agent} for {Microgrid} {Control} using {PSCAD} {Environment}},
	doi = {10.1109/GridEdge54130.2023.10102740},
	abstract = {The accessibility of real-time operational data along with breakthroughs in processing power have promoted the use of Machine Learning (ML) applications in current power systems. Prediction of device failures, meteorological data, system outages, and demand are among the applications of ML in the electricity grid. In this paper, a Reinforcement Learning (RL) method is utilized to design an efficient energy management system for grid-tied Energy Storage Systems (ESS). We implement a Deep Q-Learning (DQL) approach using Artificial Neural Networks (ANN) to design a microgrid controller system simulated in the PSCAD environment. The proposed on-grid controller coordinates the main grid, aggregated loads, renewable generations, and Advanced Energy Storage (AES). To reduce the cost of operating AESs, the designed controller takes the hourly energy market price into account in addition to physical system characteristics.},
	booktitle = {2023 {IEEE} {PES} {Grid} {Edge} {Technologies} {Conference} \& {Exposition} ({Grid} {Edge})},
	author = {Soofi, Arash Farokhi and Bayani, Reza and Yazdanibiouki, Mehrdad and Manshadi, Saeed D.},
	month = apr,
	year = {2023},
	keywords = {Q-learning, Real-time systems, Reinforcement learning, Training, Renewable energy sources, Microgrids, Artificial neural network, Artificial neural networks, Deep Q-learning, Distributed energy resources, Distributed power generation, Microgrid energy management system},
	pages = {1--5},
}

@inproceedings{aklo_reinforcement_2021,
	title = {Reinforcement {Learning} {Based} {Energy} {Storage} {Units} {Scheduling} {Considering} {Point} of {Common} {Coupling} {Constraint}},
	doi = {10.1109/ISMEE54273.2021.9774197},
	abstract = {In this paper, agent-aggregators cooperation has been introduced in Smart Microgrid (SMG) consisting of household users, Photo Voltaic array (PV), and Local Energy Storage System (LESS). The SMG has Energy Management System called agent deal with two aggregators to purchase the energy for the consumers. Each aggregator supplying a limited level of energy from different energy resource, where one aggregator depend on Community Energy storage System to provide power in one direction to the users and the other aggregator supplying power from the utility grid. The job of the agent is to decide the optimum amount of purchasing power from the aggregators at the lowest cost to supply the users and to charge the LESS taking into account the constraints of supplying limitations for both CESS and utility grid at Point of Common Coupling. Each aggregator supplies a limited level of energy from different energy resource, where one aggregator depend on the Community Energy storage System (CESS) to provide power in one direction to the users and the other aggregator supplying power from the utility grid. The job of the agent is to decide the optimum amount of purchasing power from the aggregators at the lowest cost to provide the users and to charge the LESS taking into account the constraints of providing limitations for both CESS and utility grid at Point of Common Coupling (PCC).A model-free Reinforcement Learning (RL) method is used as an essential strategy to achieve the proposed task using Deep Q-Network (DQN). The simulation result is done and the results are verified using Improved Particular Swarm (IPSO) as a benchmark method. The obtained results show the efficiency and effectiveness of the method used},
	booktitle = {2021 3rd {International} {Symposium} on {Material} and {Electrical} {Engineering} {Conference} ({ISMEE})},
	author = {Aklo, Nabil Jalil and Turky Rashid, Mofeed},
	month = nov,
	year = {2021},
	keywords = {Reinforcement learning, Uncertainty, Tariffs, Costs, reinforcement learning, aggregator, Benchmark testing, community energy storage system, Couplings, deep q-network, Energy resources, local energy storage system, smart microgrid},
	pages = {1--8},
}

@article{sangoleye_reinforcement_2023,
	title = {Reinforcement {Learning}-{Based} {Demand} {Response} {Management} in {Smart} {Grid} {Systems} {With} {Prosumers}},
	volume = {17},
	issn = {1937-9234},
	doi = {10.1109/JSYST.2023.3248320},
	abstract = {In this article, we introduce a reinforcement learning-based price-driven demand response management (DRM) mechanism in smart grid systems consisting of prosumers. Our proposed approach accounts for the prosumers' behavioral characteristics and models the emerging interactions among all the involved actors in the smart grid system, i.e., prosumers, energy management system (EMS), and utility companies. In particular, an off-policy reinforcement learning is introduced enabling the EMS to determine the optimal price that should be announced to the prosumers on an hourly-basis toward minimizing the overall system's cost. In this process, the utility companies' hourly-based wholesale price and the prosumers' energy generation and consumption characteristics are considered as input. At the same time, the prosumers' optimal amount of purchased energy is determined in a real-time manner. The presented numerical results demonstrate the success of the proposed DRM model to deal with the incomplete information availability scenarios, regarding the prosumers' energy selling and purchasing patterns, compared to the state of the art. Also, the detailed comparative evaluation against other price-based DRM approaches, e.g., cap-based and day-ahead pricing, shows the benefits of the proposed DRM model in terms of adapting in a real-time manner to the prosumers' energy demand, while jointly minimizing the overall system's long-term cost.},
	number = {2},
	journal = {IEEE Systems Journal},
	author = {Sangoleye, Fisayo and Jao, Jenilee and Faris, Kimberly and Tsiropoulou, Eirini Eleni and Papavassiliou, Symeon},
	month = jun,
	year = {2023},
	keywords = {Reinforcement learning, Smart grids, Energy management, Costs, reinforcement learning, Games, Energy consumption, Companies, Decision-making, prosumers, demand response management (DRM), smart grid systems, system modeling},
	pages = {1797--1807},
}

@inproceedings{thattai_consumer-centric_2023,
	title = {Consumer-{Centric} {Home} {Energy} {Management} {System} {Using} {Trust} {Region} {Policy} {Optimization}- {Based} {Multi}-{Agent} {Deep} {Reinforcement} {Learning}},
	doi = {10.1109/PowerTech55446.2023.10202803},
	abstract = {Autonomous home energy management system (HEMS) is the key to improving energy efficiency in the active distribution network. This HEMS also needs to maintain customer satisfaction while maximizing cost savings under dynamic price conditions, incorporating uncertainties of consumer behavior, and renewable energy generation. In this paper, a consumer-centric HEMS using Trust Region Policy Optimization (TRPO) based multi-agent deep reinforcement learning (DRL) is presented. This Multi-Agent TRPO (MA- TRPO) based HEMS is trained to respond to the dynamic retail price and the local energy generation by scheduling the Interruptible-Deferrable load (IDA) and Battery Energy Storage System (BESS). Five-minute retail electricity price derived from wholesale market price and the PV generation data derived from real-world PV profiles are used to train the proposed MA- TRPO-based HEMS in discrete action space. The performance of the proposed HEMS is relatively better than the existing policy-gradient-based on-policy approaches such as Proximal Policy Optimization and Policy Gradient-based HEMS as validated via training and testing using the same dataset.},
	booktitle = {2023 {IEEE} {Belgrade} {PowerTech}},
	author = {Thattai, Kuthsav and Ravishankar, Jayashri and Li, Chaojie},
	month = jun,
	year = {2023},
	keywords = {Reinforcement learning, Deep reinforcement learning, Uncertainty, Training, Costs, Deep learning, Dynamic scheduling, Energy Management System, Multi-Agent, Smart Home, Trust region policy optimization, Washing machines},
	pages = {1--6},
	file = {Thattai et al. - 2023 - Consumer-Centric Home Energy Management System Usi.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\PWRDCNYM\\Thattai et al. - 2023 - Consumer-Centric Home Energy Management System Usi.pdf:application/pdf},
}

@inproceedings{ashenov_dynamic_2021,
	title = {Dynamic {Cloud} and {ANN} based {Home} {Energy} {Management} {System} for {End}-{Users} with {Smart}-{Plugs} and {PV} {Generation}},
	doi = {10.1109/TPEC51183.2021.9384980},
	abstract = {Over the past decades, the importance of energy management has been raised due to increasing electricity demand and consumers' unawareness of their electricity consumption. The paper proposes a Home Energy Management System (HEMS) that implements an Artificial Neural Network (ANN) and reinforcement learning-based algorithm to schedule the home appliances as well as an optimized and efficient way of profiting from renewable energy source with the utilization of energy storage systems. The objective of the HEMS is to decrease energy cost, customer dissatisfaction, and grid overloading. Two types of appliances were considered: non-shiftable controllable, shiftable interruptible. A simulation of the case study where the forecasted values were fed to the HEMS algorithm demonstrated a total profit increase by 15\% due to the renewable energy source, making the value of total profit 63.5 units in one day. The simulation was done for a single house loading profile and throughout the capacity change of the energy storage system, a maximum profit was derived. These results show the efficient function of HEMS with the utilization of the proposed ANN, reinforcement learning, and energy decision algorithm.},
	booktitle = {2021 {IEEE} {Texas} {Power} and {Energy} {Conference} ({TPEC})},
	author = {Ashenov, Nursultan and Myrzaliyeva, Madina and Mussakhanova, Meruyert and Nunna, H. S. V. S. Kumar},
	month = feb,
	year = {2021},
	keywords = {Home appliances, Reinforcement learning, Renewable energy sources, Load modeling, Demand response, Schedules, Energy storage, Artificial neural network, Artificial neural networks, Energy management systems, Home energy management, Smart Plug, Solar energy management},
	pages = {1--6},
}

@inproceedings{ochoa_efficient_2022,
	title = {Efficient {Bidding} of a {PV} {Power} {Plant} with {Energy} {Storage} {Participating} in {Day}-{Ahead} and {Real}-{Time} {Markets} {Using} {Artificial} {Neural} {Networks}},
	doi = {10.1109/PESGM48719.2022.9916732},
	abstract = {This paper proposes the use of Artificial Neural Networks (ANN) for the efficient bidding of a Photovoltaic power plant with Energy Storage System (PV-ESS) participating in Day-Ahead (DA) and Real-Time (RT) energy and reserve markets under uncertainty. The Energy Management System (EMS) is based on Multi-Agent Deep Reinforcement Learning (MADRL). The MADRL scheme aims to maximize the profit of the hybrid PV-ESS plant through an efficient bidding in both markets. Results show that the MADRL framework can fulfill both the financial and physical constraints faced by the PV-ESS plant while providing energy and ancillary services. Daily market incomes have comparable mean values regarding traditional optimization approaches (average value of 1839 USD), but with a 45.3\% smaller variance. Furthermore, it maintains a reference-tracking performance of 86.63\% for one-year-round participation, against a 73.05\% and 79.13\% performance obtained with scenario-based robust and stochastic programming implementations, respectively.},
	booktitle = {2022 {IEEE} {Power} \& {Energy} {Society} {General} {Meeting} ({PESGM})},
	author = {Ochoa, Tomás and Gil, Esteban and Angulo, Alejandro},
	month = jul,
	year = {2022},
	note = {ISSN: 1944-9933},
	keywords = {multi-agent deep reinforcement learning, Real-time systems, Reinforcement learning, Uncertainty, Stochastic processes, Artificial neural networks, energy storage, electricity markets, Photovoltaic systems, energy management system, Programming, solar generation},
	pages = {1--5},
	file = {Ochoa et al. - 2022 - Efficient Bidding of a PV Power Plant with Energy .pdf:C\:\\Users\\Jacob\\Zotero\\storage\\FSRQ2PV4\\Ochoa et al. - 2022 - Efficient Bidding of a PV Power Plant with Energy .pdf:application/pdf},
}
