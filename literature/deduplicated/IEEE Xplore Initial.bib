
@inproceedings{gong_reinforcement_2023,
	title = {Reinforcement {Learning} {Enabled} {Real}-{Time} {Energy} {Dispatch} of {Energy} {Systems} with {Flexible} {Operational} {Resources}},
	doi = {10.1109/AIKIIE60097.2023.10390385},
	abstract = {This paper developed a reinforcement learning- enabled real-time energy dispatch solution for energy systems with flexible operational resources. The detailed process of the proposed solution is formulated and implemented. The deep reinforcement learning method is introduced to solve the action strategy of the energy storage system and the controllable generator. Specifially, this work developed a reinforcement learning-enabled real-time energy dispatch solution for energy systems considering the presence of flexible operational resources. For the real-time scheduling phase, the timing decision problem of real-time scheduling is designed to maintain the stability of the trading curve. The deep reinforcement learning algorithm is designed and adopted to identify the action strategy of the energy storage system and the controllable generator. The proposed solution is evaluated through a case study via simulations and the numerical results confirmed the effectiveness of the proposed real-time energy dispatch solution for multi-energy systems.},
	booktitle = {2023 {International} {Conference} on {Ambient} {Intelligence}, {Knowledge} {Informatics} and {Industrial} {Electronics} ({AIKIIE})},
	author = {Gong, Liwu and Huang, Yuehua and Zhang, Wei and Gu, Yixing and Chen, Chao},
	month = nov,
	year = {2023},
	keywords = {Optimization, Real-time systems, Reinforcement learning, Reinforcement Learning, Deep learning, Generators, Control systems, Day-Ahead Energy Planning, Job shop scheduling, Multi-Energy Systems, Stability analysis},
	pages = {1--6},
	file = {Gong et al. - 2023 - Reinforcement Learning Enabled Real-Time Energy Di.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\DEL4RFMN\\Gong et al. - 2023 - Reinforcement Learning Enabled Real-Time Energy Di.pdf:application/pdf},
}

@inproceedings{gao_poster_2022,
	title = {Poster {Abstract}: {Residential} {Energy} {Management} {System} {Using} {Personalized} {Federated} {Deep} {Reinforcement} learning},
	doi = {10.1109/IPSN54338.2022.00071},
	abstract = {The trend of Internet of Things is bringing in millions of new smart devices into homes to increase the quality of human life. However, this enormous number of new devices have also brings in an increasing energy consumption in standby for awaiting wire-less communication or status change. To reduce standby energy, existing approaches use real-time consumption data and machine learning techniques to identify standby energy, but aggregate data or intermediate model training updates in the cloud to collaboratively perform load forecasting, which could directly or indirectly cause personal data leakage, alongside with significant communication bandwidth and extra cloud service monetary cost. On the other hand, such a global collaborative model yields unsatisfactory en-ergy management performance as they fail to capture the diversity of each residence. In this paper, we propose a privacy-preserved, communication-efficient, personalized and cloud-service-free resi-dential energy management system (EMS) with personalized feder-ated deep reinforcement learning (PFDRL) framework to tackle the standby energy reduction in residential building.},
	booktitle = {2022 21st {ACM}/{IEEE} {International} {Conference} on {Information} {Processing} in {Sensor} {Networks} ({IPSN})},
	author = {Gao, Jiechao and Wang, Wenpeng and Campbell, Bradford},
	month = may,
	year = {2022},
	keywords = {Real-time systems, Reinforcement learning, Predictive models, Training, Cloud computing, Market research, Performance evaluation},
	pages = {541--542},
}

@inproceedings{selim_optimal_2022,
	title = {Optimal {Scheduled} {Control} {Operation} of {Battery} {Energy} {Storage} {System} using {Model}-{Free} {Reinforcement} {Learning}},
	doi = {10.1109/iSPEC54162.2022.10033035},
	abstract = {Driven by the tremendous increase in rooftop solar panels and battery installations in Australian states, several studies have been conducted to efficiently manage battery operations with the imported grid power through battery energy storage systems (BESS). Therefore, it is crucial for the BESS to carefully decide the power set-points of the installed batteries to maintain user comfort while operating household appliances. Additionally, BESS should be capable of reducing the electricity bills by optimally managing the battery operation to sustain times of higher tariff prices for the imported grid power. This paper formulates the scheduled operation of the BESS as a Markov decision Process (MDP) that enables the BESS to Figure out numerous scenarios and decides the optimal power set-points for both batteries and grid power. A model-free reinforcement learning approach is proposed to manage the batteries’ power-sharing and grid operation set-points to solve this MDP problem. This approach utilizes the advantages of the Deep Deterministic Policy Gradient (DDPG) algorithm to decide the shared power set-points every 5 minutes interval for the day ahead operation of the BESS. Finally, the proposed model is trained and validated using historical data of the Australian National Electricity market to offer an optimal scheduled control pattern for the daily BESS operations.},
	booktitle = {2022 {IEEE} {Sustainable} {Power} and {Energy} {Conference} ({iSPEC})},
	author = {Selim, Alaa},
	month = dec,
	year = {2022},
	keywords = {Pricing, Reinforcement learning, Optimal scheduling, Tariffs, Training, Battery energy storage system, Control optimization, Model-free, Optimal control, Power sharing, State of charge, Supercomputers},
	pages = {1--5},
	file = {Selim - 2022 - Optimal Scheduled Control Operation of Battery Ene.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\X6TBK9SI\\Selim - 2022 - Optimal Scheduled Control Operation of Battery Ene.pdf:application/pdf},
}

@inproceedings{basso_battery_2023,
	title = {Battery {Energy} {Storage} {Control} {Using} {Reinforcement} {Learning}},
	doi = {10.1109/IFEEC58486.2023.10458579},
	abstract = {With the increasing adoption of solar PV installations in Australian households, the availability of cheap renewable power during the day has surged. However, the challenge lies in rising electricity prices during morning and evening peak-consumption times. This project assessed the feasibility and profitability of using a Reinforcement Learning (RL) controller in a Battery Energy Storage System (BESS) to make cost-effective decisions by purchasing power when it's inexpensive and selling when it's costly. MATLAB/Simulink is used to create a BESS simulation model integrated into the electricity market, with the RL agent trained using normalized observation data and a reward function. Benchmarking demonstrated the RL controller's consistent outperformance of the timer-based controller in various market scenarios, emphasizing its adaptability and profitability advantages, particularly in volatile markets.},
	booktitle = {2023 {IEEE} {International} {Future} {Energy} {Electronics} {Conference} ({IFEEC})},
	author = {Basso, Elliott and Du, Yang},
	month = nov,
	year = {2023},
	keywords = {Reinforcement learning, Mathematical models, Electricity supply industry, Reinforcement Learning, Renewable energy sources, Profitability, Battery Energy Storage System, Energy consumption, Fluctuations, Matlab/Simulink},
	pages = {1--5},
	file = {Basso and Du - 2023 - Battery Energy Storage Control Using Reinforcement.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\DFIK6QT2\\Basso and Du - 2023 - Battery Energy Storage Control Using Reinforcement.pdf:application/pdf},
}

@inproceedings{he_interval_2023,
	title = {Interval {Multi}-{Objective} {Optimization} {Combined} with {Deep} {Reinforcement} {Learning} for {Building} {Energy} {Management} {System}},
	doi = {10.1109/ICPSAsia58343.2023.10294566},
	abstract = {To fully tap and effectively use the potential of building energy conservation and emission reduction, a low-carbon optimization dispatch method for intelligent buildings based on deep reinforcement learning interval multi-objective optimization is proposed. Firstly, interval mathematics is used to model the multiple uncertainties in the system. Secondly, considering the system's carbon emissions and carbon transaction costs, optimize the system operation with the goal of the lowest comprehensive operating cost and the best user comfort. To solve the problem of interval multi-objective optimization, deep reinforcement learning (DQN) and interval multi-objective particle swarm optimization (IMOPSO) are proposed for “offline training” and “online guidance”. The low-carbon optimization scheduling problem of intelligent buildings under multiple uncertain factors is efficiently solved. The results of an example show that the proposed IMOPSO based on DQN can consider the system's low carbon, economical and user comfort, which effectively improves the system's ability to deal with multiple uncertain factors.},
	booktitle = {2023 {IEEE}/{IAS} {Industrial} and {Commercial} {Power} {System} {Asia} ({I}\&{CPS} {Asia})},
	author = {He, Ziyin and Hou, Hui and Lu, Yanchao and Yang, Jie},
	month = jul,
	year = {2023},
	keywords = {Reinforcement learning, Uncertainty, Training, Costs, deep reinforcement learning, Deep learning, Carbon dioxide, carbon trading, intelligent building, interval multi-objective optimization, Systems operation, uncertainty},
	pages = {2012--2017},
}

@article{giglio_efficient_2023,
	title = {An {Efficient} {Artificial} {Intelligence} {Energy} {Management} {System} for {Urban} {Building} {Integrating} {Photovoltaic} and {Storage}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3247636},
	abstract = {The emerging leading role of green energy in our society pushes the investigation of new economic and technological solutions. Green energies and smart communities increase efficiency with the use of digital solutions for the benefits of inhabitants and companies. The paper focuses on the development of a methodology for the energy management, combining photovoltaics and storage systems, considering as the main case study a multi-story building characterized by a high density of households, used to generate data which allow feasibility foresights. The physical model of the algorithm is composed by two main elements: the photovoltaics modules and the battery energy storage system. In addition, to gain information about the real-time consumption a machine learning module is included in our approach to generate predictions about the near future demand. The benefits provided by the method are evaluated with an economic analysis, which computes the return of the investment using the real consumptions of a Boarding School, located in Turin (Italy). The case study analyzed in this article showed an increase in purchased energy at the minimum price from 25\% to 91\% and a 55\% reduction in the electricity bill compared to most solutions on the market, with no additional costs and a stabilizing effect on the grid. Finally, the economic analysis shows that the proposed method is a profitable investment, with a breakeven point of thirteen years, due to the very simple implementation and the zero additional cost requested.},
	journal = {IEEE Access},
	author = {Giglio, Enrico and Luzzani, Gabriele and Terranova, Vito and Trivigno, Gabriele and Niccolai, Alessandro and Grimaccia, Francesco},
	year = {2023},
	keywords = {Smart grids, Forecasting, Renewable energy sources, Deep learning, Buildings, Energy storage, energy storage, energy management systems, Computer architecture, environmental economics, Photovoltaic systems, renewable energy sources},
	pages = {18673--18688},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\GEZVWBGK\\Giglio et al. - 2023 - An Efficient Artificial Intelligence Energy Manage.pdf:application/pdf},
}

@article{li_attentive_2024,
	title = {Attentive {Convolutional} {Deep} {Reinforcement} {Learning} for {Optimizing} {Solar}-{Storage} {Systems} in {Real}-{Time} {Electricity} {Markets}},
	volume = {20},
	issn = {1941-0050},
	doi = {10.1109/TII.2024.3352229},
	abstract = {This article studies the synergy of solar-battery energy storage system (BESS) and develops a viable strategy for the BESS to unlock its economic potential by serving as a backup to reduce solar curtailments while also participating in the electricity market. We model the real-time bidding of the solar-battery system as two Markov decision processes for the solar farm and the BESS, respectively. We develop a novel deep reinforcement learning (DRL) algorithm to solve the problem by leveraging attention mechanism (AC) and multigrained feature convolution to process DRL input for better bidding decisions. Simulation results demonstrate that our AC-DRL outperforms two optimization-based and one DRL-based benchmarks by generating 23\%, 20\%, and 11\% higher revenue, as well as improving curtailment responses. The excess solar generation can effectively charge the BESS to bid in the market, significantly reducing solar curtailments by 76\% and creating synergy for the solar-battery system to be more viable.},
	number = {5},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Li, Jinhao and Wang, Changlong and Wang, Hao},
	month = may,
	year = {2024},
	keywords = {Optimization, Real-time systems, Batteries, Electricity supply industry, Battery energy storage system (BESS), deep reinforcement learning (DRL), Degradation, electricity market, Nanoelectromechanical systems, solar curtailment, solar photovoltaic (PV), Solar power generation},
	pages = {7205--7215},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\BKIHFRJZ\\Li et al. - 2024 - Attentive Convolutional Deep Reinforcement Learnin.pdf:application/pdf},
}

@article{nunna_multiagent-based_2020,
	title = {Multiagent-{Based} {Energy} {Trading} {Platform} for {Energy} {Storage} {Systems} in {Distribution} {Systems} {With} {Interconnected} {Microgrids}},
	volume = {56},
	issn = {1939-9367},
	doi = {10.1109/TIA.2020.2979782},
	abstract = {In this article, an agent-based transactive energy (TE) trading platform to integrate energy storage systems (ESSs) into the microgrids' energy management system is proposed. Using this platform, two different types of energy storage market models are proposed to promote local-level (within the microgrid) and communal- or global-level ESSs' participation in the intra- and intermicrogrid TE markets. Also, a reinforcement learning algorithm known as simulated-annealing-based Q-learning is used to develop bidding strategies for ESSs to participate in the TE markets. Besides energy trading, the proposed system also accounts for the losses caused by energy transactions between ESSs and microgrids using a complex current-tracing-based loss allocation method. The overall efficacy of the proposed energy market management system is demonstrated using a modified IEEE 123-bus distribution system with multiple microgrids and ESSs. Based on simulation results, it is observed that the proposed model can effectively reinforce the balance between the supply and the demand in the microgrids using the mix of local and global ESSs.},
	number = {3},
	journal = {IEEE Transactions on Industry Applications},
	author = {Nunna, H. S. V. S. Kumar and Sesetti, Anudeep and Rathore, Akshay Kumar and Doolla, Suryanarayana},
	month = may,
	year = {2020},
	keywords = {Biological system modeling, Energy management, Peer-to-peer computing, Load modeling, Microgrids, Electricity markets, Energy storage, energy storage systems (ESSs), Generators, microgrids, multiagent systems, transactive energy (TE)},
	pages = {3207--3217},
}

@article{zheng_power_2024,
	title = {Power {Demand} {Reshaping} {Using} {Energy} {Storage} for {Distributed} {Edge} {Clouds}},
	volume = {35},
	issn = {1558-2183},
	doi = {10.1109/TPDS.2023.3347774},
	abstract = {The booming edge computing market that is supported by the edge cloud (EC) infrastructure has brought huge operating costs, mainly the energy cost, to edge service providers. The energy cost in form of electricity bills usually consists of energy charge and demand charge, and the demand charge based on peak power may account for a large proportion of the energy cost given a significant fluctuating power curve. In this work, we investigate the backup battery characteristics and electricity charge tariffs at ECs and explore the corresponding cost-saving potential. Specifically, we transform the backup battery group into distributed battery energy storage system (BESS) and strategically schedule the BESS to minimize the energy cost of service providers. We then propose a deep reinforcement learning (DRL) based approach to BESS charging/discharging in coping with the dynamic power demand and BESS state at each EC. To enable better decision-making and speed up agent training, we further design the customized invalid action masking (IAM) method and apply the prioritized experience replay (PER) scheme. The experiment results based on real-world EC power traces show that the proposed approach can reduce the demand charge and overall electricity bill by up to 27\% and 13\%, respectively.},
	number = {2},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Zheng, Dongyu and Liu, Lei and Tang, Guoming and Wang, Yi and Li, Weichao},
	month = feb,
	year = {2024},
	keywords = {Real-time systems, Batteries, Tariffs, Costs, Energy storage, energy storage, Power demand, edge computing, Demand charge, distributed BESS, power shaving, Uninterruptible power systems},
	pages = {362--376},
}

@article{mashlakov_probabilistic_2020,
	title = {Probabilistic {Forecasting} of {Battery} {Energy} {Storage} {State}-of-{Charge} under {Primary} {Frequency} {Control}},
	volume = {38},
	issn = {1558-0008},
	doi = {10.1109/JSAC.2019.2952195},
	abstract = {Multi-service market optimization of battery energy storage system (BESS) requires assessing the forecasting uncertainty arising from coupled resources and processes. For the primary frequency control (PFC), which is one of the highest-value applications of BESS, this uncertainty is linked to the changes of BESS state-of-charge (SOC) under stochastic frequency variations. In order to quantify this uncertainty, this paper aims to exploit one of the recent achievements in the field of deep learning, i.e. multi-attention recurrent neural network (MARNN), for BESS SOC forecasting under PFC. Furthermore, we extend the MARNN model for probabilistic forecasting with a hybrid approach combining Mixture Density Networks and Monte Carlo dropout that incorporate the uncertainties of the data noise and the model parameters in the form of prediction interval (PI). The performance of the model is studied on BESS SOC datasets that are simulated based on real frequency measurements from three European synchronous areas in Great Britain, Continental Europe, and Northern Europe and validated by three PI evaluation indexes. Compared with the state-of-the-art quantile regression algorithms, the proposed hybrid model performed well with respect to the coverage probability of PIs for the different regulatory environments of the PFC.},
	number = {1},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Mashlakov, Aleksei and Lensu, Lasse and Kaarna, Arto and Tikka, Ville and Honkapuro, Samuli},
	month = jan,
	year = {2020},
	keywords = {Batteries, Forecasting, Predictive models, Uncertainty, Frequency control, Attention-based neural network, battery energy storage system (BESS), Data models, frequency control, mixture density networks, Monte Carlo dropout, prediction intervals, probabilistic forecasting, Probabilistic logic, state-of-charge (SOC)},
	pages = {96--109},
	file = {Accepted Version:C\:\\Users\\Jacob\\Zotero\\storage\\K9GGJV7Z\\Mashlakov et al. - 2020 - Probabilistic Forecasting of Battery Energy Storag.pdf:application/pdf},
}

@inproceedings{atias_opportunities_2023,
	title = {Opportunities and {Challenges} of {Using} {Artificial} {Intelligence} in {Energy} {Communities}},
	doi = {10.1109/ICAI58806.2023.10339026},
	abstract = {Energy communities are legal entities that produce, store, and sell renewable energy (RE) while also exchanging it inside the community via the public grid. They provide economic, environmental, and social advantages to the community, but they also confront enormous obstacles in anticipating, managing, and participating in energy markets. This paper explores the potential of artificial intelligence (AI) in addressing the challenges faced by energy communities. AI techniques, including machine learning (ML), deep learning (DL), fuzzy logic (FL), neural networks (NNs), and genetic algorithms (GAs), can enhance forecasting, optimization, and control of renewable energy sources (RES) and demand within energy communities. The paper discusses the concept of energy communities, the role of AI, and its applications in predicting energy generation, optimizing grid operations, managing energy storage, controlling devices, and facilitating energy trading. However, barriers such as data availability, costs, ethics, regulations, and skills gaps hinder AI adoption. Overcoming these barriers requires policy development, collaboration, data security, ethical AI use, and education. According to the research, AI could assist energy communities in developing a more sustainable and resilient energy system.},
	booktitle = {2023 {International} {Conference} {Automatics} and {Informatics} ({ICAI})},
	author = {Atias, Vitali},
	month = oct,
	year = {2023},
	keywords = {forecasting, Renewable energy sources, Regulation, Artificial intelligence, machine learning, artificial intelligence, renewable energy, Collaboration, energy communities, Ethics, Fuzzy logic, Technological innovation},
	pages = {508--513},
}

@article{liang_robust_2024,
	title = {Robust {Vehicle}-to-{Grid} {Energy} {Trading} {Method} {Based} on {Smart} {Forecast} and {Multi}-{Blockchain} {Network}},
	volume = {12},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2024.3352631},
	abstract = {In the present era, energy issues are a significant concern, and the energy trading market is the crucial sector to facilitate supply-demand balance and sustainable development. For better demand response and grid balancing, vehicle-to-grid (V2G) technology is rapidly gaining importance in energy markets. To narrow the gap between ideal V2G goals and actual applications needs, energy trading system has to overcome the challenges of over-centralized structure, inflexible timeline adaptation, limited market scale and energy efficiency, excessive feedback time costs, and low rate of economic return. To address these issues and ensure a secure energy market, we propose a decentralized intelligent V2G system called V2G Forecasting and Trading Network (V2GFTN) to achieve efficient and robust energy trading in campus EV networks. A multiple blockchain structure is proposed in V2GFTN to ensure trading security and data privacy between energy requests and offers. V2GFTN also integrates energy forecasting functions for EVs with a smart energy trading and EV allocation mechanism called SRET so that the EVs with driving tasks can supply their extra power back to the grid and achieve higher energy efficiency and economic profit. Through rigorous experimentation and compared with equivalent studies, V2GFTN system has demonstrated higher economic profit and energy demand fill rate by up to 1.6 times and 1.9 times than the state-of-the-art V2G approaches.},
	journal = {IEEE Access},
	author = {Liang, Yuxiao and Wang, Zhishang and Abdallah, Abderazek Ben},
	year = {2024},
	keywords = {Vehicle dynamics, Forecasting, Energy management, Costs, Task analysis, Economics, Vehicle-to-grid, Blockchains, Emissions trading, energy forecast, Energy trading, multi-blockchain, vehicle-to-grid},
	pages = {8135--8153},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\LKCGUZY8\\Liang et al. - 2024 - Robust Vehicle-to-Grid Energy Trading Method Based.pdf:application/pdf},
}

@inproceedings{cao_mappo-based_2023,
	title = {{MAPPO}-based {Energy} {Trading} in {Intelligent} {Community} with {Double} {Auction}},
	doi = {10.1109/ICC45041.2023.10279659},
	abstract = {With the development of electronic information technology, trading between different homes has been possible. In this paper, we investigate the energy optimization problem among multiple homes in a intelligent community, and introduce a double auction method for guiding them to trade energy. Each home is equipped with an energy storage system (ESS), an electric vehicle (EV) and load, and connected to the renewable energy and the power grid. The EV operates as an energy producer and consumer to help home energy management system (HEMS) flexibly regulate the power balance. To facilitate trading between homes and reduce the total cost of the system, we introduce a double auction (DA) market among homes, which can also protect their privacy. We formulate this problem as a partially observable markov decision process (POMDP) and propose a DA-based multi-agent proximal policy optimization (DA-MAPPO) algorithm, which solves the problem of sequential decisions and dimensional disasters. The simulations show that the model proposed can reduce the total system cost by 14.8\% compared with the model without DA market. The proposed algorithm can improve the motivation of homes to participate in the DA market and protect their privacy compared with other algorithms.},
	booktitle = {{ICC} 2023 - {IEEE} {International} {Conference} on {Communications}},
	author = {Cao, Ruoshi and Chen, Ming and Zhang, Guanglin},
	month = may,
	year = {2023},
	note = {ISSN: 1938-1883},
	keywords = {energy trading, Privacy, Costs, Renewable energy sources, Regulation, Markov processes, Power grids, double auction, home energy management, Information technology, multi-agent proximal policy optimization},
	pages = {4119--4124},
}

@inproceedings{kasi_comprehensive_2023,
	title = {A {Comprehensive} {Investigation} of {Optimal} {Sizing} of {Hybrid} {Renewable} {Energy} {Resources} for {Micro} {Distributed} {Systems}},
	doi = {10.1109/NEleX59773.2023.10421117},
	abstract = {Renewable Energy Sources (RES) are rapidly increasing for the generation of electrical power due to the high demand for green electrical power and reduced dependency on conventional energy resources. Using the RES is considered to be crucial as they are scalable, eco-friendly, abundant in nature, and can be applied in different applications, such as residential, agriculture, commercial, and industrial areas. It can increase the system's reliability and thus reduce the cost of energy generation. However, the RES demonstrate inadequate load following and are not transportable. This issue can be overcome by implementing a microgrid system that is used to generate, transfer, and store electricity economically and efficiently. The Hybrid Renewable System (HRS) integrated with a microgrid system is considered to be a promising energy source and it is feasible. The primary objective of HRS is an enhancement of aspects to resolve the issues related to optimal sizing of HRS components by considering load supply incessantly. Considering the growing importance of such HRS and the increasing number of research activities, a Systematic Literature Review (SLR) is conducted to investigate the research based on optimal sizing of HRS integrated microgrid distributed generation with a focus on techno-economic reliability. This SLR reveals the articles published during 2019 to 2023. Through the SLR, the features of traditional methods, hybrid algorithms, and Artificial Intelligence (AI) based techniques are assessed and address the recent trends and development of optimal sizing of the HRS integrated microgrid distributed generation.},
	booktitle = {2023 {International} {Conference} on {Next} {Generation} {Electronics} ({NEleX})},
	author = {Kasi, Shanmuganatha Vadivel and Das, Narottam and Alahakoon, Sanath and Hassan, Nur},
	month = dec,
	year = {2023},
	keywords = {Energy management, Renewable energy sources, Artificial intelligence, Microgrids, Market research, Energy Management, Artificial Intelligence (AI), Distributed Generation, Energy resolution, Microgrids (MGs), Optimal Sizing, Power Generation, Reliability, Renewable Energy Sources (RES)},
	pages = {1--7},
}

@inproceedings{rezazadeh_federated_2022,
	title = {A {Federated} {DRL} {Approach} for {Smart} {Micro}-{Grid} {Energy} {Control} with {Distributed} {Energy} {Resources}},
	doi = {10.1109/CAMAD55695.2022.9966919},
	abstract = {The prevalence of the Internet of things (IoT) and smart meters devices in smart grids is providing key support for measuring and analyzing the power consumption patterns. This approach enables end-user to play the role of prosumers in the market and subsequently contributes to diminish the carbon footprint and the burden on utility grids. The coordination of trading surpluses of energy that is generated by house renewable energy resources (RERs) and the supply of shortages by external networks (main grid) is a necessity. This paper proposes a hierarchical architecture to manage energy in multiple smart buildings leveraging federated deep reinforcement learning (FDRL) with dynamic load in a distributed manner. Within the context of the developed FDRL-based framework, each agent that is hosted in local building energy management systems (BEMS) trains a local deep reinforcement learning (DRL) model and shares its experience in the form of model hyperparameters to the federation layer in the energy management system (EMS). Simulation studies are conducted using one EMS and up to twenty smart houses that are equipped with photovoltaic (PV) systems and batteries. This iterative training approach enables the proposed discretized soft actor-critic (SAC) agents to aggregate the collected knowledge to expedite the overall learning procedure and reduce costs and CO2 emissions, while the federation approach can mitigate privacy breaches. The numerical results confirm the performance of the proposed framework under different daytime periods, loads, and temperatures.},
	booktitle = {2022 {IEEE} 27th {International} {Workshop} on {Computer} {Aided} {Modeling} and {Design} of {Communication} {Links} and {Networks} ({CAMAD})},
	author = {Rezazadeh, Farhad and Bartzoudis, Nikolaos},
	month = nov,
	year = {2022},
	note = {ISSN: 2378-4873},
	keywords = {Reinforcement learning, Smart grids, federated learning, Training, deep reinforcement learning, Artificial intelligence, Deep learning, Computational modeling, Smart meters, energy control, smart micro-grid, soft actor-critic, Temperature control},
	pages = {108--114},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\2VHF9BX5\\Rezazadeh and Bartzoudis - 2022 - A Federated DRL Approach for Smart Micro-Grid Ener.pdf:application/pdf},
}

@article{zheng_multi-agent_2024,
	title = {Multi-{Agent} {Reinforcement} {Learning} {With} {Privacy} {Preservation} for {Continuous} {Double} {Auction}-{Based} {P2P} {Energy} {Trading}},
	volume = {20},
	issn = {1941-0050},
	doi = {10.1109/TII.2023.3348823},
	abstract = {With increasing deployment of distributed energy resources, the energy market which aims for local generation and load profile redistribution is facing the challenge to accommodate various types of participants. To realize social welfare maximization with privacy preserving in a dynamic energy market, this article propose a multiagent reinforcement learning (MARL) method for quotation decision optimization in continuous double auction (CDA)-based peer-to-peer (P2P) energy market. To address the nonstationarity and privacy violation brought by multiagent context, we utilize mean-field approximation to abstract the unauthorized local information of other agents from the public market dynamics. An abstract Q-value function is developed for each agent to infer the neighbor agents' local observation and action through the public clearing results in the dynamic CDA market. Moreover, to avoid sparse reward so as to stabilize the learning process, we propose a dynamic potential-based reward shaping term in the reward. Without altering the learnt optimal policies, the agents can be informed with the additional energy storage state as the reward shaping in each time instants. To validate the effectiveness and economy of our proposed method, simulation studies are conducted on a real-world dataset. Simulation results show that the proposed MARL method produces up to 17\% more convergent episodic reward and 67\% less energy bills which indicates competitive convergence performance and significant economic benefits.},
	number = {4},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Zheng, Jiehui and Liang, Ze-Ting and Li, Yuanzheng and Li, Zhigang and Wu, Qing-Hua},
	month = apr,
	year = {2024},
	keywords = {Power system dynamics, Privacy, Continue double auction (CDA), dynamic potential based reward shaping, Energy management, mean-field approximation, multiagent twin delayed deep deterministic policy gradient, peer-to-peer (P2P), Peer-to-peer computing, Scalability, Tariffs, Training},
	pages = {6582--6590},
}

@inproceedings{samadi_q-learning-oriented_2021,
	title = {Q-{Learning}-{Oriented} {Distributed} {Energy} {Management} of {Grid}-{Connected} {Microgrid}},
	doi = {10.1109/ICEE52715.2021.9544152},
	abstract = {In this paper11This work is supported by Niroo Research Institute (NRI)., reinforcement learning (RL) is used for energy management of agent based microgrid (MG). The Grid connected MG that contains wind turbine, fuel cell (FC), diesel generator and electric vehicle (EV) to supply its demands, is modeled as a multi-agent system (MAS). The DER and customer are considered as self-interested agents that try to maximize their profits and optimize their behavior. These agents use RL to interact with each other in distributed manner without any direct communication. The market operator of MG is responsible to gather agents' data that have been submitted and clears the market to meet the desired goals. Modeling the stochastic nature of wind power generation and demand fluctuation of customer agents, implementing demand side management program for customer agents, besides taking into account the technical constraint of diesel generator, FC and EV agent are the main strengths of this paper. The simulation results confirm the efficiency of the proposed approach.},
	booktitle = {2021 29th {Iranian} {Conference} on {Electrical} {Engineering} ({ICEE})},
	author = {Samadi, Esmat and Badri, Ali and Ebrahimpour, Reza},
	month = may,
	year = {2021},
	note = {ISSN: 2642-9527},
	keywords = {Q-learning, Reinforcement learning, Fuel cells, Stochastic processes, Microgrids, Simulation, Fluctuations, distributed energy resources, energy management, multi-agent systems, Wind power generation, Microgrid},
	pages = {318--322},
}

@article{li_temporal-aware_2024,
	title = {Temporal-{Aware} {Deep} {Reinforcement} {Learning} for {Energy} {Storage} {Bidding} in {Energy} and {Contingency} {Reserve} {Markets}},
	issn = {2771-9626},
	doi = {10.1109/TEMPR.2024.3372656},
	abstract = {The battery energy storage system (BESS) has immense potential for enhancing grid reliability and security through its participation in the electricity market. BESS often seeks various revenue streams by taking part in multiple markets to unlock its full potential, but effective algorithms for joint-market participation under price uncertainties are insufficiently explored in the existing research. To bridge this gap, we develop a novel BESS joint bidding strategy that utilizes deep reinforcement learning (DRL) to bid in the spot and contingency frequency control ancillary services (FCAS) markets. Our approach leverages a transformer-based temporal feature extractor to effectively respond to price fluctuations in seven markets simultaneously and helps DRL learn the best BESS bidding strategy in joint-market participation. Additionally, unlike conventional “black-box” DRL model, our approach is more interpretable and provides valuable insights into the temporal bidding behavior of BESS in the dynamic electricity market. We validate our method using realistic market prices from the Australian National Electricity Market. The results show that our strategy outperforms benchmarks, including both optimization-based and other DRL-based strategies, by substantial margins. Our findings further suggest that effective temporal-aware bidding can significantly increase profits in the spot and contingency FCAS markets compared to individual market participation.},
	journal = {IEEE Transactions on Energy Markets, Policy and Regulation},
	author = {Li, Jinhao and Wang, Changlong and Zhang, Yanru and Wang, Hao},
	year = {2024},
	keywords = {Real-time systems, Uncertainty, Electricity supply industry, deep reinforcement learning, energy arbitrage, Regulation, Generators, Battery energy storage system, Australia, Contingency management, frequency control ancillary services, transformer},
	pages = {1--15},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\5TF22JC7\\Li et al. - 2024 - Temporal-Aware Deep Reinforcement Learning for Ene.pdf:application/pdf},
}

@inproceedings{li_multi-micro_2022,
	title = {Multi-micro {Network} {Multi}-time {Scale} {Trading} {Mechanism} {Design} and {Trading} {Strategy} {Optimization}},
	doi = {10.1109/ICEI57064.2022.00022},
	abstract = {In view of the grid type micro network system more time scales trading mechanism and trading strategy optimization algorithms, this paper establishes the multiple piconets insider trading price model and “newspaper is quote” and intra-day trading mechanism, realize the dynamic adjustment internal transaction prices, form a trading plan and market price, make more piconets insider trading is more economical. At the same time, the deep neural network algorithm is introduced to train and learn the transaction strategy, so that the sub-micro network can get its own optimal purchase and sale plan quickly and accurately. Finally, an example is given to verify the effectiveness of the proposed model and algorithm.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Energy} {Internet} ({ICEI})},
	author = {Li, Tong and Sun, Qian},
	month = dec,
	year = {2022},
	keywords = {energy trading, Heuristic algorithms, Mathematical models, Predictive models, Neural networks, Microgrids, Deep learning, microgrid, deep learning, Distribution networks, distribution network, multi-time scale},
	pages = {97--102},
}

@inproceedings{he_privacy-preserving_2022,
	title = {Privacy-preserving {Local} {Electricity} {Market}: {A} {Federated} {Learning}-based {Case} {Study}},
	doi = {10.1109/NAPS56150.2022.10012269},
	abstract = {Local electricity markets (LEM) envision energy sectors to satisfy the ever-increasing distributed energy resources (DERs), especially residential photovoltaics (PV), in modern communities over past years. However, local energy trading faces some obstacles in practical applications. Although massive datasets are desired to train machine/deep learning models for grid operations, forecasting, load monitoring, and decision-marking, these applications raise privacy concerns. One the one hand, some clients might not be willing to endorse sharing data to others due to privacy concerns. On the other hand, the transfer of large datasets is costly. These two obstacles would become more critical in the case of a large energy sharing platform consisting of thousands of peer-to-peer clients. This paper seeks to design a privacy-preserving LEM that consists of an LEM agent, centralized energy storage (ES), prosumers, and consumers. A future global forecasting model is jointly trained using federated learning (FL), and the clients' individual forecasts and decision-making are determined at the edge of the network without compromising privacy. Numerical results of case studies show the leakage of historical load data is detrimental for the LEM clients, with 2\% to 17\% increase in costs, if their datasets are fully obtained by the agent. The LEM agent could earn a maximum of 17\% profit increase by obtaining full access to clients' datasets.},
	booktitle = {2022 {North} {American} {Power} {Symposium} ({NAPS})},
	author = {He, Li and Zhang, Jie},
	month = oct,
	year = {2022},
	note = {ISSN: 2833-003X},
	keywords = {Predictive models, Biological system modeling, Data privacy, Electric potential, Electricity supply industry, federated learning, Federated learning, forecasting, Local electricity market, privacy, Privacy},
	pages = {1--6},
}

@inproceedings{wang_learning-based_2015,
	title = {Learning-based energy management policy with battery depth-of-discharge considerations},
	doi = {10.1109/GlobalSIP.2015.7418346},
	abstract = {This work proposes a learning-based energy management policy that takes into consideration the trade-off between the depth-of-discharge (DoD) and the lifetime of batteries. The impact of DoD on the energy management policy is often neglected in the past due to the inability to model its effect on the marginal cost per battery usage. In this work, a novel battery cost evaluation method that takes into consideration the DoD of each battery usage is proposed, and is utilized to devise the day-ahead energy management policy using reinforcement learning and linear value-function approximations. The policy determines the amount of energy to purchase for the next day in the day ahead market. A next-state policy iteration (NSPI) scheme with linear predictions of the next-day system parameters is used to learn the energy management policy. Simulations are provided based on real load profiles, pricing data, and renewable energy arrival statistics. The consideration of the battery cost due to DoD provides a more accurate evaluation of the actual energy cost and leads to an improved energy management policy.},
	booktitle = {2015 {IEEE} {Global} {Conference} on {Signal} and {Information} {Processing} ({GlobalSIP})},
	author = {Wang, Ting-Hsing and Hong, Y.-W. Peter},
	month = dec,
	year = {2015},
	keywords = {Pricing, Real-time systems, Batteries, Renewable energy sources, Learning (artificial intelligence), US Department of Defense},
	pages = {992--996},
}

@article{ma_two-timescale_2024,
	title = {A {Two}-{Timescale} {Operation} {Strategy} for {Battery} {Storage} in {Joint} {Frequency} and {Energy} {Markets}},
	volume = {2},
	issn = {2771-9626},
	doi = {10.1109/TEMPR.2023.3324920},
	abstract = {The growing penetration of renewable energy in modern power systems requires energy storage to take on more responsibilities in multiple regulation services. Battery energy storage system (BESS) possesses fast response capability and is suitable to shave peak demand and provide frequency support. This article studies coordinated bidding strategies of BESS in frequency regulation and energy markets. Challenge arises from the fact that frequency control and energy arbitrage actions are taken in different timescales, and the capacity used in either market affects the available capacity and revenue in the other one. This article proposes a two-timescale decision framework, offering the hourly base-power bid in the energy market and capacity bid in the frequency regulation market, as well as real-time responses to the automatic generation control (AGC) signal every few seconds. In the fine timescale, we employ a threshold policy to generate AGC response accounting for battery lifespan. In the coarse timescale, we establish a stochastic dynamic programming model and optimize the bidding policy without exact forecasts of market prices. To solve the stochastic dynamic programming model online, a simulation-based policy improvement method is developed to approximate the state-action value function using a heuristic base policy. The performance improvement property brought by simulation is theoretically proven. We carry out comprehensive case studies to validate the effectiveness of the proposed method and analyze the economic impact of electricity prices and battery E/P ratio. Empirical tests show that with an E/P ratio of 3{\textbackslash}sim5, the BESS gains a higher net revenue across the lifespan.},
	number = {2},
	journal = {IEEE Transactions on Energy Markets, Policy and Regulation},
	author = {Ma, Qianli and Wei, Wei and Mei, Shengwei},
	month = jun,
	year = {2024},
	keywords = {Optimization, Batteries, Renewable energy sources, Automatic generation control, Battery storage, energy arbitrage, Frequency control, frequency regulation, online dynamic programming, Regulation, Stochastic processes, two-timescale control},
	pages = {200--213},
}

@article{liu_microgrid_2023,
	title = {Microgrid {Energy} {Management} with {Energy} {Storage} {Systems}: {A} {Review}},
	volume = {9},
	issn = {2096-0042},
	doi = {10.17775/CSEEJPES.2022.04290},
	abstract = {Microgrids (MGs) are playing a fundamental role in the transition of energy systems towards a low carbon future due to the advantages of a highly efficient network architecture for flexible integration of various DC/AC loads, distributed renewable energy sources, and energy storage systems, as well as a more resilient and economical on/off-grid control, operation, and energy management. However, MGs, as newcomers to the utility grid, are also facing challenges due to economic deregulation of energy systems, restructuring of generation, and market-based operation. This paper comprehensively summarizes the published research works in the areas of MGs and related energy management modelling and solution techniques. First, MGs and energy storage systems are classified into multiple branches and typical combinations as the backbone of MG energy management. Second, energy management models under exogenous and endogenous uncertainties are summarized and extended to transactive energy management. Mathematical programming, adaptive dynamic programming, and deep reinforcement learning-based solution methods are investigated accordingly, together with their implementation schemes. Finally, problems for future energy management systems with dynamics-captured critical component models, stability constraints, resilience awareness, market operation, and emerging computational techniques are discussed.},
	number = {2},
	journal = {CSEE Journal of Power and Energy Systems},
	author = {Liu, Xiong and Zhao, Tianyang and Deng, Hui and Wang, Peng and Liu, Jizhen and Blaabjerg, Frede},
	month = mar,
	year = {2023},
	keywords = {Energy management, Microgrids, optimization, Generators, microgrids, energy management, Computer architecture, Architecture, energy storage systems, Engines, Power system stability, Propulsion, uncertainty models},
	pages = {483--504},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\UPISIX8A\\Liu et al. - 2023 - Microgrid Energy Management with Energy Storage Sy.pdf:application/pdf},
}

@inproceedings{zhao_data-driven_2021,
	title = {Data-driven {State} of {Health} {Modeling} of {Battery} {Energy} {Storage} {Systems} {Providing} {Grid} {Services}},
	doi = {10.1109/CPEEE51686.2021.9383356},
	abstract = {Battery energy storage system (BESS) is key for future renewable energy systems, as it can provide various grid support functionalities, facilitate the participation of renewable energy sources in electricity markets, and increase grid stability. However, battery degradation is a major factor hindering the BESS implementation for grid applications. Battery state of health (SOH) is a key performance indicator of the BESS, and data-driven models powered by machine learning techniques are among the most promising solutions for the BESS degradation estimation. In this paper, a novel taxonomy of BESS services is proposed based on battery usage. Besides, the data-driven techniques for battery SOH modeling and data-driven SOH estimation applications for BESS providing grid services are reviewed and discussed. Further, a comprehensive discussion is presented regarding the challenges in the area of data-driven SOH modeling methods for the BESS providing grid services in practical applications.},
	booktitle = {2021 11th {International} {Conference} on {Power}, {Energy} and {Electrical} {Engineering} ({CPEEE})},
	author = {Zhao, Chunyang and Hashemi, Seyedmostafa and Andersen, Peter Bach and Træholt, Chresten},
	month = feb,
	year = {2021},
	keywords = {Batteries, battery energy storage system, Degradation, Analytical models, Data models, battery service, data-driven model, Estimation, grid-connected application, state of health, Taxonomy, Testing},
	pages = {43--49},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\BDVEWK6K\\Zhao et al. - 2021 - Data-driven State of Health Modeling of Battery En.pdf:application/pdf},
}

@inproceedings{gao_deep_2021,
	title = {Deep {Reinforcement} {Learning} in {Power} {Distribution} {Systems}: {Overview}, {Challenges}, and {Opportunities}},
	doi = {10.1109/ISGT49243.2021.9372283},
	abstract = {To facilitate the integration of distributed energy resources and improve existing operational strategies, power distribution systems have seen a rapid proliferation of deep reinforcement learning (DRL) based applications. DRL approach is well suited for dynamic, complex, and uncertain operational environments such as power distribution systems. This paper reviews the rapidly growing body of literature that develops applications of reinforcement learning in power distribution systems. These applications include active grid management, energy management system, retail electricity market, and demand response. This paper also summarizes the challenges of deploying DRL based solutions in distribution systems such as safety, robustness, interpretability, and sample efficiency. Finally, the research opportunities that can be pursued to address the challenges are provided.},
	booktitle = {2021 {IEEE} {Power} \& {Energy} {Society} {Innovative} {Smart} {Grid} {Technologies} {Conference} ({ISGT})},
	author = {Gao, Yuanqi and Yu, Nanpeng},
	month = feb,
	year = {2021},
	note = {ISSN: 2472-8152},
	keywords = {Reinforcement learning, Smart grids, Uncertainty, deep reinforcement learning, Safety, Power distribution, Power distribution systems, Research and development, Robustness},
	pages = {1--5},
}

@inproceedings{anwar_proximal_2022,
	title = {Proximal {Policy} {Optimization} {Based} {Reinforcement} {Learning} for {Joint} {Bidding} in {Energy} and {Frequency} {Regulation} {Markets}},
	doi = {10.1109/PESGM48719.2022.9917082},
	abstract = {Driven by the global decarbonization effort, the rapid integration of renewable energy into the conventional electricity grid presents new challenges and opportunities for the battery energy storage system (BESS) participating in the energy market. Energy arbitrage can be a significant source of revenue for the BESS due to the increasing price volatility in the spot market caused by the mismatch between renewable generation and electricity demand. In addition, the Frequency Control Ancillary Services (FCAS) markets established to stabilize the grid can offer higher returns for the BESS due to their capability to respond within milliseconds. Therefore, it is crucial for the BESS to carefully decide how much capacity to assign to each market to maximize the total profit under uncertain market conditions. This paper formulates the bidding problem of the BESS as a Markov Decision Process, which enables the BESS to participate in both the spot market and the FCAS market to maximize profit. Then, Proximal Policy Optimization, a model-free deep reinforcement learning algorithm, is employed to learn the optimal bidding strategy from the dynamic environment of the energy market under a continuous bidding scale. The proposed model is trained and validated using real-world historical data of the Australian National Electricity Market. The results demonstrate that our developed joint bidding strategy in both markets is significantly profitable compared to individual markets.},
	booktitle = {2022 {IEEE} {Power} \& {Energy} {Society} {General} {Meeting} ({PESGM})},
	author = {Anwar, Muhammad and Wang, Changlong and de Nijs, Frits and Wang, Hao},
	month = jul,
	year = {2022},
	note = {ISSN: 1944-9933},
	keywords = {Heuristic algorithms, Reinforcement learning, Electricity supply industry, Renewable energy sources, Profitability, Regulation, Markov processes},
	pages = {1--5},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\5VHT5SPC\\Anwar et al. - 2022 - Proximal Policy Optimization Based Reinforcement L.pdf:application/pdf},
}

@inproceedings{mussakhanova_sd-lstm_2020,
	title = {{SD}-{LSTM} {Based} {Demand} {Response} {Framework} for {Prosumer} {Energy} {Management} {Systems}},
	doi = {10.1109/IECON43393.2020.9254615},
	abstract = {Prosumer Energy Management System (PEMS) is the system used for intelligent energy management for a house-hold with on-site photovoltaic (PV) system using the input data from various sources: smart meter, PV management system, a distribution transformer, dispatching unit of a home, real-time pricing from utility provider data center. An efficient PEMS should be able to provide demand response (DR) management in response to the prices, on-site energy generation, and electricity load to contribute to the improvement of overall electricity grid reliability and reduce the costs of a prosumer. This paper presents the Smart PEMS based on two components: seasonal decomposition long short-term memory (SD-LSTM) based forecasting system for predicting electricity prices and PV system energy generation combined with Q-Learning based home appliances scheduler.},
	booktitle = {{IECON} 2020 {The} 46th {Annual} {Conference} of the {IEEE} {Industrial} {Electronics} {Society}},
	author = {Mussakhanova, Meruyert and Kumar Nunna, H. S. V. S. and Srinivasan, Dipti},
	month = oct,
	year = {2020},
	note = {ISSN: 2577-1647},
	keywords = {Home appliances, Forecasting, Reinforcement Learning, Schedules, Smart meters, Market research, LSTM, ANN, Distributed Energy Resources, Logic gates, PEMS, PV forecasting, Scheduling},
	pages = {1998--2003},
}

@inproceedings{gupta_artificial_2023,
	title = {Artificial {Intelligence} - {Smart} {Energy} {Distribution} and {Management} {System} for small autonomous {Photo}-voltaic {Systems}},
	doi = {10.1109/ICRT57042.2023.10146714},
	abstract = {In today’s world, with the decrease in the coal and other conventional sources of energy, the need of the hour for the use of other renewable sources of energy has arisen. The untapped potential of the renewable sources of energy like the wind and solar energy which when used to the full extent, have the potential to become a major boon to the ever increasing power demand. When used in combination with the newer trends of technology like Artificial Intelligence and neural networks, they can be used in the development of smart energy management systems that can be used in decreasing the energy expenditure.This paper analyses the design of a smart energy management system that is used to limit and conserve the excess power consumption from the grid by a domestic household by the use of a stand - alone solar panel system. The excess energy required by the system above a particular threshold value of consumption from the grid can be supplied by means of wireless transfer of power from the load along with the consumption by the standalone and the domestic systems being monitored by means of Power Line Communication (PLC) and Neural Network algorithm.},
	booktitle = {2023 1st {International} {Conference} on {Intelligent} {Computing} and {Research} {Trends} ({ICRT})},
	author = {Gupta, Anish and Srivastava, Anand Kumar},
	month = feb,
	year = {2023},
	keywords = {Renewable energy sources, Wind energy, Power demand, Deep Learning, Market research, electric vehicles, Neural Networks, Photo-Voltaic Generation System, Power Line Communication, Solar energy, Solar panels, Wireless communication, Wireless Power Transmission},
	pages = {1--7},
}

@inproceedings{thirunavukkarasu_advancing_2023,
	title = {Advancing {Transactive} {Energy} {Market} {Management} using {Community} {Microgrid} {Emulator} that {Supports} {OpenADR} and {Q}-learning {Based} {Auction} {Model}},
	doi = {10.1109/ETFG55873.2023.10407269},
	abstract = {This paper delves into the practical application of transactive energy markets within community microgrids, making use of an innovative openADR-based microgrid emulator for thorough testing and validation. The emulator serves as a crucial conduit between theoretical concepts and real-world deployment, faithfully emulating the intricate behaviors of microgrids. Four distinct scenarios were meticulously examined: "Surplus Energy Selling," involving the return of excess energy to the grid; "Prioritized Community Sharing," which prioritizes local energy consumption within the community; a "Demand Response (DR)" scenario with a 10\% load reduction to explore demand-side management potential; and "Energy Auction model using Q-learning," introducing Q-learning models to optimize energy bidding strategies for efficient distribution within the community. Through rigorous testing in the community microgrid emulator, these scenarios were effectively verified, underscoring the emulator’s adaptability and versatility. This unique combination of advanced simulation and hardware-in-loop testing facilitates the exploration of a wide array of energy market strategies and demand-side management techniques, affirming the practical significance and robustness of community microgrid applications in real-world contexts.},
	booktitle = {2023 {IEEE} {International} {Conference} on {Energy} {Technologies} for {Future} {Grids} ({ETFG})},
	author = {Thirunavukkarasu, Gokul Sidarth and Seyedmahmoudian, Mehdi and Mekhilef, Saad and Stojcevski, Alex},
	month = dec,
	year = {2023},
	keywords = {Q-learning, Transactive energy, Load modeling, Microgrids, Demand response, Adaptation models, Testing, Community Microgrid, Demand side management, Hardware-in-the-Loop Testing, OpenADR, Peer-to-Peer Energy Trading, Q-Learning, Transactive Energy Market},
	pages = {1--6},
}

@inproceedings{matos_machine_2023,
	title = {A {Machine} {Learning} {Based} {Energy} {Management} {System} for {Renewable} {Energy} {Communities}},
	doi = {10.1109/IESES53571.2023.10253701},
	abstract = {Energy systems are under a profound transformation powered by the increasing penetration of renewable energy sources and the decentralization of electricity markets into local communities, in which the prosumer plays a fundamental role. As a result, the creation of Renewable Energy Communities (RECs) is becoming popular, especially in Europe, allowing their members to reduce electricity consumption from non-renewables, as well as to locally produce, store and exchange energy among themselves. This work introduces a REC management system using Artificial Intelligence/Machine Learning (AI/ML) techniques for the electricity consumption forecast. The obtained results of the simulated scheme show that, with the use of these techniques, the system is able to decrease the electricity bill of the REC as well as the energy consumption from the distribution grid.},
	booktitle = {2023 {IEEE} 3rd {International} {Conference} on {Industrial} {Electronics} for {Sustainable} {Energy} {Systems} ({IESES})},
	author = {Matos, Miguel and Almeida, João and Gonçalves, Pedro and Baldo, Fabiano and Braz, Fernando José and Bartolomeu, Paulo},
	month = jul,
	year = {2023},
	keywords = {Tariffs, Europe, Renewable Energy Communities, Renewable energy sources, Production, Machine learning, Energy consumption, Electricity Consumption Forecast, Industrial electronics, Machine Learning},
	pages = {1--6},
	file = {Matos et al. - 2023 - A Machine Learning Based Energy Management System .pdf:C\:\\Users\\Jacob\\Zotero\\storage\\KSEIBHWK\\Matos et al. - 2023 - A Machine Learning Based Energy Management System .pdf:application/pdf},
}

@article{tightiz_resilience_2021,
	title = {Resilience {Microgrid} as {Power} {System} {Integrity} {Protection} {Scheme} {Element} {With} {Reinforcement} {Learning} {Based} {Management}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3087491},
	abstract = {The microgrid is a solution for integrating renewable energy resources into the power system. However, overcoming the randomness of these nature-based resources requires a robust control system. Moreover, electricity market participation and ancillary service provision for the utility grid are other aspects, although intensify microgrid penetration makes its environment interactions more complex. Reinforcement learning is a technique vastly applied to such an intricate environment. Hence, in this paper, we deployed deep deterministic policy gradient and soft-actor critic methods to solve the high-dimensional, continuous, and stochastic problem of the microgrid's energy management system and compared the performance of two methods. Additionally, we developed the microgrid interactions with the utility grid as a participant of system integrity protection schema responding promptly to the utility grid protection requirements based on its reliable available resources. Moreover, we applied actual data of Gasa Island microgrid in Korea to prove the efficiency of proposed method.},
	journal = {IEEE Access},
	author = {Tightiz, Lilia and Yang, Hyosik},
	year = {2021},
	keywords = {Batteries, Uncertainty, Electricity supply industry, Energy management, Microgrids, Energy management system, Energy management systems, soft actor-critic, deep deterministic policy gradient, Power generation, system integrity protection schema},
	pages = {83963--83975},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\PRWWL3QS\\Tightiz and Yang - 2021 - Resilience Microgrid as Power System Integrity Pro.pdf:application/pdf},
}

@inproceedings{khayaty_intelligent_2021,
	title = {Intelligent {Microgrid} {Energy} {Management} {System} {Based} on {Deep} {Learning} {Approach}},
	doi = {10.1109/SGC54087.2021.9664022},
	abstract = {Recently, microgrids (MG) have emerged as an essential solution for smart grids. The MG efficiently aggregates dispersed distributed energy resources (DERs) and balances renewable energy output variability. Uncertainties of power generation resources and consumption have disruptive influences on MG optimal decision making. This article proposes an intelligent energy management system (EMS) for grid-connected MGs. A forecasting approach is employed based on the convolutional LSTM (long-short time memory) to overcome uncertainties and improve the performance of the energy management system. MG comprises wind turbines (WTs), photovoltaic (PV) panels, battery energy storage systems (BSS), and electrical loads. Also, we utilized the mixed-integer linear programming (MILP) approach to offer an optimal solution by minimizing operating costs. Finally, the study compares its performance over similar state-of-the-art models by employing available real datasets from California, San Diego MGs. The experimental results show strong evidence of the effectiveness of the proposed model.},
	booktitle = {2021 11th {Smart} {Grid} {Conference} ({SGC})},
	author = {Khayaty, Mohammad Saeed and Movludiazar, Amanj and Fotouhi, Ramin and Sheikh-El-Eslami, Mohammad Kazem},
	month = dec,
	year = {2021},
	note = {ISSN: 2572-6927},
	keywords = {Smart grids, Forecasting, Predictive models, Uncertainty, Microgrids, optimization, Deep learning, Decision making, microgrid, energy management, deep learning, autoencoder, convolutional long short-term memory (ConvLSTM), time-series forecasting},
	pages = {1--7},
}

@inproceedings{li_ppo-based_2022,
	title = {{PPO}-based {Pricing} {Method} for {Shared} {Energy} {Storage} {System}},
	doi = {10.1109/ISGTAsia54193.2022.10003511},
	abstract = {The shared energy storage system has the potential to promote the popularity of the battery energy storage system (BESS). In a shared energy storage system, prosumers could rent capacity and optimize its operation, whereas the operator also seeks to maximize the revenue of the BESS from both rental service and the virtual power plant (VPP) market. To optimize the pricing policy of the BESS, a novel pricing method based on deep reinforcement learning (DRL) is proposed for this energy storage rental service. The interaction between the BESS operator and prosumers is formulated as a bi-level optimization problem, which is further reformulated as a Markov decision process (MDP) and solved through the proximal policy optimization (PPO)-based DRL method. The case study shows that the proposed method could further increase the revenues of the BESS operator.},
	booktitle = {2022 {IEEE} {PES} {Innovative} {Smart} {Grid} {Technologies} - {Asia} ({ISGT} {Asia})},
	author = {Li, Xiangyu and Liu, Hangyue and Li, Chaojie and Chen, Guo and Wen, Shiping},
	month = nov,
	year = {2022},
	note = {ISSN: 2378-8542},
	keywords = {Pricing, Batteries, Reinforcement learning, Smart grids, deep reinforcement learning, Asia, Virtual power plants, Numerical simulation, proximal policy optimization, shared energy storage, virtual power plant},
	pages = {424--428},
}

@inproceedings{yang_asynchronous_2024,
	title = {Asynchronous {Federated} {Multi} {Microgrid} {Energy} {Management} {Method} {Considering} {Carbon} {Trading}},
	doi = {10.1109/ICETCI61221.2024.10594337},
	abstract = {The utilization of large-scale distributed renewable energy (RE) has facilitated the development of multiple microgrids (MMGs). However, direct data collection from different microgrids for energy management may pose a threat to microgrid privacy and data security. Therefore, this paper proposes an asynchronous federated multi-microgrid energy management approach that accounts for carbon trading. First, a distributed inter-microgrid trading mechanism is designed to simplify energy and carbon trading in multiple microgrids. Second, a Markov (MDP)-based distributed MMG model is developed, which adopts the idea of federated learning, so that the model does not need to directly access the data of the microgrids when solving, which protects the privacy and data security of the microgrids. Finally, the model is solved by introducing an asynchronous federation mechanism to train the DDPG, which accelerates the convergence speed and obtains higher economic returns. The effectiveness of this energy management method is verified while ensuring data privacy and security.},
	booktitle = {2024 {IEEE} 4th {International} {Conference} on {Electronic} {Technology}, {Communication} and {Information} ({ICETCI})},
	author = {Yang, Mingsheng and Li, Pengcheng and Fu, Kexin},
	month = may,
	year = {2024},
	keywords = {deep reinforcement learning, carbon trading, asynchronous federated learning, multiple microgrids, optimal scheduling},
	pages = {224--229},
}

@inproceedings{sadeeq_design_2021,
	title = {Design and {Analysis} of {Intelligent} {Energy} {Management} {System} based on {Multi}-{Agent} and {Distributed} {IoT}: {DPU} {Case} {Study}},
	doi = {10.1109/ICCITM53167.2021.9677679},
	abstract = {Population growth and the creation of new equipment are accompanied by a constant increase in energy use each day and have created significant consumer issues in energy management. Smart meters (SM) are simply instruments for measuring energy usage and are a significant resource of the evolving technological energy management system. Including precise billing data, information on usage at the user end, installation of two-way communication. SM is the critical component of an intelligent power grid. The Internet of Things (IoT) is a critical partner in the power business leading to intelligent resource management to ensure successful data collection and use. This paper proposes designing and analyzing intelligent energy management systems based on Multi-Agent (MA) and Distributed IoT (DIoT). An efficient approach is proposed to monitor and control power consumption levels of the proposed case study of Duhok Polytechnic University (DPU). DPU consists of Presidency, six colleges, and eight institutes. These fifteen campuses are distributed through a wide geographical area with long distances between each campus (i.e., more than 100 Km). A Node represents each campus, and Wi-Fi makes the connection inside each node. These nodes are connected via the Internet to the Main Control Unit (MCU) represented by Raspberry Pi connected to the cloud. Depending on the received data from the Nodes, the MCU will make the correct decision for each node using intelligent algorithms and the user's requirement. Then, control commands are initiated, and the node's appliances can be controlled automatically (or even manually) from the MCU.},
	booktitle = {2021 7th {International} {Conference} on {Contemporary} {Information} {Technology} and {Mathematics} ({ICCITM})},
	author = {Sadeeq, Mohammed A. M. and Zeebaree, Subhi R. M.},
	month = aug,
	year = {2021},
	keywords = {Smart meters, Cloud computing, Internet of Things, Power grids, Energy management systems, Energy Management, Distributed IoT, Intelligent System, Multiagent, Resource management, Sociology},
	pages = {48--53},
}

@inproceedings{dreher_ai_2022,
	title = {{AI} agents assessing flexibility: the value of demand side management in times of high energy prices},
	doi = {10.1109/EEM54602.2022.9920982},
	abstract = {High energy and electricity prices, coupled with high price volatility, increase the value of demand response and demand side management. Energy management systems that are predictive and exchange-price oriented can help to leverage flexibility while lowering energy costs. In this paper, the value of flexibility is assessed in two scenarios of low and high energy prices. To that end, a self-learning home energy management system is introduced that takes into account the new volatility of high stock market electricity prices. The proposed approach is compared to a baseline system, which is a typical household self-consumption optimization. The findings indicate a significant economic potential of an exchange-price oriented usage of residential flexibility options in contrast to self-consumption optimization. Furthermore, the value of flexibility for the exemplary residential system increased more than fivefold between 2021 and 2022, while prices increased about fourfold.},
	booktitle = {2022 18th {International} {Conference} on the {European} {Energy} {Market} ({EEM})},
	author = {Dreher, Alexander and Martmann, Lisa Marie and Lehna, Malte and Roelofs, Cyriana and Bergsträßer, Jonathan and Scholz, Christoph and Slaby, Wolfgang and Wetzel, Heike},
	month = sep,
	year = {2022},
	note = {ISSN: 2165-4093},
	keywords = {Electric potential, Costs, Europe, Reinforcement Learning, Demand response, Energy management systems, Energy Management, Demand side management, Demand Side Management, Power System Economics, Stock markets},
	pages = {1--9},
	file = {Dreher et al. - 2022 - AI agents assessing flexibility the value of dema.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\S5QH9TWI\\Dreher et al. - 2022 - AI agents assessing flexibility the value of dema.pdf:application/pdf},
}

@inproceedings{jung_infrastructure-assisted_2021,
	title = {Infrastructure-{Assisted} {Cooperative} {Multi}-{UAV} {Deep} {Reinforcement} {Energy} {Trading} {Learning} for {Big}-{Data} {Processing}},
	doi = {10.1109/ICOIN50884.2021.9333895},
	abstract = {This paper proposes a cooperative multi-agent deep reinforcement learning (MADRL) algorithm for energy trading among multiple unmanned aerial vehicles (UAVs) in order to perform big-data processing in a distributed manner. In order to realize UAV-based aerial surveillance or mobile cellular services, seamless and robust wireless charging mechanisms are required for delivering energy sources from charging infrastructure (i.e., charging towers) to UAVs for the consistent operations of the UAVs in the sky. For actively and intelligently managing the charging towers, MADRL-based energy management system (EMS) is proposed and designed for energy trading among the energy storage systems those are equipped with charging towers. If the required energy for charging UAVs is not enough, the purchasing energy from utility company is desired which takes high consts. The main purpose of MADRL-based EMS learning is for minimizing purchasing energy from outside utility company for minimizing operational costs. Our data-intensive performance evaluation verifies that our proposed framework achieves desired performance.},
	booktitle = {2021 {International} {Conference} on {Information} {Networking} ({ICOIN})},
	author = {Jung, Soyi and Yun, Won Joon and Kim, Joongheon and Kim, Jae-Hyun},
	month = jan,
	year = {2021},
	note = {ISSN: 1976-7684},
	keywords = {Reinforcement learning, Deep learning, Smart grid, Companies, Performance evaluation, Multi-agent deep reinforcement learning, Big-data processing, Inductive charging, Poles and towers, Surveillance, Unmanned aerial vehicle (UAV)., Unmanned aerial vehicles},
	pages = {159--162},
}

@article{rana_modelling_2022,
	title = {Modelling and {Simulation} {Approaches} for {Local} {Energy} {Community} {Integrated} {Distribution} {Networks}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3140237},
	abstract = {Due to the absence of studies of local energy communities (LECs) where the grid is represented, it is very difficult to infer implications of increased LEC integration for the distribution grid as well as for the wider society. Therefore, this paper aims to investigate holistic modelling and simulation approaches of LECs. To conduct a quantifiable assessment of different control architectures, LEC types and market frameworks, a flexible and comprehensive LEC modelling and simulation approach is needed. Modelling LECs and the environment they operate in involves a holistic approach consisting of different layers: market, controller, and grid. The controller layer is relevant both for the overall energy management system of the LEC and the controllers of single components in a LEC. In this paper, the different LEC modelling approaches in the reviewed literature are presented, several multilayered concepts for LECs are proposed, and a case study is presented to illustrate a holistic simulation where the different layers interact.},
	journal = {IEEE Access},
	author = {Rana, Rubi and Berg, Kjersti and Degefa, Merkebu Z. and Löschenbrand, Markus},
	year = {2022},
	keywords = {Optimization, Real-time systems, Biological system modeling, Energy management, Peer-to-peer computing, Microgrids, Distribution networks, Battery energy storage system, community manager, distribution system operator, energy management system, local energy community, photovoltaic, prosumers},
	pages = {3775--3789},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\E5IRIH44\\Rana et al. - 2022 - Modelling and Simulation Approaches for Local Ener.pdf:application/pdf},
}

@article{lu_demand_2019,
	title = {Demand {Response} for {Home} {Energy} {Management} {Using} {Reinforcement} {Learning} and {Artificial} {Neural} {Network}},
	volume = {10},
	issn = {1949-3061},
	doi = {10.1109/TSG.2019.2909266},
	abstract = {Ever-changing variables in the electricity market require energy management systems (EMSs) to make optimal real-time decisions adaptively. Demand response (DR) is the latest approach being used to accelerate the efficiency and stability of power systems. This paper proposes an hour-ahead DR algorithm for home EMSs. To deal with the uncertainty in future prices, a steady price prediction model based on artificial neural network is presented. In cooperation with forecasted future prices, multi-agent reinforcement learning is adopted to make optimal decisions for different home appliances in a decentralized manner. To verify the performance of the proposed energy management scheme, simulations are conducted with non-shiftable, shiftable, and controllable loads. Experimental results demonstrate that the proposed DR algorithm can handle energy management for multiple appliances, minimize user energy bills, and dissatisfaction costs, and help the user to significantly reduce its electricity cost compared with a benchmark without DR.},
	number = {6},
	journal = {IEEE Transactions on Smart Grid},
	author = {Lu, Renzhi and Hong, Seung Ho and Yu, Mengmeng},
	month = nov,
	year = {2019},
	keywords = {Home appliances, Reinforcement learning, Uncertainty, demand response, Load management, reinforcement learning, Artificial intelligence, Decision making, Energy consumption, home energy management, artificial neural network},
	pages = {6629--6639},
	file = {Lu et al. - 2019 - Demand Response for Home Energy Management Using R.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\PHDJHS7G\\Lu et al. - 2019 - Demand Response for Home Energy Management Using R.pdf:application/pdf},
}

@inproceedings{xie_attention_2023,
	title = {Attention {Based} {Multi}-{Agent} {Reinforcement} {Learning} for {Demand} {Response} in {Grid}-{Responsive} {Buildings}},
	doi = {10.1109/CCTA54093.2023.10253019},
	abstract = {Integrating renewable energy resources and deploying energy management devices offer great opportunities to develop autonomous energy management systems in grid-responsive buildings. Demand response can promote enhancing demand flexibility and energy efficiency while reducing consumer costs. In this work, we propose a novel multi-agent deep reinforcement learning (MADRL) based approach to utilize real-time system information to facilitate demand response programs for minimizing electricity costs and efficient load shaping. Achieving real-time autonomous demand response in networks of buildings is challenging due to uncertain system parameters, the dynamic market price, and complex coupled operational constraints. To develop a scalable approach for automated demand response in networks of interconnected buildings, coordination between buildings is necessary to ensure demand flexibility and the grid's stability. We propose a MADRL technique that utilizes an actor-critic algorithm incorporating shared attention mechanism to enable effective real-time coordinated demand response in grid-responsive buildings. The presented case studies demonstrate the ability of the proposed MADRL approach to obtain decentralized cooperative policies without knowledge of building energy systems. The viability of the proposed control approach is also demonstrated by a reduction of over 6\% net load demand compared to state-of-the-art reinforcement learning approaches.},
	booktitle = {2023 {IEEE} {Conference} on {Control} {Technology} and {Applications} ({CCTA})},
	author = {Xie, Jiahan and Ajagekar, Akshay and You, Fengqi},
	month = aug,
	year = {2023},
	note = {ISSN: 2768-0770},
	keywords = {Heuristic algorithms, Reinforcement learning, Costs, Renewable energy sources, demand response, Buildings, Power system stability, buildings, multi-agent reinforcement learning, Uncertain systems},
	pages = {118--123},
}

@inproceedings{li_optimal_2023,
	title = {Optimal {Energy} {Storage} {Scheduling} for {Wind} {Curtailment} {Reduction} and {Energy} {Arbitrage}: {A} {Deep} {Reinforcement} {Learning} {Approach}},
	doi = {10.1109/PESGM52003.2023.10253181},
	abstract = {Wind energy has been rapidly gaining popularity as a means for combating climate change. However, the variable nature of wind generation can undermine system reliability and lead to wind curtailment, causing substantial economic losses to wind power producers. Battery energy storage systems (BESS) that serve as onsite backup sources are among the solutions to mitigate wind curtailment. However, such an auxiliary role of the BESS might severely weaken its economic viability. This paper addresses the issue by proposing joint wind curtailment reduction and energy arbitrage for the BESS. We decouple the market participation of the co-located wind-battery system and develop a joint-bidding framework for the wind farm and BESS. It is challenging to optimize the joint-bidding because of the stochasticity of energy prices and wind generation. Therefore, we leverage deep reinforcement learning to maximize the overall revenue from the spot market while unlocking the BESS’s potential in concurrently reducing wind curtailment and conducting energy arbitrage. We validate the proposed strategy using realistic wind farm data and demonstrate that our joint-bidding strategy responds better to wind curtailment and generates higher revenues than the optimization-based benchmark. Our simulations also reveal that the extra wind generation used to be curtailed can be an effective power source to charge the BESS, resulting in additional financial returns.},
	booktitle = {2023 {IEEE} {Power} \& {Energy} {Society} {General} {Meeting} ({PESGM})},
	author = {Li, Jinhao and Wang, Changlong and Wang, Hao},
	month = jul,
	year = {2023},
	note = {ISSN: 1944-9933},
	keywords = {Reinforcement learning, Deep reinforcement learning, Renewable energy sources, energy arbitrage, Deep learning, Economics, Climate change, Simulation, spot market, wind curtailment., Wind energy, Wind energy generation, wind-battery system},
	pages = {1--5},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\7IQQQNI7\\Li et al. - 2023 - Optimal Energy Storage Scheduling for Wind Curtail.pdf:application/pdf},
}

@inproceedings{soofi_training_2023,
	title = {Training {A} {Deep} {Reinforcement} {Learning} {Agent} for {Microgrid} {Control} using {PSCAD} {Environment}},
	doi = {10.1109/GridEdge54130.2023.10102740},
	abstract = {The accessibility of real-time operational data along with breakthroughs in processing power have promoted the use of Machine Learning (ML) applications in current power systems. Prediction of device failures, meteorological data, system outages, and demand are among the applications of ML in the electricity grid. In this paper, a Reinforcement Learning (RL) method is utilized to design an efficient energy management system for grid-tied Energy Storage Systems (ESS). We implement a Deep Q-Learning (DQL) approach using Artificial Neural Networks (ANN) to design a microgrid controller system simulated in the PSCAD environment. The proposed on-grid controller coordinates the main grid, aggregated loads, renewable generations, and Advanced Energy Storage (AES). To reduce the cost of operating AESs, the designed controller takes the hourly energy market price into account in addition to physical system characteristics.},
	booktitle = {2023 {IEEE} {PES} {Grid} {Edge} {Technologies} {Conference} \& {Exposition} ({Grid} {Edge})},
	author = {Soofi, Arash Farokhi and Bayani, Reza and Yazdanibiouki, Mehrdad and Manshadi, Saeed D.},
	month = apr,
	year = {2023},
	keywords = {Q-learning, Real-time systems, Reinforcement learning, Training, Renewable energy sources, Microgrids, Artificial neural network, Artificial neural networks, Deep Q-learning, Distributed energy resources, Distributed power generation, Microgrid energy management system},
	pages = {1--5},
}

@inproceedings{aklo_reinforcement_2021,
	title = {Reinforcement {Learning} {Based} {Energy} {Storage} {Units} {Scheduling} {Considering} {Point} of {Common} {Coupling} {Constraint}},
	doi = {10.1109/ISMEE54273.2021.9774197},
	abstract = {In this paper, agent-aggregators cooperation has been introduced in Smart Microgrid (SMG) consisting of household users, Photo Voltaic array (PV), and Local Energy Storage System (LESS). The SMG has Energy Management System called agent deal with two aggregators to purchase the energy for the consumers. Each aggregator supplying a limited level of energy from different energy resource, where one aggregator depend on Community Energy storage System to provide power in one direction to the users and the other aggregator supplying power from the utility grid. The job of the agent is to decide the optimum amount of purchasing power from the aggregators at the lowest cost to supply the users and to charge the LESS taking into account the constraints of supplying limitations for both CESS and utility grid at Point of Common Coupling. Each aggregator supplies a limited level of energy from different energy resource, where one aggregator depend on the Community Energy storage System (CESS) to provide power in one direction to the users and the other aggregator supplying power from the utility grid. The job of the agent is to decide the optimum amount of purchasing power from the aggregators at the lowest cost to provide the users and to charge the LESS taking into account the constraints of providing limitations for both CESS and utility grid at Point of Common Coupling (PCC).A model-free Reinforcement Learning (RL) method is used as an essential strategy to achieve the proposed task using Deep Q-Network (DQN). The simulation result is done and the results are verified using Improved Particular Swarm (IPSO) as a benchmark method. The obtained results show the efficiency and effectiveness of the method used},
	booktitle = {2021 3rd {International} {Symposium} on {Material} and {Electrical} {Engineering} {Conference} ({ISMEE})},
	author = {Aklo, Nabil Jalil and Turky Rashid, Mofeed},
	month = nov,
	year = {2021},
	keywords = {Reinforcement learning, Uncertainty, Tariffs, Costs, reinforcement learning, aggregator, Benchmark testing, community energy storage system, Couplings, deep q-network, Energy resources, local energy storage system, smart microgrid},
	pages = {1--8},
}

@article{sangoleye_reinforcement_2023,
	title = {Reinforcement {Learning}-{Based} {Demand} {Response} {Management} in {Smart} {Grid} {Systems} {With} {Prosumers}},
	volume = {17},
	issn = {1937-9234},
	doi = {10.1109/JSYST.2023.3248320},
	abstract = {In this article, we introduce a reinforcement learning-based price-driven demand response management (DRM) mechanism in smart grid systems consisting of prosumers. Our proposed approach accounts for the prosumers' behavioral characteristics and models the emerging interactions among all the involved actors in the smart grid system, i.e., prosumers, energy management system (EMS), and utility companies. In particular, an off-policy reinforcement learning is introduced enabling the EMS to determine the optimal price that should be announced to the prosumers on an hourly-basis toward minimizing the overall system's cost. In this process, the utility companies' hourly-based wholesale price and the prosumers' energy generation and consumption characteristics are considered as input. At the same time, the prosumers' optimal amount of purchased energy is determined in a real-time manner. The presented numerical results demonstrate the success of the proposed DRM model to deal with the incomplete information availability scenarios, regarding the prosumers' energy selling and purchasing patterns, compared to the state of the art. Also, the detailed comparative evaluation against other price-based DRM approaches, e.g., cap-based and day-ahead pricing, shows the benefits of the proposed DRM model in terms of adapting in a real-time manner to the prosumers' energy demand, while jointly minimizing the overall system's long-term cost.},
	number = {2},
	journal = {IEEE Systems Journal},
	author = {Sangoleye, Fisayo and Jao, Jenilee and Faris, Kimberly and Tsiropoulou, Eirini Eleni and Papavassiliou, Symeon},
	month = jun,
	year = {2023},
	keywords = {Reinforcement learning, Smart grids, Energy management, Costs, reinforcement learning, Games, Energy consumption, Companies, Decision-making, prosumers, demand response management (DRM), smart grid systems, system modeling},
	pages = {1797--1807},
}

@inproceedings{mujeeb_impact_2021,
	title = {Impact of {Impulsive} load {Scenario} on {Isolated} {Mini}-{Grid} and its {Neutralization} with {BESS}},
	doi = {10.1109/ICECube53880.2021.9628210},
	abstract = {In this paper, the novel model of Battery Energy Storage System (BESS) is executed in MATLAB simulation to analyze the impact of impulsive effect of high or sudden switching inductive loads behavior on an isolated mini-hybrid grid equipped with DG’s and RG’s to cultivate power from different sources. Battery Energy Storage is used to provide ancillary services such as balancing the grid’s voltage and frequency, and also to store charge during off-peak hours and during periods of excess wind and solar energy in order to maximize energy utilization during peak hours. The controller plays the key role for decision-making and switching operations because it uses the Intelligent Proportional Integrate Derivative function to maintain a constant frequency in a single fixed point. This BESS-integrated technology has the potential to be extremely effective and robust in ensuring the smooth operation of grids, as well as minimizing the fluctuation of the electricity market.},
	booktitle = {2021 {International} {Conference} on {Computing}, {Electronic} and {Electrical} {Engineering} ({ICE} {Cube})},
	author = {Mujeeb, Asad and Ali, Mazhar and Mu, Chaoxu and Rasheed, Nabeel and Khan, Tahir and Ullah, Hameed},
	month = oct,
	year = {2021},
	keywords = {Generators, Wind energy, Analytical models, Switches, Battery Energy Storage System (BESS), Solar energy, Distributed Generators (DG’s), Reinforcement Learning (RL), Renewable Generator (RG’s), Smoothing methods, Supply and demand},
	pages = {1--7},
}

@inproceedings{sekizaki_intelligent_2015,
	title = {An intelligent {Home} {Energy} {Management} {System} with classifier system},
	doi = {10.1109/IWCIA.2015.7449452},
	abstract = {A Home Energy Management System (HEMS), which enables residential users to effectively manage the energy consumption in their home, can optimize the operation schedule of household appliances according to environments, e.g. indoor temperature and electricity prices. HEMS monitors the environment and the energy usage, visually represents the energy consumption, and effectively controls the appliances, thus HEMS helps to reduce the energy cost as well as to maintain users' comfort. The optimal operation schedule of the appliances for the cost saving, however, does not always coincident with the user's desired operation schedule of the appliances because the optimal operation schedule is fixed by HEMS and hence the users could not change the operation schedule even when they need. From this point of view, we address the energy management system which enables the users to use the appliances at their disposal, not only for saving the cost. Because the operation schedule of the household appliances which does not disturb the user's behavior should be calculated, we develop the intelligent HEMS based on eXtended Classifier System (XCS) in this paper. The effectiveness of the proposed HEMS is confirmed by the computational experiments.},
	booktitle = {2015 {IEEE} 8th {International} {Workshop} on {Computational} {Intelligence} and {Applications} ({IWCIA})},
	author = {Sekizaki, Shinya and Hayashida, Tomohiro and Nishizaki, Ichiro},
	month = nov,
	year = {2015},
	note = {ISSN: 1883-3977},
	keywords = {Home appliances, Optimization, Batteries, Energy management, Reinforcement Learning, Schedules, Energy consumption, Home energy management system, Extended classifier system, User comfort, Water heating},
	pages = {9--14},
}

@inproceedings{nazeri_black-box_2023,
	title = {Black-{Box} {Stealthy} {Frequency} {Spectrum} {Attack} on {LSTM}-based {Power} {Load} {Forecasting} in an {Energy} {Management} {System} with {Islanded} {Microgrid}},
	doi = {10.1109/NAPS58826.2023.10318557},
	abstract = {This research paper introduces a novel approach called Frequency Spectrum Attack (FSA) and assesses its impact on load forecasting and energy management within a microgrid. FSA leverages Fast Fourier Transform to convert load data into the frequency domain, thereby uncovering significant patterns during the learning phase. It strategically adjusts the amplitudes of dominant frequencies within the healthy amplitude range to maintain stealthiness against statistical analysis, contributing to its effectiveness. We evaluate the performance of FSA using LSTM network as a state-of-the-art technology for load forecasting. Our findings reveal that FSA results in a threefold increase in Mean Absolute Error (MAE) compared to normal conditions and a 70\% increase compared to noise injection attacks. Additionally, FSA indirectly boosts battery utilization in the Energy Management System (EMS) by 45\%. Furthermore, FSA effectively evades detection by frequency monitoring and control units in the microgrid, making frequency deviations inconspicuous.},
	booktitle = {2023 {North} {American} {Power} {Symposium} ({NAPS})},
	author = {Nazeri, Amirhossein and Biroon, Roghieh A. and Pisu, Pierluigi},
	month = oct,
	year = {2023},
	note = {ISSN: 2833-003X},
	keywords = {Batteries, Microgrids, Deep learning, Load forecasting, LSTM, Microgrid, Closed box, Cybersecurity, Energy Management System, Frequency Spectrum Attack, Frequency-domain analysis, Medical services, Transforms},
	pages = {1--6},
}

@inproceedings{thattai_consumer-centric_2023,
	title = {Consumer-{Centric} {Home} {Energy} {Management} {System} {Using} {Trust} {Region} {Policy} {Optimization}- {Based} {Multi}-{Agent} {Deep} {Reinforcement} {Learning}},
	doi = {10.1109/PowerTech55446.2023.10202803},
	abstract = {Autonomous home energy management system (HEMS) is the key to improving energy efficiency in the active distribution network. This HEMS also needs to maintain customer satisfaction while maximizing cost savings under dynamic price conditions, incorporating uncertainties of consumer behavior, and renewable energy generation. In this paper, a consumer-centric HEMS using Trust Region Policy Optimization (TRPO) based multi-agent deep reinforcement learning (DRL) is presented. This Multi-Agent TRPO (MA- TRPO) based HEMS is trained to respond to the dynamic retail price and the local energy generation by scheduling the Interruptible-Deferrable load (IDA) and Battery Energy Storage System (BESS). Five-minute retail electricity price derived from wholesale market price and the PV generation data derived from real-world PV profiles are used to train the proposed MA- TRPO-based HEMS in discrete action space. The performance of the proposed HEMS is relatively better than the existing policy-gradient-based on-policy approaches such as Proximal Policy Optimization and Policy Gradient-based HEMS as validated via training and testing using the same dataset.},
	booktitle = {2023 {IEEE} {Belgrade} {PowerTech}},
	author = {Thattai, Kuthsav and Ravishankar, Jayashri and Li, Chaojie},
	month = jun,
	year = {2023},
	keywords = {Reinforcement learning, Deep reinforcement learning, Uncertainty, Training, Costs, Deep learning, Dynamic scheduling, Energy Management System, Multi-Agent, Smart Home, Trust region policy optimization, Washing machines},
	pages = {1--6},
	file = {Thattai et al. - 2023 - Consumer-Centric Home Energy Management System Usi.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\PWRDCNYM\\Thattai et al. - 2023 - Consumer-Centric Home Energy Management System Usi.pdf:application/pdf},
}

@inproceedings{ashenov_dynamic_2021,
	title = {Dynamic {Cloud} and {ANN} based {Home} {Energy} {Management} {System} for {End}-{Users} with {Smart}-{Plugs} and {PV} {Generation}},
	doi = {10.1109/TPEC51183.2021.9384980},
	abstract = {Over the past decades, the importance of energy management has been raised due to increasing electricity demand and consumers' unawareness of their electricity consumption. The paper proposes a Home Energy Management System (HEMS) that implements an Artificial Neural Network (ANN) and reinforcement learning-based algorithm to schedule the home appliances as well as an optimized and efficient way of profiting from renewable energy source with the utilization of energy storage systems. The objective of the HEMS is to decrease energy cost, customer dissatisfaction, and grid overloading. Two types of appliances were considered: non-shiftable controllable, shiftable interruptible. A simulation of the case study where the forecasted values were fed to the HEMS algorithm demonstrated a total profit increase by 15\% due to the renewable energy source, making the value of total profit 63.5 units in one day. The simulation was done for a single house loading profile and throughout the capacity change of the energy storage system, a maximum profit was derived. These results show the efficient function of HEMS with the utilization of the proposed ANN, reinforcement learning, and energy decision algorithm.},
	booktitle = {2021 {IEEE} {Texas} {Power} and {Energy} {Conference} ({TPEC})},
	author = {Ashenov, Nursultan and Myrzaliyeva, Madina and Mussakhanova, Meruyert and Nunna, H. S. V. S. Kumar},
	month = feb,
	year = {2021},
	keywords = {Home appliances, Reinforcement learning, Renewable energy sources, Load modeling, Demand response, Schedules, Energy storage, Artificial neural network, Artificial neural networks, Energy management systems, Home energy management, Smart Plug, Solar energy management},
	pages = {1--6},
}

@inproceedings{ochoa_efficient_2022,
	title = {Efficient {Bidding} of a {PV} {Power} {Plant} with {Energy} {Storage} {Participating} in {Day}-{Ahead} and {Real}-{Time} {Markets} {Using} {Artificial} {Neural} {Networks}},
	doi = {10.1109/PESGM48719.2022.9916732},
	abstract = {This paper proposes the use of Artificial Neural Networks (ANN) for the efficient bidding of a Photovoltaic power plant with Energy Storage System (PV-ESS) participating in Day-Ahead (DA) and Real-Time (RT) energy and reserve markets under uncertainty. The Energy Management System (EMS) is based on Multi-Agent Deep Reinforcement Learning (MADRL). The MADRL scheme aims to maximize the profit of the hybrid PV-ESS plant through an efficient bidding in both markets. Results show that the MADRL framework can fulfill both the financial and physical constraints faced by the PV-ESS plant while providing energy and ancillary services. Daily market incomes have comparable mean values regarding traditional optimization approaches (average value of 1839 USD), but with a 45.3\% smaller variance. Furthermore, it maintains a reference-tracking performance of 86.63\% for one-year-round participation, against a 73.05\% and 79.13\% performance obtained with scenario-based robust and stochastic programming implementations, respectively.},
	booktitle = {2022 {IEEE} {Power} \& {Energy} {Society} {General} {Meeting} ({PESGM})},
	author = {Ochoa, Tomás and Gil, Esteban and Angulo, Alejandro},
	month = jul,
	year = {2022},
	note = {ISSN: 1944-9933},
	keywords = {multi-agent deep reinforcement learning, Real-time systems, Reinforcement learning, Uncertainty, Stochastic processes, Artificial neural networks, energy storage, electricity markets, Photovoltaic systems, energy management system, Programming, solar generation},
	pages = {1--5},
	file = {Ochoa et al. - 2022 - Efficient Bidding of a PV Power Plant with Energy .pdf:C\:\\Users\\Jacob\\Zotero\\storage\\FSRQ2PV4\\Ochoa et al. - 2022 - Efficient Bidding of a PV Power Plant with Energy .pdf:application/pdf},
}

@inproceedings{selim_optimal_2022-1,
	title = {Optimal {Scheduling} of {Grid} {Supply} and {Batteries} {Operation} in {Residential} {Building}: {Rules} and {Learning} {Approaches}},
	doi = {10.1109/SCEMS56272.2022.9990764},
	abstract = {This article discusses and simulates a demand management algorithm in a building with a battery energy storage system (BESS) and on-grid supply scheduling using deep reinforcement learning algorithms (DRL) and rule-based controllers (Fuzzy logic). BESS is used for supplying the load profile and minimizing the electricity bills of the building. Deferrable loads of the building are controlled to reduce power consumption during peak time. Controllers used in this paper aim to optimize multi-objectives, including the cost of utility bills, state of health of battery systems (SOH), and reliability of the power source. First, this article works with optimizing BESS using the fuzzy logic controller and compares the results with DRL agent outputs. Secondly, commercial loads are modeled based on the deferrability index to be introduced into the optimization problem. Finally, the paper presents a model for controlling the battery and on-grid supply schedule, minimizing the annual electricity bill without draining the battery’s SOH and disturbing the residential comfort of household appliances.},
	booktitle = {2022 {IEEE} 5th {Student} {Conference} on {Electric} {Machines} and {Systems} ({SCEMS})},
	author = {Selim, Alaa and Mo, Huadong and Pota, Hemanshu},
	month = nov,
	year = {2022},
	note = {ISSN: 2771-7577},
	keywords = {Batteries, Reinforcement learning, Optimal scheduling, Reinforcement Learning, optimization, Buildings, Schedules, Fuzzy logic, Scheduling, Energy Storage, Fuzzy Logic, Load demand, State of Health},
	pages = {1--6},
}
