
@article{louback_review_2024,
	title = {A review of the design process of energy management systems for dual-motor battery electric vehicles},
	volume = {193},
	issn = {1364-0321},
	doi = {10.1016/j.rser.2024.114293},
	abstract = {Dual -motor battery electric vehicles (DM-BEVs) are a trending technology in the electric vehicle market. They have the potential to achieve higher energy savings and dynamic performances compared to singlespeed, single -motor BEVs. However, a more complex and robust energy management system (EMS) is needed to achieve these benefits. Hence, this work reviews the design process and real-time implementation of EMSs tailored for DM-BEVs, starting from the fundamental concepts of two -motor coupling. The advantages and disadvantages of the most popular dual -motor architectures and their influence on the EMS design complexity are presented, followed by a revision of the reported energy management controllers. Besides the most prominent methods, classified as rule -based or optimization -based techniques, reinforcement learningbased EMSs are discussed in detail, given their near -optimal, real-time implementation and adaptability to newer, unforeseen drive cycles. Finally, the standard procedures and equipment required to assess the EMS' performance with hardware -in -the -loop tests are presented. Conclusions and open challenges for the energy management controllers of DM-BEVs are discussed at the end of this work.},
	journal = {RENEWABLE \& SUSTAINABLE ENERGY REVIEWS},
	author = {Louback, Eduardo and Biswas, Atriya and Machado, Fabricio and Emadi, Ali},
	month = apr,
	year = {2024},
	keywords = {Reinforcement learning, Energy management system, Battery electric vehicles, Design process, Dual-motor powertrain, Hardware-in-the-loop test},
}

@article{dong_strategic_2021,
	title = {A {Strategic} {Day}-ahead bidding strategy and operation for battery energy storage system by reinforcement learning},
	volume = {196},
	issn = {0378-7796},
	doi = {10.1016/j.epsr.2021.107229},
	abstract = {The Battery Energy Storage System (BESS) plays an essential role in the smart grid, and the ancillary market offers a high revenue. It is important for BESS owners to maximise their profit by deciding how to balance between the different offers and bidding with the rivals. Therefore, this paper formulates the BESS bidding problem as a Markov Decision Process(MDP) to maximise the total profit from the e Automation Generation Control (AGC) market and the energy market, considering the factors such as charging/discharging losses and the lifetime of the BESS. In the proposed algorithm, function approximation technology is introduced to handle the continuous massive bidding scales and avoid the dimension curse. As a model-free approach, the proposed algorithm can learn from the stochastic and dynamic environment of a power market, so as to help the BESS owners to decide their bidding and operational schedules profitably. Several case studies illustrate the effectiveness and validity of the proposed algorithm.},
	journal = {ELECTRIC POWER SYSTEMS RESEARCH},
	author = {Dong, Yi and Dong, Zhen and Zhao, Tianqiao and Ding, Zhengtao},
	month = jul,
	year = {2021},
	keywords = {Reinforcement learning, Battery energy storage system (BESS), Power market bidding},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\9PPDG3AS\\Dong et al. - 2021 - A Strategic Day-ahead bidding strategy and operati.pdf:application/pdf},
}

@article{giglio_efficient_2023,
	title = {An {Efficient} {Artificial} {Intelligence} {Energy} {Management} {System} for {Urban} {Building} {Integrating} {Photovoltaic} and {Storage}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3247636},
	abstract = {The emerging leading role of green energy in our society pushes the investigation of new economic and technological solutions. Green energies and smart communities increase efficiency with the use of digital solutions for the benefits of inhabitants and companies. The paper focuses on the development of a methodology for the energy management, combining photovoltaics and storage systems, considering as the main case study a multi-story building characterized by a high density of households, used to generate data which allow feasibility foresights. The physical model of the algorithm is composed by two main elements: the photovoltaics modules and the battery energy storage system. In addition, to gain information about the real-time consumption a machine learning module is included in our approach to generate predictions about the near future demand. The benefits provided by the method are evaluated with an economic analysis, which computes the return of the investment using the real consumptions of a Boarding School, located in Turin (Italy). The case study analyzed in this article showed an increase in purchased energy at the minimum price from 25\% to 91\% and a 55\% reduction in the electricity bill compared to most solutions on the market, with no additional costs and a stabilizing effect on the grid. Finally, the economic analysis shows that the proposed method is a profitable investment, with a breakeven point of thirteen years, due to the very simple implementation and the zero additional cost requested.},
	journal = {IEEE Access},
	author = {Giglio, Enrico and Luzzani, Gabriele and Terranova, Vito and Trivigno, Gabriele and Niccolai, Alessandro and Grimaccia, Francesco},
	year = {2023},
	keywords = {Smart grids, Forecasting, Renewable energy sources, Deep learning, Buildings, Energy storage, energy storage, energy management systems, Computer architecture, environmental economics, Photovoltaic systems, renewable energy sources},
	pages = {18673--18688},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\GEZVWBGK\\Giglio et al. - 2023 - An Efficient Artificial Intelligence Energy Manage.pdf:application/pdf},
}

@article{binyamin_artificial_2024,
	title = {Artificial intelligence-powered energy community management for developing renewable energy systems in smart homes},
	volume = {51},
	issn = {2211-467X},
	doi = {10.1016/j.esr.2023.101288},
	abstract = {The increase in demand due to scientific innovation and economic expansion raises challenges linked to environmental impact and sustainable market development. This study analyzes the role played by Peer -to -Peer (P2P) energy trading in system operation. Several case studies with four distinct prosumer models, each fitted with diverse Energy Storage Systems (ESS), photovoltaic (PV) systems, and responsive demand technologies such as Electric Vehicles (EV), are examined. An economic analysis is conducted using the developed interface. An energy management system establishes a dynamic market framework, enabling energy trading via P2P market operators and distribution system operators. The implemented trading platform is chosen depending on pricing variations across different time intervals for home models. The P2P energy trading system employs mathematical modeling via deep learning to achieve an optimal solution that minimizes costs. The study uses other domestic models and optimization techniques to explore the amount of energy traded across households and timeframes. Additionally, it investigates the accomplishment of two-way energy transfer in electric cars, the importance of energy storage and photovoltaic systems, and various housing scenarios concerning peer -to -peer energy trading. Additionally, the system's advantages are demonstrated to participants beforehand by validating and presenting data through an input and output system that accepts these instances.},
	journal = {ENERGY STRATEGY REVIEWS},
	author = {Binyamin, Sami Saeed and Ben Slama, Sami Abdullah and Zafar, Bassam},
	month = jan,
	year = {2024},
	keywords = {Deep reinforcement learning, Artificial intelligence, Electrical vehicle, Energy charing community, Peer to peer energy trading, Photovoltaic system},
}

@article{yi_integrated_2022,
	title = {An integrated energy management system using double deep {Q}-learning and energy storage equipment to reduce energy cost in manufacturing under real-time pricing condition: {A} case study of scale-model factory},
	volume = {38},
	issn = {1755-5817},
	doi = {10.1016/j.cirpj.2022.07.009},
	abstract = {Reducing energy costs is an emerging aspect in the research on the economic and environmental dimen-sions of manufacturing systems. The share of electricity cost accounts for approximately 60 \% of the total energy cost of a manufacturing system, whereas the share of oil, coal, and gas accounts for the remaining 40 \%. The electricity cost is dependent on the electricity price and usage. In terms of the electricity price, one of the pricing strategies widely used in the USA and Europe is called real-time pricing (RTP), which is characterised by hourly price changes. Compared to other pricing strategies, RTP yields the highest reward and the highest risk. In the RTP strategy, the electricity price is influenced by the supply and demand of the energy market. Hence, the energy cost of manufacturing cannot be determined by the manufacturing companies, implying a high level of risk. However, if manufacturing companies seize the opportunity to perform more manufacturing tasks when the energy price is low, the cost-savings will be significant, im-plying a high level of reward. In this study, we propose an integrated energy management system (IEMS) to reduce the energy cost of manufacturing systems. The IEMS consists of an energy storage equipment and an intelligent switch mechanism. When the electricity price is high, the manufacturing system is powered by the energy storage equipment. When the electricity price is low, the manufacturing system is powered by the public electricity grid, and the energy storage equipment is charged. The decision-making of these operations is performed by the intelligent switch mechanism based on double deep Q-learning. To validate this framework, a case study is conducted, in which an IEMS is developed to reduce the electricity cost of a scale-model factory. Based on an online test of the IEMS in different manufacturing cycles, it is concluded that the proposed IEMS approach achieves a cost reduction of approximately 57.21 \%.(c) 2022 The Authors. CC\_BY\_NC\_ND\_4.0},
	journal = {CIRP JOURNAL OF MANUFACTURING SCIENCE AND TECHNOLOGY},
	author = {Yi, Li and Langlotz, Pascal and Hussong, Marco and Glatt, Moritz and Sousa, Fabio J. P. and Aurich, Jan C.},
	month = aug,
	year = {2022},
	keywords = {Reinforcement learning, Energy management system, Double deep Q-learning, Energy cost, Manufacturing system, Real-time pricing},
	pages = {844--860},
	file = {Yi et al. - 2022 - An integrated energy management system using doubl.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\6F4UGQV9\\Yi et al. - 2022 - An integrated energy management system using doubl.pdf:application/pdf},
}

@article{li_attentive_2024,
	title = {Attentive {Convolutional} {Deep} {Reinforcement} {Learning} for {Optimizing} {Solar}-{Storage} {Systems} in {Real}-{Time} {Electricity} {Markets}},
	volume = {20},
	issn = {1941-0050},
	doi = {10.1109/TII.2024.3352229},
	abstract = {This article studies the synergy of solar-battery energy storage system (BESS) and develops a viable strategy for the BESS to unlock its economic potential by serving as a backup to reduce solar curtailments while also participating in the electricity market. We model the real-time bidding of the solar-battery system as two Markov decision processes for the solar farm and the BESS, respectively. We develop a novel deep reinforcement learning (DRL) algorithm to solve the problem by leveraging attention mechanism (AC) and multigrained feature convolution to process DRL input for better bidding decisions. Simulation results demonstrate that our AC-DRL outperforms two optimization-based and one DRL-based benchmarks by generating 23\%, 20\%, and 11\% higher revenue, as well as improving curtailment responses. The excess solar generation can effectively charge the BESS to bid in the market, significantly reducing solar curtailments by 76\% and creating synergy for the solar-battery system to be more viable.},
	number = {5},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Li, Jinhao and Wang, Changlong and Wang, Hao},
	month = may,
	year = {2024},
	keywords = {Optimization, Real-time systems, Batteries, Electricity supply industry, Battery energy storage system (BESS), deep reinforcement learning (DRL), Degradation, electricity market, Nanoelectromechanical systems, solar curtailment, solar photovoltaic (PV), Solar power generation},
	pages = {7205--7215},
	file = {Submitted Version:C\:\\Users\\Jacob\\Zotero\\storage\\BKIHFRJZ\\Li et al. - 2024 - Attentive Convolutional Deep Reinforcement Learnin.pdf:application/pdf},
}

@article{samadi_decentralized_2020,
	title = {Decentralized multi-agent based energy management of microgrid using reinforcement learning},
	volume = {122},
	issn = {0142-0615},
	doi = {10.1016/j.ijepes.2020.106211},
	abstract = {This paper proposes a multi-agent based decentralized energy management approach in a grid-connected microgrid (MG). The MG comprises of wind and photovoltaic resources, diesel generator, electrical energy storage, and combined heat and power generations to serve electrical and thermal loads at the lower-level of energy management system (EMS). All distributed energy resources (DERs) and customers are modelled as self-interested agents who adopt reinforcement learning to optimize their behaviours and operation costs. Based on this algorithm, agents have the capability to interact with each other in a distributed manner and find the best strategy in competitive environment. At the upper-level of EMS, there is an energy management agent that gathers the information of agents of lower-level and clears the MG electrical and thermal energy market in line with predetermined goals. Utilizing energy availability from different DERs and variety of customers' consumption patterns, considering uncertainty of renewable generation and load consumption and taking into account technical constraint of DERs are the strengths of the presented framework. Performance of the proposed algorithm is investigated under different conditions of agents learning and using epsilon-greedy, soft-max and upper confidence bound methods. The simulation results verify efficacy of the proposed approach.},
	journal = {INTERNATIONAL JOURNAL OF ELECTRICAL POWER \& ENERGY SYSTEMS},
	author = {Samadi, Esmat and Badri, Ali and Ebrahimpour, Reza},
	month = nov,
	year = {2020},
	keywords = {Reinforcement learning, Distributed energy resources, Microgrid energy management system, Multi-agent systems},
	file = {Samadi et al. - 2020 - Decentralized multi-agent based energy management .pdf:C\:\\Users\\Jacob\\Zotero\\storage\\H328U336\\Samadi et al. - 2020 - Decentralized multi-agent based energy management .pdf:application/pdf},
}

@article{li_deep_2023,
	title = {Deep reinforcement learning for wind and energy storage coordination in wholesale energy and ancillary service markets},
	volume = {14},
	issn = {2666-5468},
	url = {https://www.sciencedirect.com/science/article/pii/S2666546823000526},
	doi = {https://doi.org/10.1016/j.egyai.2023.100280},
	abstract = {Wind energy has been increasingly adopted to mitigate climate change. However, the variability of wind energy causes wind curtailment, resulting in considerable economic losses for wind farm owners. Wind curtailment can be reduced using battery energy storage systems (BESS) as onsite backup sources. Yet, this auxiliary role may significantly weaken the economic potential of BESS in energy trading. Ideal BESS scheduling should balance onsite wind curtailment reduction and market bidding, but practical implementation is challenging due to coordination complexity and the stochastic nature of energy prices and wind generation. We investigate the joint-market bidding strategy of a co-located wind-battery system in the spot and Regulation Frequency Control Ancillary Service markets. We propose a novel deep reinforcement learning-based approach that decouples the systemâ€™s market participation into two related Markov decision processes for each facility, enabling the BESS to absorb onsite wind curtailment while performing joint-market bidding to maximize overall operational revenues. Using realistic wind farm data, we validated the coordinated bidding strategy, with outcomes surpassing the optimization-based benchmark in terms of higher revenue by approximately 25\% and more wind curtailment reduction by 2.3 times. Our results show that joint-market bidding can significantly improve the financial performance of wind-battery systems compared to participating in each market separately. Simulations also show that using curtailed wind generation as a power source for charging the BESS can lead to additional financial gains. The successful implementation of our algorithm would encourage co-location of generation and storage assets to unlock wider system benefits.},
	journal = {Energy and AI},
	author = {Li, Jinhao and Wang, Changlong and Wang, Hao},
	year = {2023},
	keywords = {Deep reinforcement learning, Electricity market, Wind curtailment, Wind-battery system},
	pages = {100280},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\5QHMN5IB\\Li et al. - 2023 - Deep reinforcement learning for wind and energy st.pdf:application/pdf},
}

@article{hussain_deep_2022,
	title = {Deep reinforcement learning-based operation of fast charging stations coupled with energy storage system},
	volume = {210},
	issn = {0378-7796},
	doi = {10.1016/j.epsr.2022.108087},
	abstract = {Fast charging stations (FCSs) can reduce the charging time of electric vehicles (EVs) and thus can help in the widespread adoption of EVs. However, FCSs may result in the power system overload. Therefore, the deployment of the battery energy storage system (BESS) in FCSs is considered as a potential solution to avoid system overload. However, the optimal operation of FCSs equipped with BESS is challenging due to the involvement of several uncertainties, such as EV arrival/departure times and electricity prices. Therefore, in this study, a deep reinforcement learning-based method is proposed to operate FCSs with BESS under these uncertainties. The stateof-the-art soft actor-critic method (SAC) is adopted and the model is trained with one-year data to cover seasonality and different types of days (working days and holidays). The performance of SAC is compared with two other deep reinforcement learning methods, i.e., deep deterministic policy gradient and twin delayed deep deterministic policy gradient. A comprehensive reward function is devised to train the model offline, which can then be used for the real-time operation of FCS with BESS under different uncertainties. The trained model has successfully reduced the peak load of the FCS during both weekdays and holidays by optimizing the operation of the BESS. In addition, the robustness of the proposed model against different EV arrival scenarios and extreme market price scenarios is also evaluated. Simulation results have shown that the proposed model can reduce the peak load of the FCS under diverse conditions in the desired fashion.},
	journal = {ELECTRIC POWER SYSTEMS RESEARCH},
	author = {Hussain, Akhtar and Bui, Van-Hai and Kim, Hak-Man},
	month = sep,
	year = {2022},
	keywords = {Reinforcement learning, Deep reinforcement learning, Smart grid, Electric vehicles, Charging station, Energy storage system},
	file = {Hussain et al. - 2022 - Deep reinforcement learning-based operation of fas.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\BDBFJCQC\\Hussain et al. - 2022 - Deep reinforcement learning-based operation of fas.pdf:application/pdf},
}

@article{tomin_design_2022,
	title = {Design and optimal energy management of community microgrids with flexible renewable energy sources},
	volume = {183},
	issn = {0960-1481},
	doi = {10.1016/j.renene.2021.11.024},
	abstract = {Energy communities is a new, but already successful prosumer model of the local energy systems' construction. It is based on distributed energy sources and the electricity consumers' flexibility who are the members of the community. In search of the most effective ways to interact within themselves and with the external energy system, local energy communities become platforms for exciting experiments in the field of new energy practices including local markets for flexibility, building cooperative micro grids, achieving energy autonomy, and many others. This work aims to present a unified approach to building and optimally managing the community microgrids with an internal market, given the social, environmental, and economic benefits of a particular location of such a community. A new modeling framework is introduced, based on bilevel programming and reinforcement learning, for structuring and solving the internal local market of a community microgrids, composed of entities that may exchange energy and services among themselves. The overall framework is formulated in the form of a bilevel model, where the lower level problem clears the market, while the upper level problem plays the role of the community microgrid operator (Community EMS). We strengthen the traditional bilevel problem statement by the local energy management system (Local EMS) introduction based on Monte-Carlo tree search algorithm. Our approach makes it possible to enable interaction of the local control systems for microgrids with the community microgrid operator as part bilevel programming problem solution. Numerical results obtained on the real test case of the microgrid community for the settlements located in the Transbaikal National Park (Russia), which include various renewable energy sources (wind, solar power, biomass gasifiers) and storage devices, show reduction of the LCOE index from 20\% to 40\% and improving the quality of electricity supply to the analyzed settlements. (c) 2021 Elsevier Ltd. All rights reserved.},
	journal = {RENEWABLE ENERGY},
	author = {Tomin, Nikita and Shakirov, Vladislav and Kozlov, Aleksander and Sidorov, Denis and Kurbatsky, Victor and Rehtanz, Christian and Lora, Electo E. S.},
	month = jan,
	year = {2022},
	keywords = {Reinforcement learning, Bilevel programming, Biomass gasifier generator, Community microgrid, LCOE, Local market},
	pages = {903--921},
}

@article{salari_fuzzy_2023,
	title = {Fuzzy {Q}-learning-based approach for real-time energy management of home microgrids using cooperative multi-agent system},
	volume = {95},
	issn = {2210-6707},
	doi = {10.1016/j.scs.2023.104528},
	abstract = {The development of plug-in electrical vehicles (PEVs) and distributed energy resources in home microgrids (H-MGs) is gaining attention in recent years. Accordingly, it is vital to apply a suitable energy management system to provide the required energy of the PEV and ensure the health of the energy storage systems in the H-MG. This paper proposes a continuous real-time cooperative multi-agent system (MAS) for H-MG. Real-time MAS interacts with H-MG agents to perform as independent learners applying a distributed and cooperative reinforcement learning method, while state variables are shared to coordinate their real-time behavior. Therefore, the fuzzy Q-learning (FQL) method is investigated to control the agents in the continuous state space and achieve an efficient solution. The experimental results highlight the effectiveness of the suggested control strategy to guarantee the energy supply and reduce the electricity market price. The results of the simulation demonstrate that using the proposed cooperative MAS with the real-time FQL method in the energy management of the H-MG will reduce the electricity market price by 10\%, increase the health of the storage system by 35.67\%, and enhance the utilization of the PV system to charge PEV for 8\% at the peak load demand.},
	journal = {SUSTAINABLE CITIES AND SOCIETY},
	author = {Salari, Azam and Ahmadi, Seyed Ehsan and Marzband, Mousa and Zeinali, Mahdi},
	month = aug,
	year = {2023},
	keywords = {Reinforcement learning, Fuzzy Q-learning, Home microgrid, Multi-agent system, Real-time energy management},
}

@article{pla_leveraging_2024,
	title = {Leveraging battery electric vehicle energy storage potential for home energy saving by model predictive control with backward induction},
	volume = {372},
	issn = {0306-2619},
	doi = {10.1016/j.apenergy.2024.123800},
	abstract = {Battery electric vehicles (BEVs) are gaining market shares due to their ability to employ clean energy, their smooth operation and reduced noise, pollutant emissions and maintenance. Batteries are one of the key technologies in BEV since they strongly affect the vehicle cost and driving range, two of the major concerns of BEV costumers. While the energy storing capabilities of BEVs usually exceed commuting requirements, batteries can be also utilized for home energy management system using bi-directional charging technology. This paper introduces an efficient energy management system for a smart home with BEVs and a bidirectional charger by addressing the corresponding optimal control problem of deciding the battery charging and discharging strategy to minimize energy expenditure and cost. To this aim, the electricity price and expenditure of upcoming weeks is forecasted using data from the present week, and a model of the complete system is used to find the optimal solutions by means of backward induction in a receding horizon approach. The proposed strategy relies on currently available information about the home and vehicle energy expenditure and energy prices in the recent past. The results of the study show a reduction of the electricity cost above 20\% in the considered use-case.},
	journal = {APPLIED ENERGY},
	author = {Pla, Benjamin and Bares, Pau and Aronis, Andre Nakaema and Anuratha, Sanjith},
	month = oct,
	year = {2024},
	keywords = {Reinforcement learning, Smart home energy management system, Smart grid, Battery electric vehicles, Bidirectional charging},
	file = {Pla et al. - 2024 - Leveraging battery electric vehicle energy storage.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\AFVUK8M6\\Pla et al. - 2024 - Leveraging battery electric vehicle energy storage.pdf:application/pdf},
}

@article{yang_mitigating_2024,
	title = {Mitigating long-term financial risk for large customers via a hybrid procurement strategy considering power purchase agreements},
	volume = {295},
	issn = {0360-5442},
	doi = {10.1016/j.energy.2024.131038},
	abstract = {In facing urgent climate issues, large electricity customers committed to the RE100 initiative, aiming to transition entirely to renewable energy sources (RES). However, they encounter significant challenges in managing the unpredictability of RES generation and the volatility of market prices. This study unveils a groundbreaking hybrid procurement model that integrates Power Purchase Agreements (PPAs) with Battery Energy Storage Systems (BESS) to mitigate these financial risks through a novel method. Employing a sophisticated Mixed Integer Linear Programming (MILP) model alongside an innovative deep learning forecast for long-term PPAs planning, we present a unique solution that significantly boosts financial returns and enhances risk mitigation for large electricity customers. Validated with real-world data across three distinct customer profiles, our model demonstrates a notable increase in expected Net Present Value (NPV) by up to 13.58\% compared to traditional strategies and improved earnings stability under adverse market conditions. Our proposed study not only charts a path toward more effective long-term RES procurement strategies but also provides large electricity customers with a strategic framework to skillfully navigate the complexities of the electricity market in alignment with their sustainability commitments.},
	journal = {ENERGY},
	author = {Yang, Haolin and Xu, Siqi and Gao, Weijun and Wang, Yafei and Li, You and Wei, Xindong},
	month = may,
	year = {2024},
	keywords = {Renewable energy sources, Deep learning networks, Power purchase agreements, Risk-averse optimal operational strategy, Stochastic programming},
	file = {Yang et al. - 2024 - Mitigating long-term financial risk for large cust.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\FUAU7VI3\\Yang et al. - 2024 - Mitigating long-term financial risk for large cust.pdf:application/pdf},
}

@article{ochoa_multi-agent_2022,
	title = {Multi-agent deep reinforcement learning for efficient multi-timescale bidding of a hybrid power plant in day-ahead and real-time markets},
	volume = {317},
	issn = {0306-2619},
	doi = {10.1016/j.apenergy.2022.119067},
	abstract = {Effective bidding on multiple electricity products under uncertainty would allow a more profitable market participation for hybrid power plants with variable energy resources and storage systems, therefore aiding the decarbonization process. This study deals with the effective bidding of a photovoltaic plant with an energy storage system (PV-ESS) participating in multi-timescale electricity markets by providing energy and ancillary services (AS) products. The energy management system (EMS) aims to maximize the plant's profits by efficiently bidding in the day-ahead and real-time markets while considering the awarded products' adequate delivery. EMS's bidding decisions are usually obtained from traditional mathematical optimization frameworks. However, since the addressed problem is a multi-stage stochastic program, it is often intractable and suffers the curse of dimensionality. This paper presents a novel multi-agent deep reinforcement learning (MADRL) framework for efficient multi-timescale bidding. Two agents based on multi-view artificial neural networks with recurrent layers (MVANNs) are adjusted to map environment observations to actions. Such mappings use as inputs available information related to electricity market products, bidding decisions, solar generation, stored energy, and time representations to bid in both electricity markets. Sustained by a price-taker assumption, the physically and financially constrained EMS's environment is simulated by employing historical data. A shared cumulative reward function with a finite time horizon is used to adjust both MVANNs' weights simultaneously during the learning phase. We compare the proposed MADRL framework against scenario-based two-stage robust and stochastic optimization methods. Results are provided for one-year-round market participation of the hybrid plant at a 1-minute resolution. The proposed method achieved statistically significant higher profits, less variable incomes from both electricity markets, and better provision of awarded products by achieving smaller and less variable energy imbalances through time.},
	journal = {APPLIED ENERGY},
	author = {Ochoa, Tomas and Gil, Esteban and Angulo, Alejandro and Valle, Carlos},
	month = jul,
	year = {2022},
	keywords = {Energy storage, Energy management system, Electricity market bidding, Multi-agent deep reinforcement learning, Multi-timescale electricity markets, Multi-view artificial neural networks, Solar generation},
	file = {Ochoa et al. - 2022 - Multi-agent deep reinforcement learning for effici.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\YSA8F8LA\\Ochoa et al. - 2022 - Multi-agent deep reinforcement learning for effici.pdf:application/pdf},
}

@article{afrasiabi_multi-agent_2019,
	title = {Multi-agent microgrid energy management based on deep learning forecaster},
	volume = {186},
	issn = {0360-5442},
	doi = {10.1016/j.energy.2019.115873},
	abstract = {This paper presents a multi-agent day-ahead microgrid energy management framework. The objective is to minimize energy loss and operation cost of agents, including conventional distributed generators, wind turbines, photovoltaics, demands, battery storage systems, and microgrids aggregator agent. To forecast market prices, wind generation, solar generation, and load demand, a deep learning-based approach is designed based on a combination of convolutional neural networks and gated recurrent unit. Each agent utilizes the designed learning approach and its own historical data to forecast its required parameters/data for scheduling purposes. To preserve the information privacy of agents, the alternating direction method of multipliers (ADMM) is utilized to find the optimal operating point of microgrid distributedly. To enhance the convergence performance of the distributed algorithm, an accelerated ADMM is presented based on the concept of over-relaxation. In the proposed framework, the agents do not need to share with other parties either their historical data for forecasting purposes or commercially sensitive information for scheduling purposes. The proposed framework is tested on a realistic test system. The forecast values obtained by the proposed forecasting method are compared with several other methods and the accelerated distributed algorithm is compared with the standard ADMM and analytical target cascading. (C) 2019 Published by Elsevier Ltd.},
	journal = {ENERGY},
	author = {Afrasiabi, Mousa and Mohammadi, Mohammad and Rastegar, Mohammad and Kargarian, Amin},
	month = nov,
	year = {2019},
	keywords = {Convolutional neural networks, Deep learning, Microgrid energy management system, Alternating direction method of multipliers, Gated recurrent unit, Short-term forecasting},
	file = {Afrasiabi et al. - 2019 - Multi-agent microgrid energy management based on d.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\DCGTYB3N\\Afrasiabi et al. - 2019 - Multi-agent microgrid energy management based on d.pdf:application/pdf},
}

@article{kim_multi-period_2024,
	title = {Multi-period, multi-timescale stochastic optimization model for simultaneous capacity investment and energy management decisions for hybrid {Micro}-{Grids} with green hydrogen production under uncertainty},
	volume = {190},
	issn = {1364-0321},
	doi = {10.1016/j.rser.2023.114049},
	abstract = {Given the steep rises in renewable energy's proportion in the global energy mix expected over several decades, a systematic way to plan the long-term deployment is needed. The main challenges are how to handle the sig-nificant uncertainties in technologies and market dynamics over a large time horizon. The problem is further complicated by the fast-timescale volatility of renewable energy sources, potentially causing grid instability and unfulfilled demands. As a remedy, energy storage and power-to-hydrogen systems are considered in conjunction with energy management system but doing so raises the complexity of the planning problem further. In this work, the long-term capacity planning for a hybrid microgrid (HM) system is formulated as a multi-period stochastic decision problem that considers uncertainties occurring at multiple timescales. Long-term capacity decisions are inherently linked with energy dispatch and storage decisions occurring at fast-timescale and it is best to solve for them simultaneously. However, the computational demand for solving it becomes quickly intractable with problem size. To this end, we propose to develop a Markov decision process (MDP) formulation of the problem and use simulation-based reinforcement learning for multi-period capacity investments of the planning horizon. The MDP includes the policies used for dispatch and storage operation, which are represented by linear programming as a part of the simulation model. The effectiveness of our proposed method is demonstrated with a case study, where decisions over multiple decades are considered along with various un-certainties of multi-timescales. Economic and environmental assessments are performed, providing valuable guidelines for government's energy policy.},
	number = {A},
	journal = {RENEWABLE \& SUSTAINABLE ENERGY REVIEWS},
	author = {Kim, Sunwoo and Choi, Yechan and Park, Joungho and Adams, Derrick and Heo, Seongmin and Lee, Jay H.},
	month = feb,
	year = {2024},
	keywords = {Energy management system, Capacity investment planning, Dynamic multi-period and multi-timescale decision-making, Green hydrogen, Hybrid microgrid, Multi-timescale uncertainty},
}

@article{nunna_multiagent-based_2020,
	title = {Multiagent-{Based} {Energy} {Trading} {Platform} for {Energy} {Storage} {Systems} in {Distribution} {Systems} {With} {Interconnected} {Microgrids}},
	volume = {56},
	issn = {1939-9367},
	doi = {10.1109/TIA.2020.2979782},
	abstract = {In this article, an agent-based transactive energy (TE) trading platform to integrate energy storage systems (ESSs) into the microgrids' energy management system is proposed. Using this platform, two different types of energy storage market models are proposed to promote local-level (within the microgrid) and communal- or global-level ESSs' participation in the intra- and intermicrogrid TE markets. Also, a reinforcement learning algorithm known as simulated-annealing-based Q-learning is used to develop bidding strategies for ESSs to participate in the TE markets. Besides energy trading, the proposed system also accounts for the losses caused by energy transactions between ESSs and microgrids using a complex current-tracing-based loss allocation method. The overall efficacy of the proposed energy market management system is demonstrated using a modified IEEE 123-bus distribution system with multiple microgrids and ESSs. Based on simulation results, it is observed that the proposed model can effectively reinforce the balance between the supply and the demand in the microgrids using the mix of local and global ESSs.},
	number = {3},
	journal = {IEEE Transactions on Industry Applications},
	author = {Nunna, H. S. V. S. Kumar and Sesetti, Anudeep and Rathore, Akshay Kumar and Doolla, Suryanarayana},
	month = may,
	year = {2020},
	keywords = {Biological system modeling, Energy management, Peer-to-peer computing, Load modeling, Microgrids, Electricity markets, Energy storage, energy storage systems (ESSs), Generators, microgrids, multiagent systems, transactive energy (TE)},
	pages = {3207--3217},
}

@article{taherian_optimal_2021,
	title = {Optimal dynamic pricing for an electricity retailer in the price-responsive environment of smart grid},
	volume = {130},
	issn = {0142-0615},
	doi = {10.1016/j.ijepes.2021.107004},
	abstract = {The main purpose of this study is to support a retail electric provider (REP) to make the best day-ahead dynamic pricing decisions in a realistic scenario. These decisions are made with the aim of maximizing the profit achieved by the REP under the assumption that mixed types of customers with different behaviors in the electricity market are considered. While some of the customers have installed smart meters with an embedded home energy management system (HEMS) in their home, others do not participate in the demand response (DR) programs. For this purpose, a bi-level hybrid demand modeling framework is proposed. It firstly uses an optimal energy management algorithm with bill minimization in order to model the behavior of customers with smart meters. Then, using a customers? behavior learning machine (CBLM), the behavior of other groups without smart meters is modeled. Therefore, the proposed hybrid model cannot only schedule usage of home appliances to the interests of customers with smart meters but can also be used to understand electricity usage behavior of customers without smart meters. The proposed model includes a stacked auto-encoder (SAE), one of the deep learning (DL) methods suitable for real-valued inputs, and adaptive neuro-fuzzy inference system (ANFIS). Based on the established hybrid demand model for all customers, a profit maximization algorithm is developed in order to achieve optimal prices for the REP under relevant market constraints. The results of the case studies confirm the applicability and effectiveness of the proposed model.},
	journal = {INTERNATIONAL JOURNAL OF ELECTRICAL POWER \& ENERGY SYSTEMS},
	author = {Taherian, Hossein and Aghaebrahimi, Mohammad Reza and Baringo, Luis and Goldani, Saeid Reza},
	month = sep,
	year = {2021},
	keywords = {Deep learning, Smart grid, Bidding strategy, Customer behavior learning, Day-ahead dynamic pricing, Retail electric provider},
	file = {Taherian et al. - 2021 - Optimal dynamic pricing for an electricity retaile.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\GZV7UYVL\\Taherian et al. - 2021 - Optimal dynamic pricing for an electricity retaile.pdf:application/pdf},
}

@article{kelly_optimal_2020,
	title = {Optimal investment timing and sizing for battery energy storage systems},
	volume = {28},
	doi = {10.1016/j.est.2020.101272},
	abstract = {Due to electricity market deregulation over the past two decades, the responsibility for new generation is with private investors who seek profit maximisation. Battery Energy Storage Systems (BESS), which are one solution to combat the intermittent nature of renewable energy sources, also require private investment for widespread deployment. This paper develops a methodology for applying Real Options Analysis to a BESS project from the perspective of private investors to determine the optimal investment time and BESS capacity size (MWh). Two models with different timescales are utilized: the operational model which is hourly, and the planning model which is yearly. The operational model is solved using a reinforcement learning algorithm called Deterministic Policy Gradient, while the planning model is solved using a MATLAB inbuilt nonlinear global optimiser called patternsearch. The methodology is demonstrated for a 100 MW BESS connected to the Irish grid and trading exclusively in the day-ahead market. Three different BESS CAPEX future realisations are analysed along with three different BESS manufacturers' degradation warranties for C-Rates under 0.37C. The results show that BESS CAPEX has minimal influence on investment timing but has a significant effect on BESS size. Furthermore, extrapolating degradation warranty for C-Rates greater than 0.37C does not influence optimal investment timing or sizing, while a change in BESS energy retention limit at year 10 can have a significant influence on the viability of a BESS project.},
	journal = {JOURNAL OF ENERGY STORAGE},
	author = {Kelly, Joseph J. and Leahy, Paul G.},
	month = apr,
	year = {2020},
	keywords = {Reinforcement learning, Battery degradation, Battery energy storage systems, Deterministic Policy Gradient Algorithm, Net Present Value, Real Option Analysis, Stochastic optimization},
	file = {Kelly and Leahy - 2020 - Optimal investment timing and sizing for battery e.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\XVTDH4UD\\Kelly and Leahy - 2020 - Optimal investment timing and sizing for battery e.pdf:application/pdf},
}

@article{zheng_power_2024,
	title = {Power {Demand} {Reshaping} {Using} {Energy} {Storage} for {Distributed} {Edge} {Clouds}},
	volume = {35},
	issn = {1558-2183},
	doi = {10.1109/TPDS.2023.3347774},
	abstract = {The booming edge computing market that is supported by the edge cloud (EC) infrastructure has brought huge operating costs, mainly the energy cost, to edge service providers. The energy cost in form of electricity bills usually consists of energy charge and demand charge, and the demand charge based on peak power may account for a large proportion of the energy cost given a significant fluctuating power curve. In this work, we investigate the backup battery characteristics and electricity charge tariffs at ECs and explore the corresponding cost-saving potential. Specifically, we transform the backup battery group into distributed battery energy storage system (BESS) and strategically schedule the BESS to minimize the energy cost of service providers. We then propose a deep reinforcement learning (DRL) based approach to BESS charging/discharging in coping with the dynamic power demand and BESS state at each EC. To enable better decision-making and speed up agent training, we further design the customized invalid action masking (IAM) method and apply the prioritized experience replay (PER) scheme. The experiment results based on real-world EC power traces show that the proposed approach can reduce the demand charge and overall electricity bill by up to 27\% and 13\%, respectively.},
	number = {2},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Zheng, Dongyu and Liu, Lei and Tang, Guoming and Wang, Yi and Li, Weichao},
	month = feb,
	year = {2024},
	keywords = {Real-time systems, Batteries, Tariffs, Costs, Energy storage, energy storage, Power demand, edge computing, Demand charge, distributed BESS, power shaving, Uninterruptible power systems},
	pages = {362--376},
}

@article{mashlakov_probabilistic_2020,
	title = {Probabilistic {Forecasting} of {Battery} {Energy} {Storage} {State}-of-{Charge} under {Primary} {Frequency} {Control}},
	volume = {38},
	issn = {1558-0008},
	doi = {10.1109/JSAC.2019.2952195},
	abstract = {Multi-service market optimization of battery energy storage system (BESS) requires assessing the forecasting uncertainty arising from coupled resources and processes. For the primary frequency control (PFC), which is one of the highest-value applications of BESS, this uncertainty is linked to the changes of BESS state-of-charge (SOC) under stochastic frequency variations. In order to quantify this uncertainty, this paper aims to exploit one of the recent achievements in the field of deep learning, i.e. multi-attention recurrent neural network (MARNN), for BESS SOC forecasting under PFC. Furthermore, we extend the MARNN model for probabilistic forecasting with a hybrid approach combining Mixture Density Networks and Monte Carlo dropout that incorporate the uncertainties of the data noise and the model parameters in the form of prediction interval (PI). The performance of the model is studied on BESS SOC datasets that are simulated based on real frequency measurements from three European synchronous areas in Great Britain, Continental Europe, and Northern Europe and validated by three PI evaluation indexes. Compared with the state-of-the-art quantile regression algorithms, the proposed hybrid model performed well with respect to the coverage probability of PIs for the different regulatory environments of the PFC.},
	number = {1},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Mashlakov, Aleksei and Lensu, Lasse and Kaarna, Arto and Tikka, Ville and Honkapuro, Samuli},
	month = jan,
	year = {2020},
	keywords = {Batteries, Forecasting, Predictive models, Uncertainty, Frequency control, Attention-based neural network, battery energy storage system (BESS), Data models, frequency control, mixture density networks, Monte Carlo dropout, prediction intervals, probabilistic forecasting, Probabilistic logic, state-of-charge (SOC)},
	pages = {96--109},
	file = {Accepted Version:C\:\\Users\\Jacob\\Zotero\\storage\\K9GGJV7Z\\Mashlakov et al. - 2020 - Probabilistic Forecasting of Battery Energy Storag.pdf:application/pdf},
}

@article{norouzi_risk-averse_2023,
	title = {Risk-averse and flexi-intelligent scheduling of microgrids based on hybrid {Boltzmann} machines and cascade neural network forecasting},
	volume = {348},
	issn = {0306-2619},
	doi = {10.1016/j.apenergy.2023.121573},
	abstract = {The future of energy flexibility in microgrids (MGs) is steering towards a highly granular control of the end-user customers. This calls for more highly accurate uncertainty forecasting and optimal management of risk and flexibility options. This paper presents a novel data-driven model to optimize the operation of MGs based on a risk-averse flexi-intelligent energy management system (RFEMS), considering the rising challenge of global climate change. It considers the presence of renewables, a diesel generator, and flexibility resources (FRs) containing a demand response program (DRP), distributed electric vehicles (EVs), and electric springs (ESs). In the first phase, the proposed model, by means of a novel hybrid deep-learning (DL) model, forecasts uncertain parameters associated with wind and solar generations, load demand, and day-ahead energy market price. The architecture of the proposed hybrid forecasting model is composed of several stacked restricted Boltzmann machines and a cascade neural network. In the second phase, the MG operator (MGO), based on the obtained uncertainty forecasting results, in the context of a hybrid risk-controlling model, optimizes the MG operation using the provided demand-side flexibility. The proposed optimization problem is linearized stochastic pro-gramming with robust concepts, subject to AC optimal power flow constraints, MG flexibility restrictions, and operating limits of local resources. Finally, the efficiency of the proposed RFEMS by using real German datasets on a 33-bus test MG is analyzed. Numerical results demonstrate the superior performance of the proposed forecasting model over several hybrid DL models. In particular, the root mean square error (RMSE) index for wind, solar, load, and price forecasting is improved by 53.35\%, 73.24\%, 80.24\%, and 58.1\%, respectively. Further analysis of the proposed RFEMS reveals that operating indices in two 33-bus and 69-bus test networks are significantly improved. It paves pathways to risk-averse, flexible, and economic operation of smart active dis-tribution networks.},
	journal = {APPLIED ENERGY},
	author = {Norouzi, Mohammadali and Aghaei, Jamshid and Niknam, Taher and Alipour, Mohammadali and Pirouzi, Sasan and Lehtonen, Matti},
	month = oct,
	year = {2023},
	keywords = {spring},
}

@article{sierla_taxonomy_2022,
	title = {A taxonomy of machine learning applications for virtual power plants and home/building energy management systems},
	volume = {136},
	issn = {0926-5805},
	doi = {10.1016/j.autcon.2022.104174},
	abstract = {A Virtual power plant is defined as an information and communications technology system with the following primary functionalities: enhancing renewable power generation, aggregating Distributed Energy Resources and monetizing them considering the relevant energy contracts or markets. A virtual power plant also includes secondary functionalities such as forecasting load, market prices and renewable generation, as well as asset management related to the distributed energy ressources. Home energy management systems and building energy management systems have significant overlap with virtual power plants, but these bodies of research are largely separate. Machine learning has recently been applied to realize various functionalities of these systems. This article presents a 3-tier taxonomy of such functionalities. The top tier categories are optimization, forecasting and classification. A scientometric research methodology is used, so that a custom database has been developed to capture metadata from all of the articles that have been included in the taxonomy. Custom algorithms have been developed to generate infographics from the database, to visualize the taxonomy and trends in the research. The paper concludes with a discussion of topics expected to receive a high number of publications in the future, as well as currently unresolved challenges.},
	journal = {AUTOMATION IN CONSTRUCTION},
	author = {Sierla, Seppo and Pourakbari-Kasmaei, Mahdi and Vyatkin, Valeriy},
	month = apr,
	year = {2022},
}

@article{clemente_optimizing_2024,
	title = {Optimizing {Performance} of {Hybrid} {Electrochemical} {Energy} {Storage} {Systems} through {Effective} {Control}: {A} {Comprehensive} {Review}},
	volume = {13},
	doi = {10.3390/electronics13071258},
	abstract = {The implementation of energy storage system (ESS) technology with an appropriate control system can enhance the resilience and economic performance of power systems. However, none of the storage options available today can perform at their best in every situation. As a matter of fact, an isolated storage solution's energy and power density, lifespan, cost, and response time are its primary performance constraints. Batteries are the essential energy storage component used in electric mobility, industries, and household applications nowadays. In general, the battery energy storage systems (BESS) currently available on the market are based on a homogeneous type of electrochemical battery. However, a hybrid energy storage system (HESS) based on a mixture of various types of electrochemical batteries can potentially provide a better option for high-performance electric cars, heavy-duty electric vehicles, industries, and residential purposes. A hybrid energy storage system combines two or more electrochemical energy storage systems to provide a more reliable and efficient energy storage solution. At the same time, the integration of multiple energy storage systems in an HESS requires advanced control strategies to ensure optimal performance and longevity of the system. This review paper aims to provide a comprehensive overview of the control systems used in HESSs for a wide range of applications. An overview of the various control strategies used in HESSs is offered, including traditional control methods such as proportional-integral-derivative (PID) control, and advanced control methods such as model predictive control (MPC), droop control (DC), sliding mode control (SMC), rule-based control (RBC), fuzzy logic control (FLC), and artificial neural network (ANN) control are discussed. The paper also highlights the recent developments in HESS control systems, including the use of machine learning techniques such as deep reinforcement learning (DRL) and genetic algorithms (GA). The paper provides not only a description and classification of various control approaches but also a comparison between control strategies from the evaluation of performance point of view. The review concludes by summarizing the key findings and future research directions for HESS control systems, which is directly linked to the research on machine learning and the mix of different control type strategies.},
	number = {7},
	journal = {ELECTRONICS},
	author = {Clemente, Alejandro and Arias, Paula and Gevorkov, Levon and Trilla, Lluis and Rey, Sergi Obrador and Roger, Xavier Sanchez and Dominguez-Garcia, Jose Luis and Martinez, Alber Filba},
	month = apr,
	year = {2024},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\HBSTELPC\\Clemente et al. - 2024 - Optimizing Performance of Hybrid Electrochemical E.pdf:application/pdf},
}

@article{miao_co-optimizing_2021,
	title = {Co-{Optimizing} {Battery} {Storage} for {Energy} {Arbitrage} and {Frequency} {Regulation} in {Real}-{Time} {Markets} {Using} {Deep} {Reinforcement} {Learning}},
	volume = {14},
	doi = {10.3390/en14248365},
	abstract = {Battery energy storage systems (BESSs) play a critical role in eliminating uncertainties associated with renewable energy generation, to maintain stability and improve flexibility of power networks. In this paper, a BESS is used to provide energy arbitrage (EA) and frequency regulation (FR) services simultaneously to maximize its total revenue within the physical constraints. The EA and FR actions are taken at different timescales. The multitimescale problem is formulated as two nested Markov decision process (MDP) submodels. The problem is a complex decision-making problem with enormous high-dimensional data and uncertainty (e.g., the price of the electricity). Therefore, a novel co-optimization scheme is proposed to handle the multitimescale problem, and also coordinate EA and FR services. A triplet deep deterministic policy gradient with exploration noise decay (TDD-ND) approach is used to obtain the optimal policy at each timescale. Simulations are conducted with real-time electricity prices and regulation signals data from the American PJM regulation market. The simulation results show that the proposed approach performs better than other studied policies in literature.},
	number = {24},
	journal = {ENERGIES},
	author = {Miao, Yushen and Chen, Tianyi and Bu, Shengrong and Liang, Hao and Han, Zhu},
	month = dec,
	year = {2021},
	file = {1-s2.0-S0925231220304367-main.pdf:C\:\\Users\\Jacob\\Zotero\\storage\\X8D5Z3WX\\1-s2.0-S0925231220304367-main.pdf:application/pdf;Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\MBBP8FR9\\Miao et al. - 2021 - Co-Optimizing Battery Storage for Energy Arbitrage.pdf:application/pdf},
}

@article{gao_hybrid_2024,
	title = {A {Hybrid} {Approach} for {Home} {Energy} {Management} {With} {Imitation} {Learning} and {Online} {Optimization}},
	volume = {20},
	issn = {1551-3203},
	doi = {10.1109/TII.2023.3324939},
	abstract = {A home energy management system exploits the time-varying electricity tariff and renewable energy profiles to lower residents' electricity bills via wise scheduling of various domestic appliances. This study targets the rather typical case of a general household with solar panels. All four classes of loads are considered, while many existing studies only investigate a restricted subset. Considering the high stochasticity in real-time pricing and solar power generation, we propose an online approach in a hybrid semidecentralized framework, where each shiftable load is controlled by a deep neural network (DNN), and all adjustable loads are coordinated together by fast online optimization. We train each DNN via efficient and effective imitation learning (IL) instead of popular reinforcement learning (RL). This framework allows adjustable loads to react properly to possibly poor actions of shiftable loads via online one-step optimization to alleviate their adverse impact. Numerical experiments with real-world data show that, compared with RL, our approach can reduce the training time significantly, while its execution time is only slightly affected. Moreover, our approach outperforms the traditional day-ahead optimization method and the fully decentralized multiagent RL and multiagent IL methods by a wide margin, attaining an average cost fairly close to the theoretical minimum.},
	number = {3},
	journal = {IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS},
	author = {Gao, Shuhua and Lee, Raiyan bin Zulkifli and Huang, Zhenhao and Xiang, Cheng and Yu, Ming and Tan, Kuan Tak and Lee, Tong Heng Lee},
	month = mar,
	year = {2024},
	pages = {4527--4539},
	file = {Gao et al. - 2024 - A Hybrid Approach for Home Energy Management With .pdf:C\:\\Users\\Jacob\\Zotero\\storage\\DDF4FBPJ\\Gao et al. - 2024 - A Hybrid Approach for Home Energy Management With .pdf:application/pdf},
}

@article{mathew_improved_2021,
	title = {Improved residential energy management system using priority double deep {Q}-learning},
	volume = {69},
	issn = {2210-6707},
	doi = {10.1016/j.scs.2021.102812},
	abstract = {In the current era, electricity demand has skyrocketed. Power grids have to face a lot of uneven power demand daily. During a certain period in a day, the power demand peaks, making it difficult for the grid to meet the demand. To deal with this problem, an intelligent Home Energy Management (HEM) can be beneficial. Smart HEM systems can schedule loads from peak to low peak hours. Thereby reducing peak load on the grid as well as reducing decreasing the costs incurred by a user. In this paper, we proposed a Deep Reinforcement Learning model with prioritized experience sampling (PQDN-DR) for appropriate demand response, and the problem of load shifting is simulated as a game. We also propose a novel reward system for better convergence of the DRL model to near-optimal strategies and a DR adapted Epsilon Greedy Policy to guide the agent in exploration phase for faster convergence. The proposed system minimizes power demand peak and consumers? bills simultaneously. The proposed method has successfully reduced the peak load and peak costs in smaller DR environment. The agent reduced costs and overall variance of the load profile for all customers for 24 h in the standard DR environment.},
	journal = {SUSTAINABLE CITIES AND SOCIETY},
	author = {Mathew, Alwyn and Jolly, Milan Jeetendra and Mathew, Jimson},
	month = jun,
	year = {2021},
}

@article{gao_learning-based_2021,
	title = {A {Learning}-{Based} {Bidding} {Approach} for {PV}-{Attached} {BESS} {Power} {Plants}},
	volume = {9},
	issn = {2296-598X},
	doi = {10.3389/fenrg.2021.750796},
	abstract = {Large-scale renewable photovoltaic (PV) and battery energy storage system (BESS) units are promising to be significant electricity suppliers in the future electricity market. A bidding model is proposed for PV-integrated BESS power plants in a pool-based day-ahead (DA) electricity market, in which the uncertainty of PV generation output is considered. In the proposed model, we consider the market clearing process as the external environment, while each agent updates the bid price through the communication with the market environment for its revenue maximization. A multiagent reinforcement learning (MARL) called win-or-learn-fast policy-hill-climbing (WoLF-PHC) is used to explore optimal bid prices without any information of opponents. The case study validates the computational performance of WoLF-PHC in the proposed model, while the bidding strategy of each participated agent is thereafter analyzed.},
	journal = {FRONTIERS IN ENERGY RESEARCH},
	author = {Gao, Xiang and Ma, Haomin and Chan, Ka Wing and Xia, Shiwei and Zhu, Ziqing},
	month = oct,
	year = {2021},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\HV8SKA4N\\Gao et al. - 2021 - A Learning-Based Bidding Approach for PV-Attached .pdf:application/pdf},
}

@article{salazar_reinforcement_2023,
	title = {Reinforcement {Learning}-{Based} {Pricing} and {Incentive} {Strategy} for {Demand} {Response} in {Smart} {Grids}},
	volume = {16},
	doi = {10.3390/en16031466},
	abstract = {International agreements support the modernization of electricity networks and renewable energy resources (RES). However, these RES affect market prices due to resource variability (e.g., solar). Among the alternatives, Demand Response (DR) is presented as a tool to improve the balance between electricity supply and demand by adapting consumption to available production. In this sense, this work focuses on developing a DR model that combines price and incentive-based demand response models (P-B and I-B) to efficiently manage consumer demand with data from a real San Juan-Argentina distribution network. In addition, a price scheme is proposed in real time and by the time of use in relation to the consumers' influence in the peak demand of the system. The proposed schemes increase load factor and improve demand displacement compared to a demand response reference model. In addition, the proposed reinforcement learning model improves short-term and long-term price search. Finally, a description and formulation of the market where the work was implemented is presented.},
	number = {3},
	journal = {ENERGIES},
	author = {Salazar, Eduardo J. and Jurado, Mauro and Samper, Mauricio E.},
	month = feb,
	year = {2023},
	file = {Full Text:C\:\\Users\\Jacob\\Zotero\\storage\\RUVF6V5Q\\Salazar et al. - 2023 - Reinforcement Learning-Based Pricing and Incentive.pdf:application/pdf},
}
